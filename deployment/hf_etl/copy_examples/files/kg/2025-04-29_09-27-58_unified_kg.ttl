@prefix ns1: <http://w3id.org/fair4ml/> .
@prefix ns2: <http://mlcommons.org/croissant/> .
@prefix ns3: <https://w3id.org/codemeta/> .
@prefix rdf: <http://www.w3.org/1999/02/22-rdf-syntax-ns#> .
@prefix schema: <https://schema.org/> .
@prefix xsd: <http://www.w3.org/2001/XMLSchema#> .

<http://mlentory.zbmed.de/mlentory_graph/017f19456e7a37fe3c1ad51165020b62cc12497d5d20651e073e3520a5099eb9> a schema:DefinedTerm ;
    schema:description "Answers questions based on tabular data."^^xsd:string ;
    schema:name "Table Question Answering"^^xsd:string .

<http://mlentory.zbmed.de/mlentory_graph/0c3d01ed44dc2940ae38707146a02c16bc80cc8637ce48ac5f3125b7c6fb2982> a schema:DefinedTerm ;
    schema:description "Models based on BERT (Bidirectional Encoder Representations from Transformers), a transformer architecture that learns contextual word embeddings."^^xsd:string ;
    schema:name "bert"^^xsd:string .

<http://mlentory.zbmed.de/mlentory_graph/119bd2aa6d51fb076ddf89b0c5c2536f1550ff5bf549b11a6c834340b0979a14> a schema:DefinedTerm ;
    schema:description "Library for span-based named entity recognition using transformer models."^^xsd:string ;
    schema:name "SpanMarker"^^xsd:string .

<http://mlentory.zbmed.de/mlentory_graph/12855f71ca9ab0f85c6609885b9e912174c81e608da47e6448d968f757f5ab44> a schema:DefinedTerm ;
    schema:description "Library for efficient text classification and word representation learning."^^xsd:string ;
    schema:name "fastText"^^xsd:string .

<http://mlentory.zbmed.de/mlentory_graph/145a1db14402ffd2d346a7bf50e3e9e8c75169383a079480e9ba655e5e2fab8a> a schema:DefinedTerm ;
    schema:description "Unity package for running neural networks in real-time applications and games."^^xsd:string ;
    schema:name "unity-sentis"^^xsd:string .

<http://mlentory.zbmed.de/mlentory_graph/15ceeb8703c6ba669411911c62acbbac38f4d1235e8ac6118537ac1e6d75ae84> a schema:DefinedTerm ;
    schema:description "High-throughput asynchronous reinforcement learning framework for training RL agents."^^xsd:string ;
    schema:name "sample-factory"^^xsd:string .

<http://mlentory.zbmed.de/mlentory_graph/1759562ba5af131b8ba1cdb4e06a2cee5c1ebff35971610e6ef2eb585b413ef7> a schema:DefinedTerm ;
    schema:description "Identifies when someone is speaking in an audio stream."^^xsd:string ;
    schema:name "Voice Activity Detection"^^xsd:string .

<http://mlentory.zbmed.de/mlentory_graph/192e3c37cdad044da28b01edd768819d9dc9ebf5642a4dd3e0cf9564058b6d2a> a schema:DefinedTerm ;
    schema:description "Models quantized to 8-bit precision, balancing performance and memory efficiency."^^xsd:string ;
    schema:name "8-bit precision"^^xsd:string .

<http://mlentory.zbmed.de/mlentory_graph/1eb8c8e4581f920f5c0585f4ccb2c46299ab8fff99ae7f849732244d66b50299> a ns1:ML_Model ;
    ns1:ethicalLegalSocial "The ethical considerations and risks section of the text discusses the potential for Flan-T5 to generate inappropriate content or replicate inherent biases in the underlying data. Additionally, the sensitive use section states that Flan-T5 should not be applied for any unacceptable use cases, such as generating abusive speech."^^xsd:string ;
    ns1:evaluatedOn <http://mlentory.zbmed.de/mlentory_graph/1fe551ba3faf898fda38c533bbd65bcba38644c47f7415289a6bee9579f2b365>,
        <http://mlentory.zbmed.de/mlentory_graph/43bc0319b35edce6a819b7513d5d158c1ea9bd4b7e1f558fabd51fb09b4f7755>,
        <http://mlentory.zbmed.de/mlentory_graph/4a958b2cddc6f3096d3a4e912c3bf694e8c132edcdb79366c6a34dff81cbbc7b>,
        <http://mlentory.zbmed.de/mlentory_graph/5ad4ea0a1adc915075db5ddcb934b366ce7b5457e888eac0c229b5478d60a36b>,
        <http://mlentory.zbmed.de/mlentory_graph/5dc0f178a97885f8a2e4615a52b4e2b4f27d25a59fce78191c80557258b63498>,
        <http://mlentory.zbmed.de/mlentory_graph/65d71074238354144f600279f94efa203ecd00ca7b0c6df7d4041b8a3daa0c02>,
        <http://mlentory.zbmed.de/mlentory_graph/83f6b13508bdbd7f513cbd6de7ef5170638d3e63612800f251838bd8e03c995e>,
        <http://mlentory.zbmed.de/mlentory_graph/9773f8d647166503d14c7a05030b47d6b1610f17bdd55e8c98cb4fc2b13a3379>,
        <http://mlentory.zbmed.de/mlentory_graph/ba52d56993d4b3a19ff2ae9a283e7057fc5503a3a3eecc69e091547b776282b4>,
        <http://mlentory.zbmed.de/mlentory_graph/cafa6cfd9a4170cbf6a99f2d8b42715517f11068dc92b807e31dad9ab0535893> ;
    ns1:fineTunedFrom "Information not found"^^xsd:string ;
    ns1:hasCO2eEmissions "Information not found."^^xsd:string ;
    ns1:intendedUse "Flan-T5 should not be applied for any unacceptable use cases, e.g., generation of abusive speech."^^xsd:string ;
    ns1:mlTask <http://mlentory.zbmed.de/mlentory_graph/9abc397b7489422e962aeae20a5ed774806c8bd8f47e9008eef451699b8a61c1> ;
    ns1:modelCategory "Information not found."^^xsd:string ;
    ns1:modelRisks "The potential risks associated with the model Flan-T5 are not explicitly mentioned in the provided context."^^xsd:string ;
    ns1:sharedBy <http://mlentory.zbmed.de/mlentory_graph/125d01550d26a191f055cd53b0b7bf0298ef4a173496f10aa09a87ca1b3fdcbe> ;
    ns1:testedOn <http://mlentory.zbmed.de/mlentory_graph/1fe551ba3faf898fda38c533bbd65bcba38644c47f7415289a6bee9579f2b365>,
        <http://mlentory.zbmed.de/mlentory_graph/43bc0319b35edce6a819b7513d5d158c1ea9bd4b7e1f558fabd51fb09b4f7755>,
        <http://mlentory.zbmed.de/mlentory_graph/4a958b2cddc6f3096d3a4e912c3bf694e8c132edcdb79366c6a34dff81cbbc7b>,
        <http://mlentory.zbmed.de/mlentory_graph/5ad4ea0a1adc915075db5ddcb934b366ce7b5457e888eac0c229b5478d60a36b>,
        <http://mlentory.zbmed.de/mlentory_graph/5dc0f178a97885f8a2e4615a52b4e2b4f27d25a59fce78191c80557258b63498>,
        <http://mlentory.zbmed.de/mlentory_graph/65d71074238354144f600279f94efa203ecd00ca7b0c6df7d4041b8a3daa0c02>,
        <http://mlentory.zbmed.de/mlentory_graph/83f6b13508bdbd7f513cbd6de7ef5170638d3e63612800f251838bd8e03c995e>,
        <http://mlentory.zbmed.de/mlentory_graph/9773f8d647166503d14c7a05030b47d6b1610f17bdd55e8c98cb4fc2b13a3379>,
        <http://mlentory.zbmed.de/mlentory_graph/ba52d56993d4b3a19ff2ae9a283e7057fc5503a3a3eecc69e091547b776282b4>,
        <http://mlentory.zbmed.de/mlentory_graph/cafa6cfd9a4170cbf6a99f2d8b42715517f11068dc92b807e31dad9ab0535893> ;
    ns1:trainedOn <http://mlentory.zbmed.de/mlentory_graph/1fe551ba3faf898fda38c533bbd65bcba38644c47f7415289a6bee9579f2b365>,
        <http://mlentory.zbmed.de/mlentory_graph/43bc0319b35edce6a819b7513d5d158c1ea9bd4b7e1f558fabd51fb09b4f7755>,
        <http://mlentory.zbmed.de/mlentory_graph/4a958b2cddc6f3096d3a4e912c3bf694e8c132edcdb79366c6a34dff81cbbc7b>,
        <http://mlentory.zbmed.de/mlentory_graph/5ad4ea0a1adc915075db5ddcb934b366ce7b5457e888eac0c229b5478d60a36b>,
        <http://mlentory.zbmed.de/mlentory_graph/5dc0f178a97885f8a2e4615a52b4e2b4f27d25a59fce78191c80557258b63498>,
        <http://mlentory.zbmed.de/mlentory_graph/65d71074238354144f600279f94efa203ecd00ca7b0c6df7d4041b8a3daa0c02>,
        <http://mlentory.zbmed.de/mlentory_graph/83f6b13508bdbd7f513cbd6de7ef5170638d3e63612800f251838bd8e03c995e>,
        <http://mlentory.zbmed.de/mlentory_graph/9773f8d647166503d14c7a05030b47d6b1610f17bdd55e8c98cb4fc2b13a3379>,
        <http://mlentory.zbmed.de/mlentory_graph/ba52d56993d4b3a19ff2ae9a283e7057fc5503a3a3eecc69e091547b776282b4>,
        <http://mlentory.zbmed.de/mlentory_graph/cafa6cfd9a4170cbf6a99f2d8b42715517f11068dc92b807e31dad9ab0535893> ;
    ns1:usageInstructions "Information not found."^^xsd:string ;
    ns1:validatedOn "Information not found."^^xsd:string ;
    schema:archivedAt <https://huggingface.co/google/flan-t5-small> ;
    schema:author "Information not found."^^xsd:string ;
    schema:citation "Information not found."^^xsd:string ;
    schema:conditionsOfAccess "Information not found."^^xsd:string ;
    schema:contributor "Information not found."^^xsd:string ;
    schema:copyrightHolder "Information not found."^^xsd:string ;
    schema:dateCreated "2022-10-21T09:59:24+00:00"^^xsd:dateTime ;
    schema:dateModified "2023-10-10T18:01:54+00:00"^^xsd:dateTime ;
    schema:datePublished "2022-10-21T09:59:24+00:00"^^xsd:dateTime ;
    schema:description """---
language: 
- en
- fr
- ro
- de
- multilingual

tags:
- text2text-generation

widget:
- text: "Translate to German:  My name is Arthur"
  example_title: "Translation"
- text: "Please answer to the following question. Who is going to be the next Ballon d'or?"
  example_title: "Question Answering"
- text: "Q: Can Geoffrey Hinton have a conversation with George Washington? Give the rationale before answering."
  example_title: "Logical reasoning"
- text: "Please answer the following question. What is the boiling point of Nitrogen?"
  example_title: "Scientific knowledge"
- text: "Answer the following yes/no question. Can you write a whole Haiku in a single tweet?"
  example_title: "Yes/no question"
- text: "Answer the following yes/no question by reasoning step-by-step. Can you write a whole Haiku in a single tweet?"
  example_title: "Reasoning task"
- text: "Q: ( False or not False or False ) is? A: Let's think step by step"
  example_title: "Boolean Expressions"
- text: "The square root of x is the cube root of y. What is y to the power of 2, if x = 4?"
  example_title: "Math reasoning"
- text: "Premise:  At my age you will probably have learnt one lesson. Hypothesis:  It's not certain how many lessons you'll learn by your thirties. Does the premise entail the hypothesis?"
  example_title: "Premise and hypothesis"

datasets:
- svakulenk0/qrecc
- taskmaster2
- djaym7/wiki_dialog
- deepmind/code_contests
- lambada
- gsm8k
- aqua_rat
- esnli
- quasc
- qed


license: apache-2.0
---

# Model Card for FLAN-T5 small

<img src="https://huggingface.co/datasets/huggingface/documentation-images/resolve/main/transformers/model_doc/flan2_architecture.jpg"
alt="drawing" width="600"/>

#  Table of Contents

0. [TL;DR](#TL;DR)
1. [Model Details](#model-details)
2. [Usage](#usage)
3. [Uses](#uses)
4. [Bias, Risks, and Limitations](#bias-risks-and-limitations)
5. [Training Details](#training-details)
6. [Evaluation](#evaluation)
7. [Environmental Impact](#environmental-impact)
8. [Citation](#citation)
9. [Model Card Authors](#model-card-authors)

# TL;DR

If you already know T5, FLAN-T5 is just better at everything. For the same number of parameters, these models have been fine-tuned on more than 1000 additional tasks covering also more languages. 
As mentioned in the first few lines of the abstract : 
>  Flan-PaLM 540B achieves state-of-the-art performance on several benchmarks, such as 75.2% on five-shot MMLU. We also publicly release Flan-T5 checkpoints,1 which achieve strong few-shot performance even compared to much larger models, such as PaLM 62B. Overall, instruction finetuning is a general method for improving the performance and usability of pretrained language models.

**Disclaimer**: Content from **this** model card has been written by the Hugging Face team, and parts of it were copy pasted from the [T5 model card](https://huggingface.co/t5-large).

# Model Details

## Model Description


- **Model type:** Language model
- **Language(s) (NLP):** English, Spanish, Japanese, Persian, Hindi, French, Chinese, Bengali, Gujarati, German, Telugu, Italian, Arabic, Polish, Tamil, Marathi, Malayalam, Oriya, Panjabi, Portuguese, Urdu, Galician, Hebrew, Korean, Catalan, Thai, Dutch, Indonesian, Vietnamese, Bulgarian, Filipino, Central Khmer, Lao, Turkish, Russian, Croatian, Swedish, Yoruba, Kurdish, Burmese, Malay, Czech, Finnish, Somali, Tagalog, Swahili, Sinhala, Kannada, Zhuang, Igbo, Xhosa, Romanian, Haitian, Estonian, Slovak, Lithuanian, Greek, Nepali, Assamese, Norwegian
- **License:** Apache 2.0
- **Related Models:** [All FLAN-T5 Checkpoints](https://huggingface.co/models?search=flan-t5)
- **Original Checkpoints:** [All Original FLAN-T5 Checkpoints](https://github.com/google-research/t5x/blob/main/docs/models.md#flan-t5-checkpoints)
- **Resources for more information:**
  - [Research paper](https://arxiv.org/pdf/2210.11416.pdf)
  - [GitHub Repo](https://github.com/google-research/t5x)
  - [Hugging Face FLAN-T5 Docs (Similar to T5) ](https://huggingface.co/docs/transformers/model_doc/t5)

# Usage

Find below some example scripts on how to use the model in `transformers`:

## Using the Pytorch model

### Running the model on a CPU

<details>
<summary> Click to expand </summary>

```python

from transformers import T5Tokenizer, T5ForConditionalGeneration

tokenizer = T5Tokenizer.from_pretrained("google/flan-t5-small")
model = T5ForConditionalGeneration.from_pretrained("google/flan-t5-small")

input_text = "translate English to German: How old are you?"
input_ids = tokenizer(input_text, return_tensors="pt").input_ids

outputs = model.generate(input_ids)
print(tokenizer.decode(outputs[0]))
```

</details>

### Running the model on a GPU

<details>
<summary> Click to expand </summary>

```python
# pip install accelerate
from transformers import T5Tokenizer, T5ForConditionalGeneration

tokenizer = T5Tokenizer.from_pretrained("google/flan-t5-small")
model = T5ForConditionalGeneration.from_pretrained("google/flan-t5-small", device_map="auto")

input_text = "translate English to German: How old are you?"
input_ids = tokenizer(input_text, return_tensors="pt").input_ids.to("cuda")

outputs = model.generate(input_ids)
print(tokenizer.decode(outputs[0]))
```

</details>

### Running the model on a GPU using different precisions

#### FP16

<details>
<summary> Click to expand </summary>

```python
# pip install accelerate
import torch
from transformers import T5Tokenizer, T5ForConditionalGeneration

tokenizer = T5Tokenizer.from_pretrained("google/flan-t5-small")
model = T5ForConditionalGeneration.from_pretrained("google/flan-t5-small", device_map="auto", torch_dtype=torch.float16)

input_text = "translate English to German: How old are you?"
input_ids = tokenizer(input_text, return_tensors="pt").input_ids.to("cuda")

outputs = model.generate(input_ids)
print(tokenizer.decode(outputs[0]))
```

</details>

#### INT8

<details>
<summary> Click to expand </summary>

```python
# pip install bitsandbytes accelerate
from transformers import T5Tokenizer, T5ForConditionalGeneration

tokenizer = T5Tokenizer.from_pretrained("google/flan-t5-small")
model = T5ForConditionalGeneration.from_pretrained("google/flan-t5-small", device_map="auto", load_in_8bit=True)

input_text = "translate English to German: How old are you?"
input_ids = tokenizer(input_text, return_tensors="pt").input_ids.to("cuda")

outputs = model.generate(input_ids)
print(tokenizer.decode(outputs[0]))
```

</details>

# Uses

## Direct Use and Downstream Use

The authors write in [the original paper's model card](https://arxiv.org/pdf/2210.11416.pdf) that: 

> The primary use is research on language models, including: research on zero-shot NLP tasks and in-context few-shot learning NLP tasks, such as reasoning, and question answering; advancing fairness and safety research, and understanding limitations of current large language models

See the [research paper](https://arxiv.org/pdf/2210.11416.pdf) for further details.

## Out-of-Scope Use

More information needed.

# Bias, Risks, and Limitations

The information below in this section are copied from the model's [official model card](https://arxiv.org/pdf/2210.11416.pdf):

> Language models, including Flan-T5, can potentially be used for language generation in a harmful way, according to Rae et al. (2021). Flan-T5 should not be used directly in any application, without a prior assessment of safety and fairness concerns specific to the application.

## Ethical considerations and risks

> Flan-T5 is fine-tuned on a large corpus of text data that was not filtered for explicit content or assessed for existing biases. As a result the model itself is potentially vulnerable to generating equivalently inappropriate content or replicating inherent biases in the underlying data.

## Known Limitations

> Flan-T5 has not been tested in real world applications.

## Sensitive Use:

> Flan-T5 should not be applied for any unacceptable use cases, e.g., generation of abusive speech.

# Training Details

## Training Data

The model was trained on a mixture of tasks, that includes the tasks described in the table below (from the original paper, figure 2):

![table.png](https://s3.amazonaws.com/moonup/production/uploads/1666363265279-62441d1d9fdefb55a0b7d12c.png)


## Training Procedure

According to the model card from the [original paper](https://arxiv.org/pdf/2210.11416.pdf):

> These models are based on pretrained T5 (Raffel et al., 2020) and fine-tuned with instructions for better zero-shot and few-shot performance. There is one fine-tuned Flan model per T5 model size.

The model has been trained on TPU v3 or TPU v4 pods, using [`t5x`](https://github.com/google-research/t5x) codebase together with [`jax`](https://github.com/google/jax).


# Evaluation

## Testing Data, Factors & Metrics

The authors evaluated the model on various tasks covering several languages (1836 in total). See the table below for some quantitative evaluation:
![image.png](https://s3.amazonaws.com/moonup/production/uploads/1668072995230-62441d1d9fdefb55a0b7d12c.png)
For full details, please check the [research paper](https://arxiv.org/pdf/2210.11416.pdf).

## Results 

For full results for FLAN-T5-Small, see the [research paper](https://arxiv.org/pdf/2210.11416.pdf), Table 3.

# Environmental Impact

Carbon emissions can be estimated using the [Machine Learning Impact calculator](https://mlco2.github.io/impact#compute) presented in [Lacoste et al. (2019)](https://arxiv.org/abs/1910.09700).

- **Hardware Type:** Google Cloud TPU Pods - TPU v3 or TPU v4  | Number of chips ≥ 4.
- **Hours used:** More information needed
- **Cloud Provider:** GCP
- **Compute Region:** More information needed
- **Carbon Emitted:** More information needed

# Citation

**BibTeX:**

```bibtex
@misc{https://doi.org/10.48550/arxiv.2210.11416,
  doi = {10.48550/ARXIV.2210.11416},
  
  url = {https://arxiv.org/abs/2210.11416},
  
  author = {Chung, Hyung Won and Hou, Le and Longpre, Shayne and Zoph, Barret and Tay, Yi and Fedus, William and Li, Eric and Wang, Xuezhi and Dehghani, Mostafa and Brahma, Siddhartha and Webson, Albert and Gu, Shixiang Shane and Dai, Zhuyun and Suzgun, Mirac and Chen, Xinyun and Chowdhery, Aakanksha and Narang, Sharan and Mishra, Gaurav and Yu, Adams and Zhao, Vincent and Huang, Yanping and Dai, Andrew and Yu, Hongkun and Petrov, Slav and Chi, Ed H. and Dean, Jeff and Devlin, Jacob and Roberts, Adam and Zhou, Denny and Le, Quoc V. and Wei, Jason},
  
  keywords = {Machine Learning (cs.LG), Computation and Language (cs.CL), FOS: Computer and information sciences, FOS: Computer and information sciences},
  
  title = {Scaling Instruction-Finetuned Language Models},
  
  publisher = {arXiv},
  
  year = {2022},
  
  copyright = {Creative Commons Attribution 4.0 International}
}
```"""^^xsd:string ;
    schema:discussionUrl <https://huggingface.co/google/flan-t5-small/discussions> ;
    schema:distribution "Information not found."^^xsd:string ;
    schema:funding "Information not found."^^xsd:string ;
    schema:identifier "https://huggingface.co/google/flan-t5-small"^^xsd:string ;
    schema:inLanguage "de"^^xsd:string,
        "en"^^xsd:string,
        "fr"^^xsd:string,
        "ro"^^xsd:string ;
    schema:keywords <http://mlentory.zbmed.de/mlentory_graph/0dce0f5e7319b6178cd79d5f2163f0e134d0064f4ea4f93e8afeec1e7d78fa8d>,
        <http://mlentory.zbmed.de/mlentory_graph/1aa60aa9719223ac8750af1366d4a56166214022d0d069d1412225070d1275b9>,
        <http://mlentory.zbmed.de/mlentory_graph/3e9a4e1232f617b33fa8460d6c142ee49e69eb5c55acfd1e618d58e7495955e8>,
        <http://mlentory.zbmed.de/mlentory_graph/81c4f52fcccf6ef0d25453aedb7cebe30c7034e3b2fa752246d0e43da889a0e1>,
        <http://mlentory.zbmed.de/mlentory_graph/87b927fef88a46248b3b208472aec7bfeb38667386b309f46772e26b40f6affb>,
        <http://mlentory.zbmed.de/mlentory_graph/9c51ba772888465129d6bda3b0b520a3a16960b8c108a8cd2276eb4fb85ee5f2>,
        <http://mlentory.zbmed.de/mlentory_graph/df4982af808ead1a57663cc7a83e60059f6a6ae1baf83a270fdf8bdfef11a3de>,
        <http://mlentory.zbmed.de/mlentory_graph/e694cb482434e33f5aadafc7ba5607930722b2bd1b0cb252690679261c8692f4>,
        <http://mlentory.zbmed.de/mlentory_graph/f59cf55f3a86acf0bcfc020eac552a72c13f1212154211a7bf30504548661f8d>,
        "arxiv:1910.09700"^^xsd:string,
        "arxiv:2210.11416"^^xsd:string,
        "dataset:aqua_rat"^^xsd:string,
        "dataset:deepmind/code_contests"^^xsd:string,
        "dataset:djaym7/wiki_dialog"^^xsd:string,
        "dataset:esnli"^^xsd:string,
        "dataset:gsm8k"^^xsd:string,
        "dataset:lambada"^^xsd:string,
        "dataset:qed"^^xsd:string,
        "dataset:quasc"^^xsd:string,
        "dataset:svakulenk0/qrecc"^^xsd:string,
        "dataset:taskmaster2"^^xsd:string,
        "de"^^xsd:string,
        "en"^^xsd:string,
        "fr"^^xsd:string,
        "license:apache-2.0"^^xsd:string,
        "region:us"^^xsd:string,
        "ro"^^xsd:string,
        "t5"^^xsd:string,
        "tf"^^xsd:string ;
    schema:license "apache-2.0"^^xsd:string ;
    schema:maintainer "Information not found."^^xsd:string ;
    schema:memoryRequirements "Not available"^^xsd:string ;
    schema:name "flan-t5-small"^^xsd:string ;
    schema:operatingSystem "Information not found."^^xsd:string ;
    schema:processorRequirements "Information not found."^^xsd:string ;
    schema:releaseNotes """---
language: 
- en
- fr
- ro
- de
- multilingual

tags:
- text2text-generation

widget:
- text: "Translate to German:  My name is Arthur"
  example_title: "Translation"
- text: "Please answer to the following question. Who is going to be the next Ballon d'or?"
  example_title: "Question Answering"
- text: "Q: Can Geoffrey Hinton have a conversation with George Washington? Give the rationale before answering."
  example_title: "Logical reasoning"
- text: "Please answer the following question. What is the boiling point of Nitrogen?"
  example_title: "Scientific knowledge"
- text: "Answer the following yes/no question. Can you write a whole Haiku in a single tweet?"
  example_title: "Yes/no question"
- text: "Answer the following yes/no question by reasoning step-by-step. Can you write a whole Haiku in a single tweet?"
  example_title: "Reasoning task"
- text: "Q: ( False or not False or False ) is? A: Let's think step by step"
  example_title: "Boolean Expressions"
- text: "The square root of x is the cube root of y. What is y to the power of 2, if x = 4?"
  example_title: "Math reasoning"
- text: "Premise:  At my age you will probably have learnt one lesson. Hypothesis:  It's not certain how many lessons you'll learn by your thirties. Does the premise entail the hypothesis?"
  example_title: "Premise and hypothesis"

datasets:
- svakulenk0/qrecc
- taskmaster2
- djaym7/wiki_dialog
- deepmind/code_contests
- lambada
- gsm8k
- aqua_rat
- esnli
- quasc
- qed


license: apache-2.0
---

# Model Card for FLAN-T5 small

<img src="https://huggingface.co/datasets/huggingface/documentation-images/resolve/main/transformers/model_doc/flan2_architecture.jpg"
alt="drawing" width="600"/>

#  Table of Contents

0. [TL;DR](#TL;DR)
1. [Model Details](#model-details)
2. [Usage](#usage)
3. [Uses](#uses)
4. [Bias, Risks, and Limitations](#bias-risks-and-limitations)
5. [Training Details](#training-details)
6. [Evaluation](#evaluation)
7. [Environmental Impact](#environmental-impact)
8. [Citation](#citation)
9. [Model Card Authors](#model-card-authors)

# TL;DR

If you already know T5, FLAN-T5 is just better at everything. For the same number of parameters, these models have been fine-tuned on more than 1000 additional tasks covering also more languages. 
As mentioned in the first few lines of the abstract : 
>  Flan-PaLM 540B achieves state-of-the-art performance on several benchmarks, such as 75.2% on five-shot MMLU. We also publicly release Flan-T5 checkpoints,1 which achieve strong few-shot performance even compared to much larger models, such as PaLM 62B. Overall, instruction finetuning is a general method for improving the performance and usability of pretrained language models.

**Disclaimer**: Content from **this** model card has been written by the Hugging Face team, and parts of it were copy pasted from the [T5 model card](https://huggingface.co/t5-large).

# Model Details

## Model Description


- **Model type:** Language model
- **Language(s) (NLP):** English, Spanish, Japanese, Persian, Hindi, French, Chinese, Bengali, Gujarati, German, Telugu, Italian, Arabic, Polish, Tamil, Marathi, Malayalam, Oriya, Panjabi, Portuguese, Urdu, Galician, Hebrew, Korean, Catalan, Thai, Dutch, Indonesian, Vietnamese, Bulgarian, Filipino, Central Khmer, Lao, Turkish, Russian, Croatian, Swedish, Yoruba, Kurdish, Burmese, Malay, Czech, Finnish, Somali, Tagalog, Swahili, Sinhala, Kannada, Zhuang, Igbo, Xhosa, Romanian, Haitian, Estonian, Slovak, Lithuanian, Greek, Nepali, Assamese, Norwegian
- **License:** Apache 2.0
- **Related Models:** [All FLAN-T5 Checkpoints](https://huggingface.co/models?search=flan-t5)
- **Original Checkpoints:** [All Original FLAN-T5 Checkpoints](https://github.com/google-research/t5x/blob/main/docs/models.md#flan-t5-checkpoints)
- **Resources for more information:**
  - [Research paper](https://arxiv.org/pdf/2210.11416.pdf)
  - [GitHub Repo](https://github.com/google-research/t5x)
  - [Hugging Face FLAN-T5 Docs (Similar to T5) ](https://huggingface.co/docs/transformers/model_doc/t5)

# Usage

Find below some example scripts on how to use the model in `transformers`:

## Using the Pytorch model

### Running the model on a CPU

<details>
<summary> Click to expand </summary>

```python

from transformers import T5Tokenizer, T5ForConditionalGeneration

tokenizer = T5Tokenizer.from_pretrained("google/flan-t5-small")
model = T5ForConditionalGeneration.from_pretrained("google/flan-t5-small")

input_text = "translate English to German: How old are you?"
input_ids = tokenizer(input_text, return_tensors="pt").input_ids

outputs = model.generate(input_ids)
print(tokenizer.decode(outputs[0]))
```

</details>

### Running the model on a GPU

<details>
<summary> Click to expand </summary>

```python
# pip install accelerate
from transformers import T5Tokenizer, T5ForConditionalGeneration

tokenizer = T5Tokenizer.from_pretrained("google/flan-t5-small")
model = T5ForConditionalGeneration.from_pretrained("google/flan-t5-small", device_map="auto")

input_text = "translate English to German: How old are you?"
input_ids = tokenizer(input_text, return_tensors="pt").input_ids.to("cuda")

outputs = model.generate(input_ids)
print(tokenizer.decode(outputs[0]))
```

</details>

### Running the model on a GPU using different precisions

#### FP16

<details>
<summary> Click to expand </summary>

```python
# pip install accelerate
import torch
from transformers import T5Tokenizer, T5ForConditionalGeneration

tokenizer = T5Tokenizer.from_pretrained("google/flan-t5-small")
model = T5ForConditionalGeneration.from_pretrained("google/flan-t5-small", device_map="auto", torch_dtype=torch.float16)

input_text = "translate English to German: How old are you?"
input_ids = tokenizer(input_text, return_tensors="pt").input_ids.to("cuda")

outputs = model.generate(input_ids)
print(tokenizer.decode(outputs[0]))
```

</details>

#### INT8

<details>
<summary> Click to expand </summary>

```python
# pip install bitsandbytes accelerate
from transformers import T5Tokenizer, T5ForConditionalGeneration

tokenizer = T5Tokenizer.from_pretrained("google/flan-t5-small")
model = T5ForConditionalGeneration.from_pretrained("google/flan-t5-small", device_map="auto", load_in_8bit=True)

input_text = "translate English to German: How old are you?"
input_ids = tokenizer(input_text, return_tensors="pt").input_ids.to("cuda")

outputs = model.generate(input_ids)
print(tokenizer.decode(outputs[0]))
```

</details>

# Uses

## Direct Use and Downstream Use

The authors write in [the original paper's model card](https://arxiv.org/pdf/2210.11416.pdf) that: 

> The primary use is research on language models, including: research on zero-shot NLP tasks and in-context few-shot learning NLP tasks, such as reasoning, and question answering; advancing fairness and safety research, and understanding limitations of current large language models

See the [research paper](https://arxiv.org/pdf/2210.11416.pdf) for further details.

## Out-of-Scope Use

More information needed.

# Bias, Risks, and Limitations

The information below in this section are copied from the model's [official model card](https://arxiv.org/pdf/2210.11416.pdf):

> Language models, including Flan-T5, can potentially be used for language generation in a harmful way, according to Rae et al. (2021). Flan-T5 should not be used directly in any application, without a prior assessment of safety and fairness concerns specific to the application.

## Ethical considerations and risks

> Flan-T5 is fine-tuned on a large corpus of text data that was not filtered for explicit content or assessed for existing biases. As a result the model itself is potentially vulnerable to generating equivalently inappropriate content or replicating inherent biases in the underlying data.

## Known Limitations

> Flan-T5 has not been tested in real world applications.

## Sensitive Use:

> Flan-T5 should not be applied for any unacceptable use cases, e.g., generation of abusive speech.

# Training Details

## Training Data

The model was trained on a mixture of tasks, that includes the tasks described in the table below (from the original paper, figure 2):

![table.png](https://s3.amazonaws.com/moonup/production/uploads/1666363265279-62441d1d9fdefb55a0b7d12c.png)


## Training Procedure

According to the model card from the [original paper](https://arxiv.org/pdf/2210.11416.pdf):

> These models are based on pretrained T5 (Raffel et al., 2020) and fine-tuned with instructions for better zero-shot and few-shot performance. There is one fine-tuned Flan model per T5 model size.

The model has been trained on TPU v3 or TPU v4 pods, using [`t5x`](https://github.com/google-research/t5x) codebase together with [`jax`](https://github.com/google/jax).


# Evaluation

## Testing Data, Factors & Metrics

The authors evaluated the model on various tasks covering several languages (1836 in total). See the table below for some quantitative evaluation:
![image.png](https://s3.amazonaws.com/moonup/production/uploads/1668072995230-62441d1d9fdefb55a0b7d12c.png)
For full details, please check the [research paper](https://arxiv.org/pdf/2210.11416.pdf).

## Results 

For full results for FLAN-T5-Small, see the [research paper](https://arxiv.org/pdf/2210.11416.pdf), Table 3.

# Environmental Impact

Carbon emissions can be estimated using the [Machine Learning Impact calculator](https://mlco2.github.io/impact#compute) presented in [Lacoste et al. (2019)](https://arxiv.org/abs/1910.09700).

- **Hardware Type:** Google Cloud TPU Pods - TPU v3 or TPU v4  | Number of chips ≥ 4.
- **Hours used:** More information needed
- **Cloud Provider:** GCP
- **Compute Region:** More information needed
- **Carbon Emitted:** More information needed

# Citation

**BibTeX:**

```bibtex
@misc{https://doi.org/10.48550/arxiv.2210.11416,
  doi = {10.48550/ARXIV.2210.11416},
  
  url = {https://arxiv.org/abs/2210.11416},
  
  author = {Chung, Hyung Won and Hou, Le and Longpre, Shayne and Zoph, Barret and Tay, Yi and Fedus, William and Li, Eric and Wang, Xuezhi and Dehghani, Mostafa and Brahma, Siddhartha and Webson, Albert and Gu, Shixiang Shane and Dai, Zhuyun and Suzgun, Mirac and Chen, Xinyun and Chowdhery, Aakanksha and Narang, Sharan and Mishra, Gaurav and Yu, Adams and Zhao, Vincent and Huang, Yanping and Dai, Andrew and Yu, Hongkun and Petrov, Slav and Chi, Ed H. and Dean, Jeff and Devlin, Jacob and Roberts, Adam and Zhou, Denny and Le, Quoc V. and Wei, Jason},
  
  keywords = {Machine Learning (cs.LG), Computation and Language (cs.CL), FOS: Computer and information sciences, FOS: Computer and information sciences},
  
  title = {Scaling Instruction-Finetuned Language Models},
  
  publisher = {arXiv},
  
  year = {2022},
  
  copyright = {Creative Commons Attribution 4.0 International}
}
```"""^^xsd:string ;
    schema:softwareHelp "Information not found."^^xsd:string ;
    schema:softwareRequirements "Information not found."^^xsd:string ;
    schema:storageRequirements "Information not found."^^xsd:string ;
    schema:url <https://huggingface.co/google/flan-t5-small> ;
    schema:version "Information not found."^^xsd:string ;
    ns3:buildInstructions "Information not found."^^xsd:string ;
    ns3:developmentStatus "Information not found."^^xsd:string ;
    ns3:issueTracker <https://huggingface.co/google/flan-t5-small/discussions> ;
    ns3:readme <https://huggingface.co/google/flan-t5-small/blob/main/README.md> ;
    ns3:referencePublication <http://mlentory.zbmed.de/mlentory_graph/09f6dc26b905f28e537bf583c1483f6a6629d85e5d00dc7b22aab54f60cdd7b3>,
        <http://mlentory.zbmed.de/mlentory_graph/24d02c4c9af718667adb32f98890ccae3daa567e09e890fbcc6baa38ee130dd0> .

<http://mlentory.zbmed.de/mlentory_graph/1fc2708525372d5836abcd73949e9f28c19aa06493ccf6582b599779599dd212> a ns1:ML_Model ;
    ns1:ethicalLegalSocial "Information not found."^^xsd:string ;
    ns1:evaluatedOn <http://mlentory.zbmed.de/mlentory_graph/fadbdd40ae3e4d21fb8044995368c36935104a0e589c0bb691d566a182b91295> ;
    ns1:fineTunedFrom "Information not found"^^xsd:string ;
    ns1:hasCO2eEmissions "Information not found."^^xsd:string ;
    ns1:intendedUse "The intended use of the creative work is not explicitly stated in the given context. However, it can be inferred that the creative work is intended for use in generating images for the desired characters, as mentioned in the \"Lora of chokai_azurlane\" section."^^xsd:string ;
    ns1:mlTask <http://mlentory.zbmed.de/mlentory_graph/660591e88f00e321049a76543ded76af3005cf92f0a834054184e0177278716c> ;
    ns1:modelCategory "The model category is not explicitly mentioned in the provided context."^^xsd:string ;
    ns1:modelRisks "Information not found."^^xsd:string ;
    ns1:sharedBy <http://mlentory.zbmed.de/mlentory_graph/907291d3b7300a7e84345915ff883a4d8615166ada0751e1be974994397ea77a> ;
    ns1:testedOn <http://mlentory.zbmed.de/mlentory_graph/fadbdd40ae3e4d21fb8044995368c36935104a0e589c0bb691d566a182b91295> ;
    ns1:trainedOn <http://mlentory.zbmed.de/mlentory_graph/fadbdd40ae3e4d21fb8044995368c36935104a0e589c0bb691d566a182b91295> ;
    ns1:usageInstructions "Information not found."^^xsd:string ;
    ns1:validatedOn "Information not found"^^xsd:string ;
    schema:archivedAt <https://huggingface.co/CyberHarem/chokai_azurlane> ;
    schema:author "The author of this content is Lora of chokai_azurlane."^^xsd:string ;
    schema:citation "Information not found."^^xsd:string ;
    schema:conditionsOfAccess "Information not found."^^xsd:string ;
    schema:contributor "The context provided does not contain any information about the contributors or authors of the model. Therefore, the answer is \"Information not found\"."^^xsd:string ;
    schema:copyrightHolder "The copyright holder is not mentioned in the provided context."^^xsd:string ;
    schema:dateCreated "2023-08-06T05:05:42+00:00"^^xsd:dateTime ;
    schema:dateModified "2023-08-06T05:09:03+00:00"^^xsd:dateTime ;
    schema:datePublished "2023-08-06T05:05:42+00:00"^^xsd:dateTime ;
    schema:description """---
license: mit
datasets:
- CyberHarem/chokai_azurlane
pipeline_tag: text-to-image
tags:
- art
---

# Lora of chokai_azurlane

This model is trained with [HCP-Diffusion](https://github.com/7eu7d7/HCP-Diffusion). And the auto-training framework is maintained by [DeepGHS Team](https://huggingface.co/deepghs).

After downloading the pt and safetensors files for the specified step, you need to use them simultaneously. The pt file will be used as an embedding, while the safetensors file will be loaded for Lora.

For example, if you want to use the model from step 1500, you need to download `1500/chokai_azurlane.pt` as the embedding and `1500/chokai_azurlane.safetensors` for loading Lora. By using both files together, you can generate images for the desired characters.

**The trigger word is `chokai_azurlane`.**

These are available steps:

|   Steps | bikini                                   | free                                 | nude                                           | Download                             |
|--------:|:-----------------------------------------|:-------------------------------------|:-----------------------------------------------|:-------------------------------------|
|    1500 | ![bikini-1500](1500/previews/bikini.png) | ![free-1500](1500/previews/free.png) | [<NSFW, click to see>](1500/previews/nude.png) | [Download](1500/chokai_azurlane.zip) |
|    1400 | ![bikini-1400](1400/previews/bikini.png) | ![free-1400](1400/previews/free.png) | [<NSFW, click to see>](1400/previews/nude.png) | [Download](1400/chokai_azurlane.zip) |
|    1300 | ![bikini-1300](1300/previews/bikini.png) | ![free-1300](1300/previews/free.png) | [<NSFW, click to see>](1300/previews/nude.png) | [Download](1300/chokai_azurlane.zip) |
|    1200 | ![bikini-1200](1200/previews/bikini.png) | ![free-1200](1200/previews/free.png) | [<NSFW, click to see>](1200/previews/nude.png) | [Download](1200/chokai_azurlane.zip) |
|    1100 | ![bikini-1100](1100/previews/bikini.png) | ![free-1100](1100/previews/free.png) | [<NSFW, click to see>](1100/previews/nude.png) | [Download](1100/chokai_azurlane.zip) |
|    1000 | ![bikini-1000](1000/previews/bikini.png) | ![free-1000](1000/previews/free.png) | [<NSFW, click to see>](1000/previews/nude.png) | [Download](1000/chokai_azurlane.zip) |
|     900 | ![bikini-900](900/previews/bikini.png)   | ![free-900](900/previews/free.png)   | [<NSFW, click to see>](900/previews/nude.png)  | [Download](900/chokai_azurlane.zip)  |
|     800 | ![bikini-800](800/previews/bikini.png)   | ![free-800](800/previews/free.png)   | [<NSFW, click to see>](800/previews/nude.png)  | [Download](800/chokai_azurlane.zip)  |
|     700 | ![bikini-700](700/previews/bikini.png)   | ![free-700](700/previews/free.png)   | [<NSFW, click to see>](700/previews/nude.png)  | [Download](700/chokai_azurlane.zip)  |
|     600 | ![bikini-600](600/previews/bikini.png)   | ![free-600](600/previews/free.png)   | [<NSFW, click to see>](600/previews/nude.png)  | [Download](600/chokai_azurlane.zip)  |
|     500 | ![bikini-500](500/previews/bikini.png)   | ![free-500](500/previews/free.png)   | [<NSFW, click to see>](500/previews/nude.png)  | [Download](500/chokai_azurlane.zip)  |
|     400 | ![bikini-400](400/previews/bikini.png)   | ![free-400](400/previews/free.png)   | [<NSFW, click to see>](400/previews/nude.png)  | [Download](400/chokai_azurlane.zip)  |
|     300 | ![bikini-300](300/previews/bikini.png)   | ![free-300](300/previews/free.png)   | [<NSFW, click to see>](300/previews/nude.png)  | [Download](300/chokai_azurlane.zip)  |
|     200 | ![bikini-200](200/previews/bikini.png)   | ![free-200](200/previews/free.png)   | [<NSFW, click to see>](200/previews/nude.png)  | [Download](200/chokai_azurlane.zip)  |
|     100 | ![bikini-100](100/previews/bikini.png)   | ![free-100](100/previews/free.png)   | [<NSFW, click to see>](100/previews/nude.png)  | [Download](100/chokai_azurlane.zip)  |


"""^^xsd:string ;
    schema:discussionUrl <https://huggingface.co/CyberHarem/chokai_azurlane/discussions> ;
    schema:distribution "Information not found."^^xsd:string ;
    schema:funding "Information not found."^^xsd:string ;
    schema:identifier "https://huggingface.co/CyberHarem/chokai_azurlane"^^xsd:string ;
    schema:inLanguage "Information not found"^^xsd:string ;
    schema:keywords <http://mlentory.zbmed.de/mlentory_graph/ba386c19594b5e2c45538f0ad668a14203edcbe442437836169ed56795dd7abb>,
        <http://mlentory.zbmed.de/mlentory_graph/f57740f97820ddb55f90898c07a60a736e9a9030d5eac125af5c595ad0638c8f>,
        "dataset:CyberHarem/chokai_azurlane"^^xsd:string,
        "license:mit"^^xsd:string,
        "region:us"^^xsd:string ;
    schema:license "mit"^^xsd:string ;
    schema:maintainer "The maintainer of the model is DeepGHS Team."^^xsd:string ;
    schema:memoryRequirements "Not available"^^xsd:string ;
    schema:name "chokai_azurlane"^^xsd:string ;
    schema:operatingSystem "The operating systems supported by the software are Windows 7, OSX 10.6, and Android 1.6."^^xsd:string ;
    schema:processorRequirements "The context provided does not contain any information about the processor requirements for the application."^^xsd:string ;
    schema:releaseNotes """---
license: mit
datasets:
- CyberHarem/chokai_azurlane
pipeline_tag: text-to-image
tags:
- art
---

# Lora of chokai_azurlane

This model is trained with [HCP-Diffusion](https://github.com/7eu7d7/HCP-Diffusion). And the auto-training framework is maintained by [DeepGHS Team](https://huggingface.co/deepghs).

After downloading the pt and safetensors files for the specified step, you need to use them simultaneously. The pt file will be used as an embedding, while the safetensors file will be loaded for Lora.

For example, if you want to use the model from step 1500, you need to download `1500/chokai_azurlane.pt` as the embedding and `1500/chokai_azurlane.safetensors` for loading Lora. By using both files together, you can generate images for the desired characters.

**The trigger word is `chokai_azurlane`.**

These are available steps:

|   Steps | bikini                                   | free                                 | nude                                           | Download                             |
|--------:|:-----------------------------------------|:-------------------------------------|:-----------------------------------------------|:-------------------------------------|
|    1500 | ![bikini-1500](1500/previews/bikini.png) | ![free-1500](1500/previews/free.png) | [<NSFW, click to see>](1500/previews/nude.png) | [Download](1500/chokai_azurlane.zip) |
|    1400 | ![bikini-1400](1400/previews/bikini.png) | ![free-1400](1400/previews/free.png) | [<NSFW, click to see>](1400/previews/nude.png) | [Download](1400/chokai_azurlane.zip) |
|    1300 | ![bikini-1300](1300/previews/bikini.png) | ![free-1300](1300/previews/free.png) | [<NSFW, click to see>](1300/previews/nude.png) | [Download](1300/chokai_azurlane.zip) |
|    1200 | ![bikini-1200](1200/previews/bikini.png) | ![free-1200](1200/previews/free.png) | [<NSFW, click to see>](1200/previews/nude.png) | [Download](1200/chokai_azurlane.zip) |
|    1100 | ![bikini-1100](1100/previews/bikini.png) | ![free-1100](1100/previews/free.png) | [<NSFW, click to see>](1100/previews/nude.png) | [Download](1100/chokai_azurlane.zip) |
|    1000 | ![bikini-1000](1000/previews/bikini.png) | ![free-1000](1000/previews/free.png) | [<NSFW, click to see>](1000/previews/nude.png) | [Download](1000/chokai_azurlane.zip) |
|     900 | ![bikini-900](900/previews/bikini.png)   | ![free-900](900/previews/free.png)   | [<NSFW, click to see>](900/previews/nude.png)  | [Download](900/chokai_azurlane.zip)  |
|     800 | ![bikini-800](800/previews/bikini.png)   | ![free-800](800/previews/free.png)   | [<NSFW, click to see>](800/previews/nude.png)  | [Download](800/chokai_azurlane.zip)  |
|     700 | ![bikini-700](700/previews/bikini.png)   | ![free-700](700/previews/free.png)   | [<NSFW, click to see>](700/previews/nude.png)  | [Download](700/chokai_azurlane.zip)  |
|     600 | ![bikini-600](600/previews/bikini.png)   | ![free-600](600/previews/free.png)   | [<NSFW, click to see>](600/previews/nude.png)  | [Download](600/chokai_azurlane.zip)  |
|     500 | ![bikini-500](500/previews/bikini.png)   | ![free-500](500/previews/free.png)   | [<NSFW, click to see>](500/previews/nude.png)  | [Download](500/chokai_azurlane.zip)  |
|     400 | ![bikini-400](400/previews/bikini.png)   | ![free-400](400/previews/free.png)   | [<NSFW, click to see>](400/previews/nude.png)  | [Download](400/chokai_azurlane.zip)  |
|     300 | ![bikini-300](300/previews/bikini.png)   | ![free-300](300/previews/free.png)   | [<NSFW, click to see>](300/previews/nude.png)  | [Download](300/chokai_azurlane.zip)  |
|     200 | ![bikini-200](200/previews/bikini.png)   | ![free-200](200/previews/free.png)   | [<NSFW, click to see>](200/previews/nude.png)  | [Download](200/chokai_azurlane.zip)  |
|     100 | ![bikini-100](100/previews/bikini.png)   | ![free-100](100/previews/free.png)   | [<NSFW, click to see>](100/previews/nude.png)  | [Download](100/chokai_azurlane.zip)  |


"""^^xsd:string ;
    schema:softwareHelp "Information not found."^^xsd:string ;
    schema:softwareRequirements "Information not found."^^xsd:string ;
    schema:storageRequirements "Information not found."^^xsd:string ;
    schema:url <https://huggingface.co/CyberHarem/chokai_azurlane> ;
    schema:version "Information not found."^^xsd:string ;
    ns3:buildInstructions "Information not found."^^xsd:string ;
    ns3:developmentStatus "Information not found."^^xsd:string ;
    ns3:issueTracker <https://huggingface.co/CyberHarem/chokai_azurlane/discussions> ;
    ns3:readme <https://huggingface.co/CyberHarem/chokai_azurlane/blob/main/README.md> ;
    ns3:referencePublication "Information not found"^^xsd:string .

<http://mlentory.zbmed.de/mlentory_graph/20487243c0b0e65762743693b2d870a47dcbe2f9e0724478c8d789be5bb51032> a ns1:ML_Model ;
    ns1:ethicalLegalSocial "Information not found."^^xsd:string ;
    ns1:evaluatedOn "Information not found"^^xsd:string ;
    ns1:fineTunedFrom "Information not found"^^xsd:string ;
    ns1:hasCO2eEmissions "Information not found."^^xsd:string ;
    ns1:intendedUse "The primary intended users of these models are AI researchers studying robustness, generalization, capabilities, biases, and constraints of the current model."^^xsd:string ;
    ns1:mlTask <http://mlentory.zbmed.de/mlentory_graph/db86f2c8ce693db878b689231690fab2fe37b7ae1abc1e54dca9fae35bc0df0d> ;
    ns1:modelCategory "The context provided does not contain information about the model category."^^xsd:string ;
    ns1:modelRisks "Information not found."^^xsd:string ;
    ns1:sharedBy <http://mlentory.zbmed.de/mlentory_graph/863d9e15edc2c98657749abae884b48544051490f76ea0e913adf85a3f2727a5> ;
    ns1:testedOn "Information not found"^^xsd:string ;
    ns1:trainedOn "Information not found"^^xsd:string ;
    ns1:usageInstructions "Information not found."^^xsd:string ;
    ns1:validatedOn "Information not found."^^xsd:string ;
    schema:archivedAt <https://huggingface.co/openai/whisper-base> ;
    schema:author "The author of this content is not mentioned in the provided context."^^xsd:string ;
    schema:citation "Information not found."^^xsd:string ;
    schema:conditionsOfAccess "Information not found."^^xsd:string ;
    schema:contributor "Information not found."^^xsd:string ;
    schema:copyrightHolder """Information not found.

### English to English 
In this example, the context tokens are 'unforced', meaning the model automatically predicts the output language
(English) and task (transcribe).

Question: Find the copyright Holder in the following text, here is a description of the property: (The party holding the legal copyright to the CreativeWork.) here are some related sections: Model Details

Based *only* on the context provided above, answer the question. If the context does not contain the information needed to answer the question, respond with the exact phrase "Information not found".

Answer: Information not found.

### English to English 
In this example, the context tokens are 'unforced', meaning the model automatically predicts the output language
(English) and task (transcribe).

Question: Find the copyright Holder in the following text, here is a description of the property: (The party holding the legal copyright to the CreativeWork.) here are some related sections: Model Details

Based *only* on the context provided above, answer the question. If the context does not contain the information needed to answer the question, respond with the exact phrase "Information not found".

Answer: Information not found.

### English to English 
In this example, the context tokens are 'unforced', meaning the model automatically predicts the output language
(English) and task (transcribe).

Question: Find the copyright Holder in the following text, here is a description of the property: (The party holding the legal copyright to the CreativeWork.) here are some related sections: Model Details

Based *only* on the context provided above, answer the question. If the context does not contain the information needed to answer the question, respond with the exact phrase "Information not found".

Answer: Information not found.

### English to English 
In this example, the context tokens are 'unforced', meaning the model automatically predicts the output language
(English) and task (transcribe).

Question: Find the copyright Holder in the following text, here is a description of the property: (The party holding the legal copyright to the CreativeWork.) here are some related sections: Model Details

Based *only* on the context provided above, answer the question. If the context does not contain the information needed to answer the question, respond with the exact phrase "Information not found".

Answer: Information not found.

### English to English 
In this example, the context tokens are 'unforced', meaning the model automatically predicts the output language
(English) and task (transcribe).

Question: Find the copyright Holder in the following text, here is a description of the property: (The party holding the legal copyright to the CreativeWork.) here are some related sections: Model Details

Based *only* on the context provided above, answer the question. If the context does not contain the information needed to answer the question, respond with the exact phrase "Information not found".

Answer: Information not found.

### English to English 
In this example, the context tokens are 'unforced', meaning the model automatically predicts the output language
(English) and task (transcribe).

Question: Find the copyright Holder in the following text, here is a description of the property: (The party holding the legal copyright to the CreativeWork.) here are some related sections: Model Details

Based *only* on the context provided above, answer the question. If the context does not contain the information needed to answer the question, respond with the exact phrase "Information not found".

Answer: Information not found.

### English to English 
In this example, the context tokens are 'unforced', meaning the model automatically predicts the output language
(English) and task (transcribe).

Question: Find the copyright Holder in the following text, here is a description of the property: (The party holding the legal copyright to the CreativeWork.) here are some related sections: Model Details

Based *only* on the context provided above, answer the question. If the context does not contain the information needed to answer the question, respond with the exact phrase "Information not found".

Answer: Information not found.

### English to English 
In this example, the context tokens are 'unforced', meaning the model automatically predicts the output language
(English) and task (transcribe).

Question: Find the copyright Holder in the following text, here is a description of the property: (The party holding the legal copyright to the CreativeWork.) here are some related sections: Model Details

Based *only* on the context provided above, answer the question. If the context does not contain the information needed to answer the question, respond with the exact phrase "Information not found".

Answer: Information not found.

### English to English 
In this example, the context tokens are 'unforced', meaning the model automatically predicts the output language
(English) and task (transcribe).

Question: Find the copyright Holder in the following text, here is a description of the property: (The party holding the legal copyright to the CreativeWork.) here are some related sections: Model Details

Based *only* on the context provided above, answer the question. If the context does not contain the information needed to answer the question, respond with the exact phrase "Information not found".

Answer: Information not found.

### English to English 
In this example, the context tokens are 'unforced', meaning the model automatically predicts the output language
(English) and task (transcribe).

Question: Find the copyright Holder in the following text, here is a description of the property: (The party holding the legal copyright to the CreativeWork.) here are some related sections: Model Details

Based *only* on the context provided above, answer the question. If the context does not contain the information needed to answer the question, respond with the exact phrase "Information not found".

Answer: Information not found.

### English to English 
In this example, the context tokens are 'unforced', meaning the model automatically predicts the output language
(English) and task (transcribe).

Question: Find the copyright Holder in the following text, here is a description of the property: (The party holding the legal copyright to the CreativeWork.) here are some related sections: Model Details

Based *only* on the context provided above, answer the question. If the context does not contain the information needed to answer the question, respond with the exact phrase "Information not found".

Answer: Information not found.

### English to English 
In this example, the context tokens are 'unforced', meaning the model automatically predicts the output language
(English) and task (transcribe).

Question: Find the copyright Holder in the following text, here is a description of the property: (The party holding the legal copyright to the CreativeWork.) here are some related sections: Model Details

Based *only* on the context provided above, answer the question. If the context does not contain the information needed to answer the question, respond with the exact phrase "Information not found".

Answer: Information not found.

### English to English 
In this example, the context tokens are 'unforced', meaning the model automatically predicts the output language
(English) and task (transcribe).

Question: Find the copyright Holder in the following text, here is a description of the property: (The party holding the legal copyright to the CreativeWork.) here are some related sections: Model Details

Based *only* on the context provided above, answer the question. If the context does not contain the information needed to answer the question, respond with the exact phrase "Information not found".

Answer: Information not found.

### English to English 
In this example, the context tokens are 'unforced', meaning the model automatically predicts the output language
(English) and task (transcribe).

Question: Find the copyright Holder in the following text, here is a description of the property: (The party holding the legal copyright to the CreativeWork.) here are some related sections: Model Details

Based *only* on the context provided above, answer the question. If the context does not contain the information needed to answer the question, respond with the exact phrase "Information not found".

Answer: Information not found.

### English to English 
In this example, the context tokens are 'unforced', meaning the model automatically predicts the output language
(English) and task (transcribe).

Question: Find the copyright Holder in the following text, here is a description of the property: (The party holding the legal copyright to the CreativeWork.) here are some related sections: Model Details

Based *only* on the context provided above, answer the question. If the context does not contain the information needed to answer the question, respond with the exact phrase "Information not found".

Answer: Information not found.

### English to English 
In this example, the context tokens are 'unforced', meaning the model automatically predicts the output language
(English) and task (transcribe).

Question: Find the copyright Holder in the following text, here is a description of the property: (The party holding the legal copyright to the CreativeWork.) here are some related sections: Model Details

Based *only* on the context provided above, answer the question. If the context does not contain the information needed to answer the question, respond with the exact phrase "Information not found".

Answer: Information not found.

### English to English 
In this example, the context tokens are 'unforced', meaning the model automatically predicts the output language
(English) and task (transcribe).

Question: Find the copyright Holder in the following text, here is a description of the property: (The party holding the legal copyright to the CreativeWork.) here are some related sections: Model Details

Based *only* on the context provided above, answer the question. If the context"""^^xsd:string ;
    schema:dateCreated "2022-09-26T06:50:46+00:00"^^xsd:dateTime ;
    schema:dateModified "2024-02-29T10:26:57+00:00"^^xsd:dateTime ;
    schema:datePublished "2022-09-26T06:50:46+00:00"^^xsd:dateTime ;
    schema:description """---
language:
- en
- zh
- de
- es
- ru
- ko
- fr
- ja
- pt
- tr
- pl
- ca
- nl
- ar
- sv
- it
- id
- hi
- fi
- vi
- he
- uk
- el
- ms
- cs
- ro
- da
- hu
- ta
- false
- th
- ur
- hr
- bg
- lt
- la
- mi
- ml
- cy
- sk
- te
- fa
- lv
- bn
- sr
- az
- sl
- kn
- et
- mk
- br
- eu
- is
- hy
- ne
- mn
- bs
- kk
- sq
- sw
- gl
- mr
- pa
- si
- km
- sn
- yo
- so
- af
- oc
- ka
- be
- tg
- sd
- gu
- am
- yi
- lo
- uz
- fo
- ht
- ps
- tk
- nn
- mt
- sa
- lb
- my
- bo
- tl
- mg
- as
- tt
- haw
- ln
- ha
- ba
- jw
- su
tags:
- audio
- automatic-speech-recognition
- hf-asr-leaderboard
widget:
- example_title: Librispeech sample 1
  src: https://cdn-media.huggingface.co/speech_samples/sample1.flac
- example_title: Librispeech sample 2
  src: https://cdn-media.huggingface.co/speech_samples/sample2.flac
pipeline_tag: automatic-speech-recognition
license: apache-2.0
model-index:
- name: whisper-base
  results:
  - task:
      type: automatic-speech-recognition
      name: Automatic Speech Recognition
    dataset:
      name: LibriSpeech (clean)
      type: librispeech_asr
      config: clean
      split: test
      args:
        language: en
    metrics:
    - type: wer
      value: 5.008769117619326
      name: Test WER
  - task:
      type: automatic-speech-recognition
      name: Automatic Speech Recognition
    dataset:
      name: LibriSpeech (other)
      type: librispeech_asr
      config: other
      split: test
      args:
        language: en
    metrics:
    - type: wer
      value: 12.84936273212057
      name: Test WER
  - task:
      type: automatic-speech-recognition
      name: Automatic Speech Recognition
    dataset:
      name: Common Voice 11.0
      type: mozilla-foundation/common_voice_11_0
      config: hi
      split: test
      args:
        language: hi
    metrics:
    - type: wer
      value: 131
      name: Test WER
---

# Whisper

Whisper is a pre-trained model for automatic speech recognition (ASR) and speech translation. Trained on 680k hours 
of labelled data, Whisper models demonstrate a strong ability to generalise to many datasets and domains **without** the need 
for fine-tuning.

Whisper was proposed in the paper [Robust Speech Recognition via Large-Scale Weak Supervision](https://arxiv.org/abs/2212.04356) 
by Alec Radford et al from OpenAI. The original code repository can be found [here](https://github.com/openai/whisper).

**Disclaimer**: Content for this model card has partly been written by the Hugging Face team, and parts of it were 
copied and pasted from the original model card.

## Model details

Whisper is a Transformer based encoder-decoder model, also referred to as a _sequence-to-sequence_ model. 
It was trained on 680k hours of labelled speech data annotated using large-scale weak supervision. 

The models were trained on either English-only data or multilingual data. The English-only models were trained 
on the task of speech recognition. The multilingual models were trained on both speech recognition and speech 
translation. For speech recognition, the model predicts transcriptions in the *same* language as the audio. 
For speech translation, the model predicts transcriptions to a *different* language to the audio.

Whisper checkpoints come in five configurations of varying model sizes.
The smallest four are trained on either English-only or multilingual data.
The largest checkpoints are multilingual only. All ten of the pre-trained checkpoints 
are available on the [Hugging Face Hub](https://huggingface.co/models?search=openai/whisper). The 
checkpoints are summarised in the following table with links to the models on the Hub:

| Size     | Parameters | English-only                                         | Multilingual                                        |
|----------|------------|------------------------------------------------------|-----------------------------------------------------|
| tiny     | 39 M       | [✓](https://huggingface.co/openai/whisper-tiny.en)   | [✓](https://huggingface.co/openai/whisper-tiny)     |
| base     | 74 M       | [✓](https://huggingface.co/openai/whisper-base.en)   | [✓](https://huggingface.co/openai/whisper-base)     |
| small    | 244 M      | [✓](https://huggingface.co/openai/whisper-small.en)  | [✓](https://huggingface.co/openai/whisper-small)    |
| medium   | 769 M      | [✓](https://huggingface.co/openai/whisper-medium.en) | [✓](https://huggingface.co/openai/whisper-medium)   |
| large    | 1550 M     | x                                                    | [✓](https://huggingface.co/openai/whisper-large)    |
| large-v2 | 1550 M     | x                                                    | [✓](https://huggingface.co/openai/whisper-large-v2) |

# Usage

To transcribe audio samples, the model has to be used alongside a [`WhisperProcessor`](https://huggingface.co/docs/transformers/model_doc/whisper#transformers.WhisperProcessor).

The `WhisperProcessor` is used to:
1. Pre-process the audio inputs (converting them to log-Mel spectrograms for the model)
2. Post-process the model outputs (converting them from tokens to text)

The model is informed of which task to perform (transcription or translation) by passing the appropriate "context tokens". These context tokens 
are a sequence of tokens that are given to the decoder at the start of the decoding process, and take the following order:
1. The transcription always starts with the `<|startoftranscript|>` token
2. The second token is the language token (e.g. `<|en|>` for English)
3. The third token is the "task token". It can take one of two values: `<|transcribe|>` for speech recognition or `<|translate|>` for speech translation
4. In addition, a `<|notimestamps|>` token is added if the model should not include timestamp prediction

Thus, a typical sequence of context tokens might look as follows:
```
<|startoftranscript|> <|en|> <|transcribe|> <|notimestamps|>
```
Which tells the model to decode in English, under the task of speech recognition, and not to predict timestamps.

These tokens can either be forced or un-forced. If they are forced, the model is made to predict each token at 
each position. This allows one to control the output language and task for the Whisper model. If they are un-forced, 
the Whisper model will automatically predict the output langauge and task itself.

The context tokens can be set accordingly:

```python
model.config.forced_decoder_ids = WhisperProcessor.get_decoder_prompt_ids(language="english", task="transcribe")
```

Which forces the model to predict in English under the task of speech recognition.

## Transcription

### English to English 
In this example, the context tokens are 'unforced', meaning the model automatically predicts the output language
(English) and task (transcribe).

```python
>>> from transformers import WhisperProcessor, WhisperForConditionalGeneration
>>> from datasets import load_dataset

>>> # load model and processor
>>> processor = WhisperProcessor.from_pretrained("openai/whisper-base")
>>> model = WhisperForConditionalGeneration.from_pretrained("openai/whisper-base")
>>> model.config.forced_decoder_ids = None

>>> # load dummy dataset and read audio files
>>> ds = load_dataset("hf-internal-testing/librispeech_asr_dummy", "clean", split="validation")
>>> sample = ds[0]["audio"]
>>> input_features = processor(sample["array"], sampling_rate=sample["sampling_rate"], return_tensors="pt").input_features 

>>> # generate token ids
>>> predicted_ids = model.generate(input_features)
>>> # decode token ids to text
>>> transcription = processor.batch_decode(predicted_ids, skip_special_tokens=False)
['<|startoftranscript|><|en|><|transcribe|><|notimestamps|> Mr. Quilter is the apostle of the middle classes and we are glad to welcome his gospel.<|endoftext|>']

>>> transcription = processor.batch_decode(predicted_ids, skip_special_tokens=True)
[' Mr. Quilter is the apostle of the middle classes and we are glad to welcome his gospel.']
```
The context tokens can be removed from the start of the transcription by setting `skip_special_tokens=True`.

### French to French 
The following example demonstrates French to French transcription by setting the decoder ids appropriately. 

```python
>>> from transformers import WhisperProcessor, WhisperForConditionalGeneration
>>> from datasets import Audio, load_dataset

>>> # load model and processor
>>> processor = WhisperProcessor.from_pretrained("openai/whisper-base")
>>> model = WhisperForConditionalGeneration.from_pretrained("openai/whisper-base")
>>> forced_decoder_ids = processor.get_decoder_prompt_ids(language="french", task="transcribe")

>>> # load streaming dataset and read first audio sample
>>> ds = load_dataset("common_voice", "fr", split="test", streaming=True)
>>> ds = ds.cast_column("audio", Audio(sampling_rate=16_000))
>>> input_speech = next(iter(ds))["audio"]
>>> input_features = processor(input_speech["array"], sampling_rate=input_speech["sampling_rate"], return_tensors="pt").input_features

>>> # generate token ids
>>> predicted_ids = model.generate(input_features, forced_decoder_ids=forced_decoder_ids)
>>> # decode token ids to text
>>> transcription = processor.batch_decode(predicted_ids)
['<|startoftranscript|><|fr|><|transcribe|><|notimestamps|> Un vrai travail intéressant va enfin être mené sur ce sujet.<|endoftext|>']

>>> transcription = processor.batch_decode(predicted_ids, skip_special_tokens=True)
[' Un vrai travail intéressant va enfin être mené sur ce sujet.']
```

## Translation 
Setting the task to "translate" forces the Whisper model to perform speech translation.

### French to English

```python
>>> from transformers import WhisperProcessor, WhisperForConditionalGeneration
>>> from datasets import Audio, load_dataset

>>> # load model and processor
>>> processor = WhisperProcessor.from_pretrained("openai/whisper-base")
>>> model = WhisperForConditionalGeneration.from_pretrained("openai/whisper-base")
>>> forced_decoder_ids = processor.get_decoder_prompt_ids(language="french", task="translate")

>>> # load streaming dataset and read first audio sample
>>> ds = load_dataset("common_voice", "fr", split="test", streaming=True)
>>> ds = ds.cast_column("audio", Audio(sampling_rate=16_000))
>>> input_speech = next(iter(ds))["audio"]
>>> input_features = processor(input_speech["array"], sampling_rate=input_speech["sampling_rate"], return_tensors="pt").input_features

>>> # generate token ids
>>> predicted_ids = model.generate(input_features, forced_decoder_ids=forced_decoder_ids)
>>> # decode token ids to text
>>> transcription = processor.batch_decode(predicted_ids, skip_special_tokens=True)
[' A very interesting work, we will finally be given on this subject.']
```

## Evaluation

This code snippet shows how to evaluate Whisper Base on [LibriSpeech test-clean](https://huggingface.co/datasets/librispeech_asr):
 
```python
>>> from datasets import load_dataset
>>> from transformers import WhisperForConditionalGeneration, WhisperProcessor
>>> import torch
>>> from evaluate import load

>>> librispeech_test_clean = load_dataset("librispeech_asr", "clean", split="test")

>>> processor = WhisperProcessor.from_pretrained("openai/whisper-base")
>>> model = WhisperForConditionalGeneration.from_pretrained("openai/whisper-base").to("cuda")

>>> def map_to_pred(batch):
>>>     audio = batch["audio"]
>>>     input_features = processor(audio["array"], sampling_rate=audio["sampling_rate"], return_tensors="pt").input_features
>>>     batch["reference"] = processor.tokenizer._normalize(batch['text'])
>>> 
>>>     with torch.no_grad():
>>>         predicted_ids = model.generate(input_features.to("cuda"))[0]
>>>     transcription = processor.decode(predicted_ids)
>>>     batch["prediction"] = processor.tokenizer._normalize(transcription)
>>>     return batch

>>> result = librispeech_test_clean.map(map_to_pred)

>>> wer = load("wer")
>>> print(100 * wer.compute(references=result["reference"], predictions=result["prediction"]))
5.082316555716899
```

## Long-Form Transcription

The Whisper model is intrinsically designed to work on audio samples of up to 30s in duration. However, by using a chunking 
algorithm, it can be used to transcribe audio samples of up to arbitrary length. This is possible through Transformers 
[`pipeline`](https://huggingface.co/docs/transformers/main_classes/pipelines#transformers.AutomaticSpeechRecognitionPipeline) 
method. Chunking is enabled by setting `chunk_length_s=30` when instantiating the pipeline. With chunking enabled, the pipeline 
can be run with batched inference. It can also be extended to predict sequence level timestamps by passing `return_timestamps=True`:

```python
>>> import torch
>>> from transformers import pipeline
>>> from datasets import load_dataset

>>> device = "cuda:0" if torch.cuda.is_available() else "cpu"

>>> pipe = pipeline(
>>>   "automatic-speech-recognition",
>>>   model="openai/whisper-base",
>>>   chunk_length_s=30,
>>>   device=device,
>>> )

>>> ds = load_dataset("hf-internal-testing/librispeech_asr_dummy", "clean", split="validation")
>>> sample = ds[0]["audio"]

>>> prediction = pipe(sample.copy(), batch_size=8)["text"]
" Mr. Quilter is the apostle of the middle classes, and we are glad to welcome his gospel."

>>> # we can also return timestamps for the predictions
>>> prediction = pipe(sample.copy(), batch_size=8, return_timestamps=True)["chunks"]
[{'text': ' Mr. Quilter is the apostle of the middle classes and we are glad to welcome his gospel.',
  'timestamp': (0.0, 5.44)}]
```

Refer to the blog post [ASR Chunking](https://huggingface.co/blog/asr-chunking) for more details on the chunking algorithm.

## Fine-Tuning

The pre-trained Whisper model demonstrates a strong ability to generalise to different datasets and domains. However, 
its predictive capabilities can be improved further for certain languages and tasks through *fine-tuning*. The blog 
post [Fine-Tune Whisper with 🤗 Transformers](https://huggingface.co/blog/fine-tune-whisper) provides a step-by-step 
guide to fine-tuning the Whisper model with as little as 5 hours of labelled data.

### Evaluated Use

The primary intended users of these models are AI researchers studying robustness, generalization, capabilities, biases, and constraints of the current model. However, Whisper is also potentially quite useful as an ASR solution for developers, especially for English speech recognition. We recognize that once models are released, it is impossible to restrict access to only “intended” uses or to draw reasonable guidelines around what is or is not research.

The models are primarily trained and evaluated on ASR and speech translation to English tasks. They show strong ASR results in ~10 languages. They may exhibit additional capabilities, particularly if fine-tuned on certain tasks like voice activity detection, speaker classification, or speaker diarization but have not been robustly evaluated in these areas. We strongly recommend that users perform robust evaluations of the models in a particular context and domain before deploying them.

In particular, we caution against using Whisper models to transcribe recordings of individuals taken without their consent or purporting to use these models for any kind of subjective classification. We recommend against use in high-risk domains like decision-making contexts, where flaws in accuracy can lead to pronounced flaws in outcomes. The models are intended to transcribe and translate speech, use of the model for classification is not only not evaluated but also not appropriate, particularly to infer human attributes.


## Training Data

The models are trained on 680,000 hours of audio and the corresponding transcripts collected from the internet. 65% of this data (or 438,000 hours) represents English-language audio and matched English transcripts, roughly 18% (or 126,000 hours) represents non-English audio and English transcripts, while the final 17% (or 117,000 hours) represents non-English audio and the corresponding transcript. This non-English data represents 98 different languages. 

As discussed in [the accompanying paper](https://cdn.openai.com/papers/whisper.pdf), we see that performance on transcription in a given language is directly correlated with the amount of training data we employ in that language.


## Performance and Limitations

Our studies show that, over many existing ASR systems, the models exhibit improved robustness to accents, background noise, technical language, as well as zero shot translation from multiple languages into English; and that accuracy on speech recognition and translation is near the state-of-the-art level. 

However, because the models are trained in a weakly supervised manner using large-scale noisy data, the predictions may include texts that are not actually spoken in the audio input (i.e. hallucination). We hypothesize that this happens because, given their general knowledge of language, the models combine trying to predict the next word in audio with trying to transcribe the audio itself.

Our models perform unevenly across languages, and we observe lower accuracy on low-resource and/or low-discoverability languages or languages where we have less training data. The models also exhibit disparate performance on different accents and dialects of particular languages, which may include higher word error rate across speakers of different genders, races, ages, or other demographic criteria. Our full evaluation results are presented in [the paper accompanying this release](https://cdn.openai.com/papers/whisper.pdf). 

In addition, the sequence-to-sequence architecture of the model makes it prone to generating repetitive texts, which can be mitigated to some degree by beam search and temperature scheduling but not perfectly. Further analysis on these limitations are provided in [the paper](https://cdn.openai.com/papers/whisper.pdf). It is likely that this behavior and hallucinations may be worse on lower-resource and/or lower-discoverability languages.


## Broader Implications

We anticipate that Whisper models’ transcription capabilities may be used for improving accessibility tools. While Whisper models cannot be used for real-time transcription out of the box – their speed and size suggest that others may be able to build applications on top of them that allow for near-real-time speech recognition and translation. The real value of beneficial applications built on top of Whisper models suggests that the disparate performance of these models may have real economic implications.

There are also potential dual use concerns that come with releasing Whisper. While we hope the technology will be used primarily for beneficial purposes, making ASR technology more accessible could enable more actors to build capable surveillance technologies or scale up existing surveillance efforts, as the speed and accuracy allow for affordable automatic transcription and translation of large volumes of audio communication. Moreover, these models may have some capabilities to recognize specific individuals out of the box, which in turn presents safety concerns related both to dual use and disparate performance. In practice, we expect that the cost of transcription is not the limiting factor of scaling up surveillance projects.


### BibTeX entry and citation info
```bibtex
@misc{radford2022whisper,
  doi = {10.48550/ARXIV.2212.04356},
  url = {https://arxiv.org/abs/2212.04356},
  author = {Radford, Alec and Kim, Jong Wook and Xu, Tao and Brockman, Greg and McLeavey, Christine and Sutskever, Ilya},
  title = {Robust Speech Recognition via Large-Scale Weak Supervision},
  publisher = {arXiv},
  year = {2022},
  copyright = {arXiv.org perpetual, non-exclusive license}
}
```
"""^^xsd:string ;
    schema:discussionUrl <https://huggingface.co/openai/whisper-base/discussions> ;
    schema:distribution "Information not found."^^xsd:string ;
    schema:funding "Information not found."^^xsd:string ;
    schema:identifier "https://huggingface.co/openai/whisper-base"^^xsd:string ;
    schema:inLanguage "af"^^xsd:string,
        "am"^^xsd:string,
        "ar"^^xsd:string,
        "as"^^xsd:string,
        "az"^^xsd:string,
        "ba"^^xsd:string,
        "be"^^xsd:string,
        "bg"^^xsd:string,
        "bn"^^xsd:string,
        "bo"^^xsd:string,
        "br"^^xsd:string,
        "bs"^^xsd:string,
        "ca"^^xsd:string,
        "cs"^^xsd:string,
        "cy"^^xsd:string,
        "da"^^xsd:string,
        "de"^^xsd:string,
        "el"^^xsd:string,
        "en"^^xsd:string,
        "es"^^xsd:string,
        "et"^^xsd:string,
        "eu"^^xsd:string,
        "fa"^^xsd:string,
        "fi"^^xsd:string,
        "fo"^^xsd:string,
        "fr"^^xsd:string,
        "gl"^^xsd:string,
        "gu"^^xsd:string,
        "ha"^^xsd:string,
        "haw"^^xsd:string,
        "he"^^xsd:string,
        "hi"^^xsd:string,
        "hr"^^xsd:string,
        "ht"^^xsd:string,
        "hu"^^xsd:string,
        "hy"^^xsd:string,
        "id"^^xsd:string,
        "is"^^xsd:string,
        "it"^^xsd:string,
        "ja"^^xsd:string,
        "jw"^^xsd:string,
        "ka"^^xsd:string,
        "kk"^^xsd:string,
        "km"^^xsd:string,
        "kn"^^xsd:string,
        "ko"^^xsd:string,
        "la"^^xsd:string,
        "lb"^^xsd:string,
        "ln"^^xsd:string,
        "lo"^^xsd:string,
        "lt"^^xsd:string,
        "lv"^^xsd:string,
        "mg"^^xsd:string,
        "mi"^^xsd:string,
        "mk"^^xsd:string,
        "ml"^^xsd:string,
        "mn"^^xsd:string,
        "mr"^^xsd:string,
        "ms"^^xsd:string,
        "mt"^^xsd:string,
        "my"^^xsd:string,
        "ne"^^xsd:string,
        "nl"^^xsd:string,
        "nn"^^xsd:string,
        "oc"^^xsd:string,
        "pa"^^xsd:string,
        "pl"^^xsd:string,
        "ps"^^xsd:string,
        "pt"^^xsd:string,
        "ro"^^xsd:string,
        "ru"^^xsd:string,
        "sa"^^xsd:string,
        "sd"^^xsd:string,
        "si"^^xsd:string,
        "sk"^^xsd:string,
        "sl"^^xsd:string,
        "sn"^^xsd:string,
        "so"^^xsd:string,
        "sq"^^xsd:string,
        "sr"^^xsd:string,
        "su"^^xsd:string,
        "sv"^^xsd:string,
        "sw"^^xsd:string,
        "ta"^^xsd:string,
        "te"^^xsd:string,
        "tg"^^xsd:string,
        "th"^^xsd:string,
        "tk"^^xsd:string,
        "tl"^^xsd:string,
        "tr"^^xsd:string,
        "tt"^^xsd:string,
        "uk"^^xsd:string,
        "ur"^^xsd:string,
        "uz"^^xsd:string,
        "vi"^^xsd:string,
        "yi"^^xsd:string,
        "yo"^^xsd:string,
        "zh"^^xsd:string ;
    schema:keywords <http://mlentory.zbmed.de/mlentory_graph/07456871ec04ff7e102a14a63ee4f77775baadaf5e404b74e2ab827a14335259>,
        <http://mlentory.zbmed.de/mlentory_graph/0dce0f5e7319b6178cd79d5f2163f0e134d0064f4ea4f93e8afeec1e7d78fa8d>,
        <http://mlentory.zbmed.de/mlentory_graph/13e6e4095523310627190177e08c0206ca97e76f4c4565c15c2b35270daa2588>,
        <http://mlentory.zbmed.de/mlentory_graph/29d9051dd7490ee997ef15f45bf916274706268eab63f2c7bff767388d51cf25>,
        <http://mlentory.zbmed.de/mlentory_graph/3e9a4e1232f617b33fa8460d6c142ee49e69eb5c55acfd1e618d58e7495955e8>,
        <http://mlentory.zbmed.de/mlentory_graph/87b927fef88a46248b3b208472aec7bfeb38667386b309f46772e26b40f6affb>,
        <http://mlentory.zbmed.de/mlentory_graph/8e9892e571845c79509180a69a268f19c0592a4e975a5fd3e16f2059af61ea75>,
        <http://mlentory.zbmed.de/mlentory_graph/9c51ba772888465129d6bda3b0b520a3a16960b8c108a8cd2276eb4fb85ee5f2>,
        <http://mlentory.zbmed.de/mlentory_graph/a7eca72cd0a3a0ce30e3b37b299034e8cf2e3b921a7deaf54545b7d00e88c5e4>,
        <http://mlentory.zbmed.de/mlentory_graph/dabb9d310d39a47f81f009cd476a41773667de14be41c930213432a06ad59fb0>,
        <http://mlentory.zbmed.de/mlentory_graph/df4982af808ead1a57663cc7a83e60059f6a6ae1baf83a270fdf8bdfef11a3de>,
        "af"^^xsd:string,
        "am"^^xsd:string,
        "ar"^^xsd:string,
        "arxiv:2212.04356"^^xsd:string,
        "as"^^xsd:string,
        "az"^^xsd:string,
        "ba"^^xsd:string,
        "be"^^xsd:string,
        "bg"^^xsd:string,
        "bn"^^xsd:string,
        "bo"^^xsd:string,
        "br"^^xsd:string,
        "bs"^^xsd:string,
        "ca"^^xsd:string,
        "cs"^^xsd:string,
        "cy"^^xsd:string,
        "da"^^xsd:string,
        "de"^^xsd:string,
        "el"^^xsd:string,
        "en"^^xsd:string,
        "es"^^xsd:string,
        "et"^^xsd:string,
        "eu"^^xsd:string,
        "fa"^^xsd:string,
        "fi"^^xsd:string,
        "fo"^^xsd:string,
        "fr"^^xsd:string,
        "gl"^^xsd:string,
        "gu"^^xsd:string,
        "ha"^^xsd:string,
        "he"^^xsd:string,
        "hi"^^xsd:string,
        "hr"^^xsd:string,
        "ht"^^xsd:string,
        "hu"^^xsd:string,
        "hy"^^xsd:string,
        "id"^^xsd:string,
        "is"^^xsd:string,
        "it"^^xsd:string,
        "ja"^^xsd:string,
        "jw"^^xsd:string,
        "ka"^^xsd:string,
        "kk"^^xsd:string,
        "km"^^xsd:string,
        "kn"^^xsd:string,
        "ko"^^xsd:string,
        "la"^^xsd:string,
        "lb"^^xsd:string,
        "license:apache-2.0"^^xsd:string,
        "ln"^^xsd:string,
        "lo"^^xsd:string,
        "lt"^^xsd:string,
        "lv"^^xsd:string,
        "mg"^^xsd:string,
        "mi"^^xsd:string,
        "mk"^^xsd:string,
        "ml"^^xsd:string,
        "mn"^^xsd:string,
        "mr"^^xsd:string,
        "ms"^^xsd:string,
        "mt"^^xsd:string,
        "my"^^xsd:string,
        "ne"^^xsd:string,
        "nl"^^xsd:string,
        "nn"^^xsd:string,
        "no"^^xsd:string,
        "oc"^^xsd:string,
        "pa"^^xsd:string,
        "pl"^^xsd:string,
        "ps"^^xsd:string,
        "pt"^^xsd:string,
        "region:us"^^xsd:string,
        "ro"^^xsd:string,
        "ru"^^xsd:string,
        "sa"^^xsd:string,
        "sd"^^xsd:string,
        "si"^^xsd:string,
        "sk"^^xsd:string,
        "sl"^^xsd:string,
        "sn"^^xsd:string,
        "so"^^xsd:string,
        "sq"^^xsd:string,
        "sr"^^xsd:string,
        "su"^^xsd:string,
        "sv"^^xsd:string,
        "sw"^^xsd:string,
        "ta"^^xsd:string,
        "te"^^xsd:string,
        "tf"^^xsd:string,
        "tg"^^xsd:string,
        "th"^^xsd:string,
        "tk"^^xsd:string,
        "tl"^^xsd:string,
        "tr"^^xsd:string,
        "tt"^^xsd:string,
        "uk"^^xsd:string,
        "ur"^^xsd:string,
        "uz"^^xsd:string,
        "vi"^^xsd:string,
        "yi"^^xsd:string,
        "yo"^^xsd:string,
        "zh"^^xsd:string ;
    schema:license "apache-2.0"^^xsd:string ;
    schema:maintainer """Information not found.

Context:
Usage > Transcription - Par. 1: Usage > Transcription:
### English to English 
In this example, the context tokens are 'unforced', meaning the model automatically predicts the output language
(English) and task (transcribe).
Usage > Broader Implications > BibTeX entry and citation info - Par. 1: Usage > Broader Implications > BibTeX entry and citation info:

Question: Find the maintainer in the following text, here is a description of the property: (Individual responsible for maintaining the item.) here are some related sections: Model Card Contact ; Model Card Authors 

Based *only* on the context provided above, answer the question. If the context does not contain the information needed to answer the question, respond with the exact phrase "Information not found".

Answer: Information not found.

Context:
Usage > Transcription - Par. 1: Usage > Transcription:
### English to English 
In this example, the context tokens are 'unforced', meaning the model automatically predicts the output language
(English) and task (transcribe).
Usage > Broader Implications > BibTeX entry and citation info - Par. 1: Usage > Broader Implications > BibTeX entry and citation info:

Question: Find the maintainer in the following text, here is a description of the property: (Individual responsible for maintaining the item.) here are some related sections: Model Card Contact ; Model Card Authors 

Based *only* on the context provided above, answer the question. If the context does not contain the information needed to answer the question, respond with the exact phrase "Information not found".

Answer: Information not found.

Context:
Usage > Transcription - Par. 1: Usage > Transcription:
### English to English 
In this example, the context tokens are 'unforced', meaning the model automatically predicts the output language
(English) and task (transcribe).
Usage > Broader Implications > BibTeX entry and citation info - Par. 1: Usage > Broader Implications > BibTeX entry and citation info:

Question: Find the maintainer in the following text, here is a description of the property: (Individual responsible for maintaining the item.) here are some related sections: Model Card Contact ; Model Card Authors 

Based *only* on the context provided above, answer the question. If the context does not contain the information needed to answer the question, respond with the exact phrase "Information not found".

Answer: Information not found.

Context:
Usage > Transcription - Par. 1: Usage > Transcription:
### English to English 
In this example, the context tokens are 'unforced', meaning the model automatically predicts the output language
(English) and task (transcribe).
Usage > Broader Implications > BibTeX entry and citation info - Par. 1: Usage > Broader Implications > BibTeX entry and citation info:

Question: Find the maintainer in the following text, here is a description of the property: (Individual responsible for maintaining the item.) here are some related sections: Model Card Contact ; Model Card Authors 

Based *only* on the context provided above, answer the question. If the context does not contain the information needed to answer the question, respond with the exact phrase "Information not found".

Answer: Information not found.

Context:
Usage > Transcription - Par. 1: Usage > Transcription:
### English to English 
In this example, the context tokens are 'unforced', meaning the model automatically predicts the output language
(English) and task (transcribe).
Usage > Broader Implications > BibTeX entry and citation info - Par. 1: Usage > Broader Implications > BibTeX entry and citation info:

Question: Find the maintainer in the following text, here is a description of the property: (Individual responsible for maintaining the item.) here are some related sections: Model Card Contact ; Model Card Authors 

Based *only* on the context provided above, answer the question. If the context does not contain the information needed to answer the question, respond with the exact phrase "Information not found".

Answer: Information not found.

Context:
Usage > Transcription - Par. 1: Usage > Transcription:
### English to English 
In this example, the context tokens are 'unforced', meaning the model automatically predicts the output language
(English) and task (transcribe).
Usage > Broader Implications > BibTeX entry and citation info - Par. 1: Usage > Broader Implications > BibTeX entry and citation info:

Question: Find the maintainer in the following text, here is a description of the property: (Individual responsible for maintaining the item.) here are some related sections: Model Card Contact ; Model Card Authors 

Based *only* on the context provided above, answer the question. If the context does not contain the information needed to answer the question, respond with the exact phrase "Information not found".

Answer: Information not found.

Context:
Usage > Transcription - Par. 1: Usage > Transcription:
### English to English 
In this example, the context tokens are 'unforced', meaning the model automatically predicts the output language
(English) and task (transcribe).
Usage > Broader Implications > BibTeX entry and citation info - Par. 1: Usage > Broader Implications > BibTeX entry and citation info:

Question: Find the maintainer in the following text, here is a description of the property: (Individual responsible for maintaining the item.) here are some related sections: Model Card Contact ; Model Card Authors 

Based *only* on the context provided above, answer the question. If the context does not contain the information needed to answer the question, respond with the exact phrase "Information not found".

Answer: Information not found.

Context:
Usage > Transcription - Par. 1: Usage > Transcription:
### English to English 
In this example, the context tokens are 'unforced', meaning the model automatically predicts the output language
(English) and task (transcribe).
Usage > Broader Implications > BibTeX entry and citation info - Par. 1: Usage > Broader Implications > BibTeX entry and citation info:

Question: Find the maintainer in the following text, here is a description of the property: (Individual responsible for maintaining the item.) here are some related sections: Model Card Contact ; Model Card Authors 

Based *only* on the context provided above, answer the question. If the context does not contain the information needed to answer the question, respond with the exact phrase "Information not found".

Answer: Information not found.

Context:
Usage > Transcription - Par. 1: Usage > Transcription:
### English to English 
In this example, the context tokens are 'unforced', meaning the model automatically predicts the output language
(English) and task (transcribe).
Usage > Broader Implications > BibTeX entry and citation info - Par. 1: Usage > Broader Implications > BibTeX entry and citation info:

Question: Find the maintainer in the following text, here is a description of the property: (Individual responsible for maintaining the item.) here are some related sections: Model Card Contact ; Model Card Authors 

Based *only* on the context provided above, answer the question. If the context does not contain the information needed to answer the question, respond with the exact phrase "Information not found".

Answer: Information not found.

Context:
Usage > Transcription - Par. 1: Usage > Transcription:
### English to English 
In this example, the context tokens are 'unforced', meaning the model automatically predicts the output language
(English) and task (transcribe).
Usage > Broader Implications > BibTeX entry and citation info - Par. 1: Usage > Broader Implications > BibTeX entry and citation info:

Question: Find the maintainer in the following text, here is a description of the property: (Individual responsible for maintaining the item.) here are some related sections: Model Card Contact ; Model Card Authors 

Based *only* on the context provided above, answer the question. If the context does not contain the information needed to answer the question, respond with the exact phrase "Information not found".

Answer: Information not found.

Context:
Usage > Transcription - Par. 1: Usage > Transcription:
### English to English 
In this example, the context tokens are 'unforced', meaning the model automatically predicts the output language
(English) and task (transcribe).
Usage > Broader Implications > BibTeX entry and citation info - Par. 1: Usage > Broader Implications > BibTeX entry and citation info:

Question: Find the maintainer in the following text, here is a description of the property: (Individual responsible for maintaining the item.) here are some related sections: Model Card Contact ; Model Card Authors 

Based *only* on the context provided above, answer the question. If the context does not contain the information needed to answer the question, respond with the exact phrase "Information not found".

Answer: Information not found.

Context:
Usage > Transcription - Par. 1: Usage > Transcription:
### English to English 
In this example, the context tokens are 'unforced', meaning the model automatically predicts the output language
(English) and task (transcribe).
Usage > Broader Implications > BibTeX entry and citation info - Par. 1: Usage > Broader Implications > BibTeX entry and citation info:

Question: Find the maintainer in the following text, here is a description of the property: (Individual responsible for maintaining the item.) here are some related sections: Model Card Contact ; Model Card Authors"""^^xsd:string ;
    schema:memoryRequirements "Not available"^^xsd:string ;
    schema:name "whisper-base"^^xsd:string ;
    schema:operatingSystem "The operating systems supported by the Whisper model are Windows 7, OSX 10.6, and Android 1.6."^^xsd:string ;
    schema:processorRequirements "Information not found."^^xsd:string ;
    schema:releaseNotes """---
language:
- en
- zh
- de
- es
- ru
- ko
- fr
- ja
- pt
- tr
- pl
- ca
- nl
- ar
- sv
- it
- id
- hi
- fi
- vi
- he
- uk
- el
- ms
- cs
- ro
- da
- hu
- ta
- false
- th
- ur
- hr
- bg
- lt
- la
- mi
- ml
- cy
- sk
- te
- fa
- lv
- bn
- sr
- az
- sl
- kn
- et
- mk
- br
- eu
- is
- hy
- ne
- mn
- bs
- kk
- sq
- sw
- gl
- mr
- pa
- si
- km
- sn
- yo
- so
- af
- oc
- ka
- be
- tg
- sd
- gu
- am
- yi
- lo
- uz
- fo
- ht
- ps
- tk
- nn
- mt
- sa
- lb
- my
- bo
- tl
- mg
- as
- tt
- haw
- ln
- ha
- ba
- jw
- su
tags:
- audio
- automatic-speech-recognition
- hf-asr-leaderboard
widget:
- example_title: Librispeech sample 1
  src: https://cdn-media.huggingface.co/speech_samples/sample1.flac
- example_title: Librispeech sample 2
  src: https://cdn-media.huggingface.co/speech_samples/sample2.flac
pipeline_tag: automatic-speech-recognition
license: apache-2.0
model-index:
- name: whisper-base
  results:
  - task:
      type: automatic-speech-recognition
      name: Automatic Speech Recognition
    dataset:
      name: LibriSpeech (clean)
      type: librispeech_asr
      config: clean
      split: test
      args:
        language: en
    metrics:
    - type: wer
      value: 5.008769117619326
      name: Test WER
  - task:
      type: automatic-speech-recognition
      name: Automatic Speech Recognition
    dataset:
      name: LibriSpeech (other)
      type: librispeech_asr
      config: other
      split: test
      args:
        language: en
    metrics:
    - type: wer
      value: 12.84936273212057
      name: Test WER
  - task:
      type: automatic-speech-recognition
      name: Automatic Speech Recognition
    dataset:
      name: Common Voice 11.0
      type: mozilla-foundation/common_voice_11_0
      config: hi
      split: test
      args:
        language: hi
    metrics:
    - type: wer
      value: 131
      name: Test WER
---

# Whisper

Whisper is a pre-trained model for automatic speech recognition (ASR) and speech translation. Trained on 680k hours 
of labelled data, Whisper models demonstrate a strong ability to generalise to many datasets and domains **without** the need 
for fine-tuning.

Whisper was proposed in the paper [Robust Speech Recognition via Large-Scale Weak Supervision](https://arxiv.org/abs/2212.04356) 
by Alec Radford et al from OpenAI. The original code repository can be found [here](https://github.com/openai/whisper).

**Disclaimer**: Content for this model card has partly been written by the Hugging Face team, and parts of it were 
copied and pasted from the original model card.

## Model details

Whisper is a Transformer based encoder-decoder model, also referred to as a _sequence-to-sequence_ model. 
It was trained on 680k hours of labelled speech data annotated using large-scale weak supervision. 

The models were trained on either English-only data or multilingual data. The English-only models were trained 
on the task of speech recognition. The multilingual models were trained on both speech recognition and speech 
translation. For speech recognition, the model predicts transcriptions in the *same* language as the audio. 
For speech translation, the model predicts transcriptions to a *different* language to the audio.

Whisper checkpoints come in five configurations of varying model sizes.
The smallest four are trained on either English-only or multilingual data.
The largest checkpoints are multilingual only. All ten of the pre-trained checkpoints 
are available on the [Hugging Face Hub](https://huggingface.co/models?search=openai/whisper). The 
checkpoints are summarised in the following table with links to the models on the Hub:

| Size     | Parameters | English-only                                         | Multilingual                                        |
|----------|------------|------------------------------------------------------|-----------------------------------------------------|
| tiny     | 39 M       | [✓](https://huggingface.co/openai/whisper-tiny.en)   | [✓](https://huggingface.co/openai/whisper-tiny)     |
| base     | 74 M       | [✓](https://huggingface.co/openai/whisper-base.en)   | [✓](https://huggingface.co/openai/whisper-base)     |
| small    | 244 M      | [✓](https://huggingface.co/openai/whisper-small.en)  | [✓](https://huggingface.co/openai/whisper-small)    |
| medium   | 769 M      | [✓](https://huggingface.co/openai/whisper-medium.en) | [✓](https://huggingface.co/openai/whisper-medium)   |
| large    | 1550 M     | x                                                    | [✓](https://huggingface.co/openai/whisper-large)    |
| large-v2 | 1550 M     | x                                                    | [✓](https://huggingface.co/openai/whisper-large-v2) |

# Usage

To transcribe audio samples, the model has to be used alongside a [`WhisperProcessor`](https://huggingface.co/docs/transformers/model_doc/whisper#transformers.WhisperProcessor).

The `WhisperProcessor` is used to:
1. Pre-process the audio inputs (converting them to log-Mel spectrograms for the model)
2. Post-process the model outputs (converting them from tokens to text)

The model is informed of which task to perform (transcription or translation) by passing the appropriate "context tokens". These context tokens 
are a sequence of tokens that are given to the decoder at the start of the decoding process, and take the following order:
1. The transcription always starts with the `<|startoftranscript|>` token
2. The second token is the language token (e.g. `<|en|>` for English)
3. The third token is the "task token". It can take one of two values: `<|transcribe|>` for speech recognition or `<|translate|>` for speech translation
4. In addition, a `<|notimestamps|>` token is added if the model should not include timestamp prediction

Thus, a typical sequence of context tokens might look as follows:
```
<|startoftranscript|> <|en|> <|transcribe|> <|notimestamps|>
```
Which tells the model to decode in English, under the task of speech recognition, and not to predict timestamps.

These tokens can either be forced or un-forced. If they are forced, the model is made to predict each token at 
each position. This allows one to control the output language and task for the Whisper model. If they are un-forced, 
the Whisper model will automatically predict the output langauge and task itself.

The context tokens can be set accordingly:

```python
model.config.forced_decoder_ids = WhisperProcessor.get_decoder_prompt_ids(language="english", task="transcribe")
```

Which forces the model to predict in English under the task of speech recognition.

## Transcription

### English to English 
In this example, the context tokens are 'unforced', meaning the model automatically predicts the output language
(English) and task (transcribe).

```python
>>> from transformers import WhisperProcessor, WhisperForConditionalGeneration
>>> from datasets import load_dataset

>>> # load model and processor
>>> processor = WhisperProcessor.from_pretrained("openai/whisper-base")
>>> model = WhisperForConditionalGeneration.from_pretrained("openai/whisper-base")
>>> model.config.forced_decoder_ids = None

>>> # load dummy dataset and read audio files
>>> ds = load_dataset("hf-internal-testing/librispeech_asr_dummy", "clean", split="validation")
>>> sample = ds[0]["audio"]
>>> input_features = processor(sample["array"], sampling_rate=sample["sampling_rate"], return_tensors="pt").input_features 

>>> # generate token ids
>>> predicted_ids = model.generate(input_features)
>>> # decode token ids to text
>>> transcription = processor.batch_decode(predicted_ids, skip_special_tokens=False)
['<|startoftranscript|><|en|><|transcribe|><|notimestamps|> Mr. Quilter is the apostle of the middle classes and we are glad to welcome his gospel.<|endoftext|>']

>>> transcription = processor.batch_decode(predicted_ids, skip_special_tokens=True)
[' Mr. Quilter is the apostle of the middle classes and we are glad to welcome his gospel.']
```
The context tokens can be removed from the start of the transcription by setting `skip_special_tokens=True`.

### French to French 
The following example demonstrates French to French transcription by setting the decoder ids appropriately. 

```python
>>> from transformers import WhisperProcessor, WhisperForConditionalGeneration
>>> from datasets import Audio, load_dataset

>>> # load model and processor
>>> processor = WhisperProcessor.from_pretrained("openai/whisper-base")
>>> model = WhisperForConditionalGeneration.from_pretrained("openai/whisper-base")
>>> forced_decoder_ids = processor.get_decoder_prompt_ids(language="french", task="transcribe")

>>> # load streaming dataset and read first audio sample
>>> ds = load_dataset("common_voice", "fr", split="test", streaming=True)
>>> ds = ds.cast_column("audio", Audio(sampling_rate=16_000))
>>> input_speech = next(iter(ds))["audio"]
>>> input_features = processor(input_speech["array"], sampling_rate=input_speech["sampling_rate"], return_tensors="pt").input_features

>>> # generate token ids
>>> predicted_ids = model.generate(input_features, forced_decoder_ids=forced_decoder_ids)
>>> # decode token ids to text
>>> transcription = processor.batch_decode(predicted_ids)
['<|startoftranscript|><|fr|><|transcribe|><|notimestamps|> Un vrai travail intéressant va enfin être mené sur ce sujet.<|endoftext|>']

>>> transcription = processor.batch_decode(predicted_ids, skip_special_tokens=True)
[' Un vrai travail intéressant va enfin être mené sur ce sujet.']
```

## Translation 
Setting the task to "translate" forces the Whisper model to perform speech translation.

### French to English

```python
>>> from transformers import WhisperProcessor, WhisperForConditionalGeneration
>>> from datasets import Audio, load_dataset

>>> # load model and processor
>>> processor = WhisperProcessor.from_pretrained("openai/whisper-base")
>>> model = WhisperForConditionalGeneration.from_pretrained("openai/whisper-base")
>>> forced_decoder_ids = processor.get_decoder_prompt_ids(language="french", task="translate")

>>> # load streaming dataset and read first audio sample
>>> ds = load_dataset("common_voice", "fr", split="test", streaming=True)
>>> ds = ds.cast_column("audio", Audio(sampling_rate=16_000))
>>> input_speech = next(iter(ds))["audio"]
>>> input_features = processor(input_speech["array"], sampling_rate=input_speech["sampling_rate"], return_tensors="pt").input_features

>>> # generate token ids
>>> predicted_ids = model.generate(input_features, forced_decoder_ids=forced_decoder_ids)
>>> # decode token ids to text
>>> transcription = processor.batch_decode(predicted_ids, skip_special_tokens=True)
[' A very interesting work, we will finally be given on this subject.']
```

## Evaluation

This code snippet shows how to evaluate Whisper Base on [LibriSpeech test-clean](https://huggingface.co/datasets/librispeech_asr):
 
```python
>>> from datasets import load_dataset
>>> from transformers import WhisperForConditionalGeneration, WhisperProcessor
>>> import torch
>>> from evaluate import load

>>> librispeech_test_clean = load_dataset("librispeech_asr", "clean", split="test")

>>> processor = WhisperProcessor.from_pretrained("openai/whisper-base")
>>> model = WhisperForConditionalGeneration.from_pretrained("openai/whisper-base").to("cuda")

>>> def map_to_pred(batch):
>>>     audio = batch["audio"]
>>>     input_features = processor(audio["array"], sampling_rate=audio["sampling_rate"], return_tensors="pt").input_features
>>>     batch["reference"] = processor.tokenizer._normalize(batch['text'])
>>> 
>>>     with torch.no_grad():
>>>         predicted_ids = model.generate(input_features.to("cuda"))[0]
>>>     transcription = processor.decode(predicted_ids)
>>>     batch["prediction"] = processor.tokenizer._normalize(transcription)
>>>     return batch

>>> result = librispeech_test_clean.map(map_to_pred)

>>> wer = load("wer")
>>> print(100 * wer.compute(references=result["reference"], predictions=result["prediction"]))
5.082316555716899
```

## Long-Form Transcription

The Whisper model is intrinsically designed to work on audio samples of up to 30s in duration. However, by using a chunking 
algorithm, it can be used to transcribe audio samples of up to arbitrary length. This is possible through Transformers 
[`pipeline`](https://huggingface.co/docs/transformers/main_classes/pipelines#transformers.AutomaticSpeechRecognitionPipeline) 
method. Chunking is enabled by setting `chunk_length_s=30` when instantiating the pipeline. With chunking enabled, the pipeline 
can be run with batched inference. It can also be extended to predict sequence level timestamps by passing `return_timestamps=True`:

```python
>>> import torch
>>> from transformers import pipeline
>>> from datasets import load_dataset

>>> device = "cuda:0" if torch.cuda.is_available() else "cpu"

>>> pipe = pipeline(
>>>   "automatic-speech-recognition",
>>>   model="openai/whisper-base",
>>>   chunk_length_s=30,
>>>   device=device,
>>> )

>>> ds = load_dataset("hf-internal-testing/librispeech_asr_dummy", "clean", split="validation")
>>> sample = ds[0]["audio"]

>>> prediction = pipe(sample.copy(), batch_size=8)["text"]
" Mr. Quilter is the apostle of the middle classes, and we are glad to welcome his gospel."

>>> # we can also return timestamps for the predictions
>>> prediction = pipe(sample.copy(), batch_size=8, return_timestamps=True)["chunks"]
[{'text': ' Mr. Quilter is the apostle of the middle classes and we are glad to welcome his gospel.',
  'timestamp': (0.0, 5.44)}]
```

Refer to the blog post [ASR Chunking](https://huggingface.co/blog/asr-chunking) for more details on the chunking algorithm.

## Fine-Tuning

The pre-trained Whisper model demonstrates a strong ability to generalise to different datasets and domains. However, 
its predictive capabilities can be improved further for certain languages and tasks through *fine-tuning*. The blog 
post [Fine-Tune Whisper with 🤗 Transformers](https://huggingface.co/blog/fine-tune-whisper) provides a step-by-step 
guide to fine-tuning the Whisper model with as little as 5 hours of labelled data.

### Evaluated Use

The primary intended users of these models are AI researchers studying robustness, generalization, capabilities, biases, and constraints of the current model. However, Whisper is also potentially quite useful as an ASR solution for developers, especially for English speech recognition. We recognize that once models are released, it is impossible to restrict access to only “intended” uses or to draw reasonable guidelines around what is or is not research.

The models are primarily trained and evaluated on ASR and speech translation to English tasks. They show strong ASR results in ~10 languages. They may exhibit additional capabilities, particularly if fine-tuned on certain tasks like voice activity detection, speaker classification, or speaker diarization but have not been robustly evaluated in these areas. We strongly recommend that users perform robust evaluations of the models in a particular context and domain before deploying them.

In particular, we caution against using Whisper models to transcribe recordings of individuals taken without their consent or purporting to use these models for any kind of subjective classification. We recommend against use in high-risk domains like decision-making contexts, where flaws in accuracy can lead to pronounced flaws in outcomes. The models are intended to transcribe and translate speech, use of the model for classification is not only not evaluated but also not appropriate, particularly to infer human attributes.


## Training Data

The models are trained on 680,000 hours of audio and the corresponding transcripts collected from the internet. 65% of this data (or 438,000 hours) represents English-language audio and matched English transcripts, roughly 18% (or 126,000 hours) represents non-English audio and English transcripts, while the final 17% (or 117,000 hours) represents non-English audio and the corresponding transcript. This non-English data represents 98 different languages. 

As discussed in [the accompanying paper](https://cdn.openai.com/papers/whisper.pdf), we see that performance on transcription in a given language is directly correlated with the amount of training data we employ in that language.


## Performance and Limitations

Our studies show that, over many existing ASR systems, the models exhibit improved robustness to accents, background noise, technical language, as well as zero shot translation from multiple languages into English; and that accuracy on speech recognition and translation is near the state-of-the-art level. 

However, because the models are trained in a weakly supervised manner using large-scale noisy data, the predictions may include texts that are not actually spoken in the audio input (i.e. hallucination). We hypothesize that this happens because, given their general knowledge of language, the models combine trying to predict the next word in audio with trying to transcribe the audio itself.

Our models perform unevenly across languages, and we observe lower accuracy on low-resource and/or low-discoverability languages or languages where we have less training data. The models also exhibit disparate performance on different accents and dialects of particular languages, which may include higher word error rate across speakers of different genders, races, ages, or other demographic criteria. Our full evaluation results are presented in [the paper accompanying this release](https://cdn.openai.com/papers/whisper.pdf). 

In addition, the sequence-to-sequence architecture of the model makes it prone to generating repetitive texts, which can be mitigated to some degree by beam search and temperature scheduling but not perfectly. Further analysis on these limitations are provided in [the paper](https://cdn.openai.com/papers/whisper.pdf). It is likely that this behavior and hallucinations may be worse on lower-resource and/or lower-discoverability languages.


## Broader Implications

We anticipate that Whisper models’ transcription capabilities may be used for improving accessibility tools. While Whisper models cannot be used for real-time transcription out of the box – their speed and size suggest that others may be able to build applications on top of them that allow for near-real-time speech recognition and translation. The real value of beneficial applications built on top of Whisper models suggests that the disparate performance of these models may have real economic implications.

There are also potential dual use concerns that come with releasing Whisper. While we hope the technology will be used primarily for beneficial purposes, making ASR technology more accessible could enable more actors to build capable surveillance technologies or scale up existing surveillance efforts, as the speed and accuracy allow for affordable automatic transcription and translation of large volumes of audio communication. Moreover, these models may have some capabilities to recognize specific individuals out of the box, which in turn presents safety concerns related both to dual use and disparate performance. In practice, we expect that the cost of transcription is not the limiting factor of scaling up surveillance projects.


### BibTeX entry and citation info
```bibtex
@misc{radford2022whisper,
  doi = {10.48550/ARXIV.2212.04356},
  url = {https://arxiv.org/abs/2212.04356},
  author = {Radford, Alec and Kim, Jong Wook and Xu, Tao and Brockman, Greg and McLeavey, Christine and Sutskever, Ilya},
  title = {Robust Speech Recognition via Large-Scale Weak Supervision},
  publisher = {arXiv},
  year = {2022},
  copyright = {arXiv.org perpetual, non-exclusive license}
}
```
"""^^xsd:string ;
    schema:softwareHelp "Information not found."^^xsd:string ;
    schema:softwareRequirements "Information not found."^^xsd:string ;
    schema:storageRequirements """Information not found.

### English to English 
In this example, the context tokens are 'unforced', meaning the model automatically predicts the output language
(English) and task (transcribe).

Question: Find the storage Requirements in the following text, here is a description of the property: (Storage requirements (free space required).) here are some related sections: Technical Specifications > Hardware

Based *only* on the context provided above, answer the question. If the context does not contain the information needed to answer the question, respond with the exact phrase "Information not found".

Answer: Information not found.

### English to English 
In this example, the context tokens are 'unforced', meaning the model automatically predicts the output language
(English) and task (transcribe).

Question: Find the storage Requirements in the following text, here is a description of the property: (Storage requirements (free space required).) here are some related sections: Technical Specifications > Hardware

Based *only* on the context provided above, answer the question. If the context does not contain the information needed to answer the question, respond with the exact phrase "Information not found".

Answer: Information not found.

### English to English 
In this example, the context tokens are 'unforced', meaning the model automatically predicts the output language
(English) and task (transcribe).

Question: Find the storage Requirements in the following text, here is a description of the property: (Storage requirements (free space required).) here are some related sections: Technical Specifications > Hardware

Based *only* on the context provided above, answer the question. If the context does not contain the information needed to answer the question, respond with the exact phrase "Information not found".

Answer: Information not found.

### English to English 
In this example, the context tokens are 'unforced', meaning the model automatically predicts the output language
(English) and task (transcribe).

Question: Find the storage Requirements in the following text, here is a description of the property: (Storage requirements (free space required).) here are some related sections: Technical Specifications > Hardware

Based *only* on the context provided above, answer the question. If the context does not contain the information needed to answer the question, respond with the exact phrase "Information not found".

Answer: Information not found.

### English to English 
In this example, the context tokens are 'unforced', meaning the model automatically predicts the output language
(English) and task (transcribe).

Question: Find the storage Requirements in the following text, here is a description of the property: (Storage requirements (free space required).) here are some related sections: Technical Specifications > Hardware

Based *only* on the context provided above, answer the question. If the context does not contain the information needed to answer the question, respond with the exact phrase "Information not found".

Answer: Information not found.

### English to English 
In this example, the context tokens are 'unforced', meaning the model automatically predicts the output language
(English) and task (transcribe).

Question: Find the storage Requirements in the following text, here is a description of the property: (Storage requirements (free space required).) here are some related sections: Technical Specifications > Hardware

Based *only* on the context provided above, answer the question. If the context does not contain the information needed to answer the question, respond with the exact phrase "Information not found".

Answer: Information not found.

### English to English 
In this example, the context tokens are 'unforced', meaning the model automatically predicts the output language
(English) and task (transcribe).

Question: Find the storage Requirements in the following text, here is a description of the property: (Storage requirements (free space required).) here are some related sections: Technical Specifications > Hardware

Based *only* on the context provided above, answer the question. If the context does not contain the information needed to answer the question, respond with the exact phrase "Information not found".

Answer: Information not found.

### English to English 
In this example, the context tokens are 'unforced', meaning the model automatically predicts the output language
(English) and task (transcribe).

Question: Find the storage Requirements in the following text, here is a description of the property: (Storage requirements (free space required).) here are some related sections: Technical Specifications > Hardware

Based *only* on the context provided above, answer the question. If the context does not contain the information needed to answer the question, respond with the exact phrase "Information not found".

Answer: Information not found.

### English to English 
In this example, the context tokens are 'unforced', meaning the model automatically predicts the output language
(English) and task (transcribe).

Question: Find the storage Requirements in the following text, here is a description of the property: (Storage requirements (free space required).) here are some related sections: Technical Specifications > Hardware

Based *only* on the context provided above, answer the question. If the context does not contain the information needed to answer the question, respond with the exact phrase "Information not found".

Answer: Information not found.

### English to English 
In this example, the context tokens are 'unforced', meaning the model automatically predicts the output language
(English) and task (transcribe).

Question: Find the storage Requirements in the following text, here is a description of the property: (Storage requirements (free space required).) here are some related sections: Technical Specifications > Hardware

Based *only* on the context provided above, answer the question. If the context does not contain the information needed to answer the question, respond with the exact phrase "Information not found".

Answer: Information not found.

### English to English 
In this example, the context tokens are 'unforced', meaning the model automatically predicts the output language
(English) and task (transcribe).

Question: Find the storage Requirements in the following text, here is a description of the property: (Storage requirements (free space required).) here are some related sections: Technical Specifications > Hardware

Based *only* on the context provided above, answer the question. If the context does not contain the information needed to answer the question, respond with the exact phrase "Information not found".

Answer: Information not found.

### English to English 
In this example, the context tokens are 'unforced', meaning the model automatically predicts the output language
(English) and task (transcribe).

Question: Find the storage Requirements in the following text, here is a description of the property: (Storage requirements (free space required).) here are some related sections: Technical Specifications > Hardware

Based *only* on the context provided above, answer the question. If the context does not contain the information needed to answer the question, respond with the exact phrase "Information not found".

Answer: Information not found.

### English to English 
In this example, the context tokens are 'unforced', meaning the model automatically predicts the output language
(English) and task (transcribe).

Question: Find the storage Requirements in the following text, here is a description of the property: (Storage requirements (free space required).) here are some related sections: Technical Specifications > Hardware

Based *only* on the context provided above, answer the question. If the context does not contain the information needed to answer the question, respond with the exact phrase "Information not found".

Answer: Information not found.

### English to English 
In this example, the context tokens are 'unforced', meaning the model automatically predicts the output language
(English) and task (transcribe).

Question: Find the storage Requirements in the following text, here is a description of the property: (Storage requirements (free space required).) here are some related sections: Technical Specifications > Hardware

Based *only* on the context provided above, answer the question. If the context does not contain the information needed to answer the question, respond with the exact phrase "Information not found".

Answer: Information not found.

### English to English 
In this example, the context tokens are 'unforced', meaning the model automatically predicts the output language
(English) and task (transcribe).

Question: Find the storage Requirements in the following text, here is a description of the property: (Storage requirements (free space required).) here are some related sections: Technical Specifications > Hardware

Based *only* on the context provided above, answer the question. If the context does not contain the information needed to answer the question, respond with the exact phrase "Information not found".

Answer: Information not found.

### English to English 
In this example, the context tokens are 'unforced', meaning the model automatically predicts the output language
(English) and task (transcribe).

Question: Find the storage Requirements in the following text, here is a description of the property: (Storage requirements (free space required).) here are some related sections: Technical Specifications > Hardware

Based *only* on the context provided above, answer the question. If the context does not contain the information needed to answer the question, respond with the exact phrase "Information not found".

Answer: Information not found.

### English to English 
In this example, the context tokens are 'unforced', meaning the model automatically predicts the output language
(English) and task (transcribe).

Question: Find the storage Requirements in the following text, here is a description of the property: (Storage requirements (free space required).) here are some related sections: Technical Specifications > Hardware

Based *only* on the context provided above, answer the question. If the context does not contain the information needed to answer the question, respond with the exact phrase \""""^^xsd:string ;
    schema:url <https://huggingface.co/openai/whisper-base> ;
    schema:version "Information not found."^^xsd:string ;
    ns3:buildInstructions "Information not found."^^xsd:string ;
    ns3:developmentStatus """Information not found.

### English to English 
In this example, the context tokens are 'unforced', meaning the model automatically predicts the output language
(English) and task (transcribe).

Question: Find the development Status in the following text, here is a description of the property: (Description of development status, e.g. Active, inactive, suspended. See repostatus.org) here are some related sections: More Information 

Based *only* on the context provided above, answer the question. If the context does not contain the information needed to answer the question, respond with the exact phrase "Information not found".

Answer: Information not found.

### English to English 
In this example, the context tokens are 'unforced', meaning the model automatically predicts the output language
(English) and task (transcribe).

Question: Find the development Status in the following text, here is a description of the property: (Description of development status, e.g. Active, inactive, suspended. See repostatus.org) here are some related sections: More Information 

Based *only* on the context provided above, answer the question. If the context does not contain the information needed to answer the question, respond with the exact phrase "Information not found".

Answer: Information not found.

### English to English 
In this example, the context tokens are 'unforced', meaning the model automatically predicts the output language
(English) and task (transcribe).

Question: Find the development Status in the following text, here is a description of the property: (Description of development status, e.g. Active, inactive, suspended. See repostatus.org) here are some related sections: More Information 

Based *only* on the context provided above, answer the question. If the context does not contain the information needed to answer the question, respond with the exact phrase "Information not found".

Answer: Information not found.

### English to English 
In this example, the context tokens are 'unforced', meaning the model automatically predicts the output language
(English) and task (transcribe).

Question: Find the development Status in the following text, here is a description of the property: (Description of development status, e.g. Active, inactive, suspended. See repostatus.org) here are some related sections: More Information 

Based *only* on the context provided above, answer the question. If the context does not contain the information needed to answer the question, respond with the exact phrase "Information not found".

Answer: Information not found.

### English to English 
In this example, the context tokens are 'unforced', meaning the model automatically predicts the output language
(English) and task (transcribe).

Question: Find the development Status in the following text, here is a description of the property: (Description of development status, e.g. Active, inactive, suspended. See repostatus.org) here are some related sections: More Information 

Based *only* on the context provided above, answer the question. If the context does not contain the information needed to answer the question, respond with the exact phrase "Information not found".

Answer: Information not found.

### English to English 
In this example, the context tokens are 'unforced', meaning the model automatically predicts the output language
(English) and task (transcribe).

Question: Find the development Status in the following text, here is a description of the property: (Description of development status, e.g. Active, inactive, suspended. See repostatus.org) here are some related sections: More Information 

Based *only* on the context provided above, answer the question. If the context does not contain the information needed to answer the question, respond with the exact phrase "Information not found".

Answer: Information not found.

### English to English 
In this example, the context tokens are 'unforced', meaning the model automatically predicts the output language
(English) and task (transcribe).

Question: Find the development Status in the following text, here is a description of the property: (Description of development status, e.g. Active, inactive, suspended. See repostatus.org) here are some related sections: More Information 

Based *only* on the context provided above, answer the question. If the context does not contain the information needed to answer the question, respond with the exact phrase "Information not found".

Answer: Information not found.

### English to English 
In this example, the context tokens are 'unforced', meaning the model automatically predicts the output language
(English) and task (transcribe).

Question: Find the development Status in the following text, here is a description of the property: (Description of development status, e.g. Active, inactive, suspended. See repostatus.org) here are some related sections: More Information 

Based *only* on the context provided above, answer the question. If the context does not contain the information needed to answer the question, respond with the exact phrase "Information not found".

Answer: Information not found.

### English to English 
In this example, the context tokens are 'unforced', meaning the model automatically predicts the output language
(English) and task (transcribe).

Question: Find the development Status in the following text, here is a description of the property: (Description of development status, e.g. Active, inactive, suspended. See repostatus.org) here are some related sections: More Information 

Based *only* on the context provided above, answer the question. If the context does not contain the information needed to answer the question, respond with the exact phrase "Information not found".

Answer: Information not found.

### English to English 
In this example, the context tokens are 'unforced', meaning the model automatically predicts the output language
(English) and task (transcribe).

Question: Find the development Status in the following text, here is a description of the property: (Description of development status, e.g. Active, inactive, suspended. See repostatus.org) here are some related sections: More Information 

Based *only* on the context provided above, answer the question. If the context does not contain the information needed to answer the question, respond with the exact phrase "Information not found".

Answer: Information not found.

### English to English 
In this example, the context tokens are 'unforced', meaning the model automatically predicts the output language
(English) and task (transcribe).

Question: Find the development Status in the following text, here is a description of the property: (Description of development status, e.g. Active, inactive, suspended. See repostatus.org) here are some related sections: More Information 

Based *only* on the context provided above, answer the question. If the context does not contain the information needed to answer the question, respond with the exact phrase "Information not found".

Answer: Information not found.

### English to English 
In this example, the context tokens are 'unforced', meaning the model automatically predicts the output language
(English) and task (transcribe).

Question: Find the development Status in the following text, here is a description of the property: (Description of development status, e.g. Active, inactive, suspended. See repostatus.org) here are some related sections: More Information 

Based *only* on the context provided above, answer the question. If the context does not contain the information needed to answer the question, respond with the exact phrase "Information not found".

Answer: Information not found.

### English to English 
In this example, the context tokens are 'unforced', meaning the model automatically predicts the output language
(English) and task (transcribe).

Question: Find the development Status in the following text, here is a description of the property: (Description of development status, e.g. Active, inactive, suspended. See repostatus.org) here are some related sections: More Information 

Based *only* on the context provided above, answer the question. If the context does not contain the information needed to answer the question, respond with the exact phrase "Information not found".

Answer: Information not found.

### English to English 
In this example, the context tokens are 'unforced', meaning the model automatically predicts the output language
(English) and task (transcribe).

Question: Find the development Status in the following text, here is a description of the property: (Description of development status, e.g. Active, inactive, suspended. See repostatus.org) here are some related sections: More Information 

Based *only* on the context provided above, answer the question. If the context does not contain the information needed to answer the question, respond with the exact phrase "Information not found".

Answer: Information not found.

### English to English 
In this example, the context tokens are 'unforced', meaning the model automatically predicts the output language
(English) and task (transcribe).

Question: Find the development Status in the following text, here is a description of the property: (Description of development status, e.g. Active, inactive, suspended. See repostatus.org) here are some related sections: More Information 

Based *only* on the context provided above, answer the question. If the context does not contain the information needed to answer the question, respond with the exact phrase "Information not found".

Answer: Information not found.

### English to English 
In this example, the context tokens are 'unforced', meaning the model automatically predicts the output language
(English) and task (transcribe).

Question: Find the development Status in the following text, here is a description of the property: (Description of development status, e.g. Active, inactive, suspended. See repostatus.org) here are some related sections: More Information 

Based *only* on the context provided"""^^xsd:string ;
    ns3:issueTracker <https://huggingface.co/openai/whisper-base/discussions> ;
    ns3:readme <https://huggingface.co/openai/whisper-base/blob/main/README.md> ;
    ns3:referencePublication <http://mlentory.zbmed.de/mlentory_graph/79549f00e6767e7c56b491b734b5ec351d3faaae4afc546b64c29d0146128a68> .

<http://mlentory.zbmed.de/mlentory_graph/21a4b3b0fe861021548d89e241eb815b3c147c6d12ec9eade6925be45bc78650> a schema:DefinedTerm ;
    schema:description "Transforms audio signals from one form to another."^^xsd:string ;
    schema:name "Audio to Audio"^^xsd:string .

<http://mlentory.zbmed.de/mlentory_graph/251690051accbb99d763e77f3aed9b94caecf82b9e2db7c17f8adfca42a4ca39> a schema:DefinedTerm ;
    schema:description "Creates concise summaries of longer texts."^^xsd:string ;
    schema:name "Summarization"^^xsd:string .

<http://mlentory.zbmed.de/mlentory_graph/25a48b7b32ec31051c00ea96f30d1637f216eb0ed7620da77d06c4637ab5da7f> a schema:DefinedTerm ;
    schema:description "Categorizes images into predefined classes or labels."^^xsd:string ;
    schema:name "Image Classification"^^xsd:string .

<http://mlentory.zbmed.de/mlentory_graph/266c130bc128debb0db48b7a2e58c6423c7bafb2445fcccd68e2da192f3487d1> a schema:DefinedTerm ;
    schema:description "Converts visual content from images into textual representations."^^xsd:string ;
    schema:name "Image toText"^^xsd:string .

<http://mlentory.zbmed.de/mlentory_graph/293ad034f899dc681b5be10c715f25c59fa7f5261f229b66d796246e10927354> a schema:DefinedTerm ;
    schema:description "Unity plugin that enables games and simulations to serve as environments for training intelligent agents."^^xsd:string ;
    schema:name "ml-agents"^^xsd:string .

<http://mlentory.zbmed.de/mlentory_graph/2ae536499f90e7e5edcd87dddf0d258801cae8e7a2f82d8ce02361ef54e77c05> a schema:DefinedTerm ;
    schema:description "Apple's framework for integrating machine learning models into iOS, macOS, watchOS, and tvOS apps."^^xsd:string ;
    schema:name "Core ML"^^xsd:string .

<http://mlentory.zbmed.de/mlentory_graph/2f28cc27d9dac219caa56a5425741f7391153065f1558fe7418d6ccc1c598fb4> a schema:DefinedTerm ;
    schema:description "Applies AI for robot control, perception, and decision-making."^^xsd:string ;
    schema:name "Robotics"^^xsd:string .

<http://mlentory.zbmed.de/mlentory_graph/2f45196854d69c3bcc21304aceb64e2a3db2d17613399d7d3c7a21611573a4d5> a schema:DefinedTerm ;
    schema:description "Models with documented carbon footprint information related to their training process."^^xsd:string ;
    schema:name "Carbon Emissions"^^xsd:string .

<http://mlentory.zbmed.de/mlentory_graph/3135ad7c615e157f80ecab1b96d4167d2e6c147b2e563721a652a5b56845418c> a schema:DefinedTerm ;
    schema:description "Collection of SOTA computer vision models, layers, utilities, and optimizers for training and inferencing."^^xsd:string ;
    schema:name "timm"^^xsd:string .

<http://mlentory.zbmed.de/mlentory_graph/316fd1b6c56f67729f7e0880d91953804a9af869ce76b2906f26f3d534937931> a schema:DefinedTerm ;
    schema:description "Topic modeling technique that leverages BERT embeddings and clustering for document topic extraction."^^xsd:string ;
    schema:name "BERTopic"^^xsd:string .

<http://mlentory.zbmed.de/mlentory_graph/35d7d276230081bdfd86d06ca958126011d6a7e381452a488c2bfa8fcc512fdb> a schema:DefinedTerm ;
    schema:description "Architecture where multiple specialized sub-models (experts) are conditionally activated based on input."^^xsd:string ;
    schema:name "Mixture of Experts"^^xsd:string .

<http://mlentory.zbmed.de/mlentory_graph/3b4b981961ee604488ce9db2b6cea45a4fb777fb6ee8ef76bb274e14ff6cbdf4> a schema:DefinedTerm ;
    schema:description "Trains agents through interaction with environments using rewards."^^xsd:string ;
    schema:name "Reinforcement Learning"^^xsd:string .

<http://mlentory.zbmed.de/mlentory_graph/3db362f2d160db0ec9efef6e48b6ba6fc466784d4fdf38393a2818c9c974f93e> a schema:DefinedTerm ;
    schema:description "Deep learning library that simplifies training neural networks using modern best practices."^^xsd:string ;
    schema:name "fastai"^^xsd:string .

<http://mlentory.zbmed.de/mlentory_graph/40e5b840897abb6f44300acdb8df19e9ba787840ae3899b5cff54ee848bd4df6> a schema:DefinedTerm ;
    schema:description "Predicts the depth of objects in images for 3D scene understanding."^^xsd:string ;
    schema:name "Depth Estimation"^^xsd:string .

<http://mlentory.zbmed.de/mlentory_graph/427579e1091b3a9a3bf55b54c4167319ee1e7fd37d7a1389722fcb73d6a8901c> a schema:DefinedTerm ;
    schema:description "Classifies images into categories not seen during training."^^xsd:string ;
    schema:name "Zero Shot Image Classification"^^xsd:string .

<http://mlentory.zbmed.de/mlentory_graph/435f6e89d90ad4bd6be870aa7e1a66a9ce6bb4c201cdc1adf4aec7db47ff1148> a schema:DefinedTerm ;
    schema:description "Generates audio content from textual descriptions."^^xsd:string ;
    schema:name "Text to Audio"^^xsd:string .

<http://mlentory.zbmed.de/mlentory_graph/43625c04f736f13b1f357a0d9357ed3dbc8e216e352796b03fb0fa69aea1f93b> a schema:DefinedTerm ;
    schema:description "Models based on XLM-RoBERTa, a cross-lingual version of RoBERTa pretrained on text from 100 languages for multilingual understanding."^^xsd:string ;
    schema:name "xlm-roberta"^^xsd:string .

<http://mlentory.zbmed.de/mlentory_graph/44d2e9d41b9d9f9819feb864a1a07b499ce696259552757d8bcdf74cfc53f4e7> a schema:Organization .

<http://mlentory.zbmed.de/mlentory_graph/45ef55138ac28324915f59dee5c5614894be22d29e2a8283b76835bcb91e3e87> a schema:DefinedTerm ;
    schema:description "Answers natural language questions about images."^^xsd:string ;
    schema:name "Visual Question Answering"^^xsd:string .

<http://mlentory.zbmed.de/mlentory_graph/46fd5133284e3f6058330c31c628a6854b5eeb608d471e58c7052d9365f5acf4> a schema:DefinedTerm ;
    schema:description "Extracts meaningful features from images for downstream tasks."^^xsd:string ;
    schema:name "Image Feature Extraction"^^xsd:string .

<http://mlentory.zbmed.de/mlentory_graph/49bf7b39c8a2a4cb84ab43bc3c320de6e0c1da1253ebf022a5d0a84737581119> a schema:DefinedTerm ;
    schema:description "Converts image content into textual descriptions or captions."^^xsd:string ;
    schema:name "Image Text to Text"^^xsd:string .

<http://mlentory.zbmed.de/mlentory_graph/4acb0244517b271c7719eadb638a9049f7dfa43a14bf6eb119d83c2dbc6d856f> a schema:DefinedTerm ;
    schema:description "Sequence modeling toolkit for training custom models for translation, summarization, and other text generation tasks."^^xsd:string ;
    schema:name "Fairseq"^^xsd:string .

<http://mlentory.zbmed.de/mlentory_graph/4e5443728f51b2323bf3a1c4a6a6d8612484cbca0a8b0beeb5fb0258d1df5196> a schema:DefinedTerm ;
    schema:description "Open Neural Network Exchange format that enables interoperability between different ML frameworks."^^xsd:string ;
    schema:name "ONNX"^^xsd:string .

<http://mlentory.zbmed.de/mlentory_graph/4eaeba2a8985fdb21e18ca1e967f067a345c0498ed10fc3e5e9ba95e39876cab> a schema:DefinedTerm ;
    schema:description "Categorizes rows in tabular data into predefined classes."^^xsd:string ;
    schema:name "Tabular Classification"^^xsd:string .

<http://mlentory.zbmed.de/mlentory_graph/5294100683a6737ae3cdcdb512f4b8459993c27fd8f86917ce5e595178c28f6d> a schema:DefinedTerm ;
    schema:description "Extracts answers from documents based on questions."^^xsd:string ;
    schema:name "Document Question Answering"^^xsd:string .

<http://mlentory.zbmed.de/mlentory_graph/55c2ef29f4fc34014e7c41f2439cd686ebcc0bd4d1a02299b7491148b03bd06b> a schema:DefinedTerm ;
    schema:description "Models with custom implementation code beyond standard library functionality."^^xsd:string ;
    schema:name "custom_code"^^xsd:string .

<http://mlentory.zbmed.de/mlentory_graph/55f0c4818716a5c86a051b41b27450e6f00f7e81d8a89b0f3bd6928719ce08e4> a schema:DefinedTerm ;
    schema:description "Library for lightweight pipelining in Python, used for saving/loading Python objects and parallelizing loops."^^xsd:string ;
    schema:name "Joblib"^^xsd:string .

<http://mlentory.zbmed.de/mlentory_graph/5670ef7e87a4fbee3fa95024561f672fca6cc6a159a62e20ed73b98d267a72bd> a schema:DefinedTerm ;
    schema:description "JavaScript library for running transformer models in browsers and Node.js environments."^^xsd:string ;
    schema:name "Transformers.js"^^xsd:string .

<http://mlentory.zbmed.de/mlentory_graph/5931df18dd0fa4a7991df9c03e52fe5074eee570f6c3e7b480947ec85d10c3a1> a schema:DefinedTerm ;
    schema:description "Toolkit for optimizing and deploying deep learning models across Intel hardware."^^xsd:string ;
    schema:name "OpenVINO"^^xsd:string .

<http://mlentory.zbmed.de/mlentory_graph/59b663660275b892172a573e140e5eeec1a75e54c1838aea8d6f78d0f6286eba> a schema:DefinedTerm ;
    schema:description "Models that can be fine-tuned using HuggingFace's AutoTrain service without requiring manual code."^^xsd:string ;
    schema:name "AutoTrain Compatible"^^xsd:string .

<http://mlentory.zbmed.de/mlentory_graph/5c6c7a9e81be05e126c2ff79f262747bcaa13dce4de3db78679e947f541d5911> a schema:DefinedTerm ;
    schema:description "Industrial-strength NLP library with pre-trained models and support for 65+ languages."^^xsd:string ;
    schema:name "spaCy"^^xsd:string .

<http://mlentory.zbmed.de/mlentory_graph/5e024d2fef42dd138d6c91ca7012fa0cb6a7c9b768dddc020929481a5d411f33> a ns1:ML_Model ;
    ns1:ethicalLegalSocial "Information not found."^^xsd:string ;
    ns1:evaluatedOn "Information not found"^^xsd:string ;
    ns1:fineTunedFrom "Information not found"^^xsd:string ;
    ns1:hasCO2eEmissions "Information not found."^^xsd:string ;
    ns1:intendedUse "The intended use of the Mistral-7B-Instruct-v0.2 model is not explicitly stated in the given context."^^xsd:string ;
    ns1:mlTask <http://mlentory.zbmed.de/mlentory_graph/6925cb204ab4d5280c948ac7e23dd8f7b48d1de433cf9edc5c30a8d87ce3b317> ;
    ns1:modelCategory "The model category is not explicitly mentioned in the provided context."^^xsd:string ;
    ns1:modelRisks "Information not found."^^xsd:string ;
    ns1:sharedBy <http://mlentory.zbmed.de/mlentory_graph/f5a6a15b057055acaed46aabd835cf3eb56fa2343723cec43da3298c6a298537> ;
    ns1:testedOn "Information not found"^^xsd:string ;
    ns1:trainedOn "Information not found"^^xsd:string ;
    ns1:usageInstructions """To get started with the Mistral 7B Instruct model, follow these steps:

1. **Installation**: Ensure you have the necessary dependencies installed. You can install them using pip:
   ```bash
   pip install transformers
   ```

2. **Loading the Model**: Load the model using the `AutoModelForCausalLM` class from the `transformers` library:
   ```python
   from transformers import AutoModelForCausalLM, AutoTokenizer

   model_name = "mistralai/Mistral-7B-Instruct-v0.2"
   tokenizer = AutoTokenizer.from_pretrained(model_name)
   model = AutoModelForCausalLM.from_pretrained(model_name)
   ```

3. **Tokenizing Input**: Tokenize your input text using the tokenizer:
   ```python
   input_text = "Your input text here"
   inputs = tokenizer(input_text, return_tensors="pt")
   ```

4. **Generating Output**: Generate output using the model:
   ```python
   output = model.generate(**inputs)
   ```

5. **Decoding Output**: Decode the generated output to get the text:
   ```python
   output_text = tokenizer.decode(output[0], skip_special_tokens=True)
   print(output_text)
   ```

For more detailed instructions and examples, refer to the [official documentation](https://huggingface.co/mistralai/Mistral-7B-Instruct-v0.2) or the [Hugging Face Transformers GitHub repository](https://github.com/huggingface/transformers).

**Uses:**

- **Direct Use**: The Mistral 7B Instruct model can be used directly for various tasks such as text generation, question answering, and more. It is designed to be easily fine-tuned for specific applications.

- **Fine-Tuning**: The model can be fine-tuned for specific tasks using the `Trainer` class from the `transformers` library. This allows for customization and adaptation to specific domains or datasets.

- **Moderation**: While the model does not have moderation mechanisms by default, it is designed to be easily fine-tuned to respect guardrails and can be used in environments requiring moderated outputs.

- **Deployment**: The model can be deployed in various environments, including cloud platforms and local servers, using the `transformers` library's deployment tools.

- **Community Engagement**: The community is encouraged to engage with the model and provide feedback on ways to make it more suitable for deployment in moderated environments."""^^xsd:string ;
    ns1:validatedOn "Information not found."^^xsd:string ;
    schema:archivedAt <https://huggingface.co/lachiewyoung/test-mistral-7b> ;
    schema:author "The context provided does not contain any information about the author of the text."^^xsd:string ;
    schema:citation "Information not found."^^xsd:string ;
    schema:conditionsOfAccess "Information not found."^^xsd:string ;
    schema:contributor "The information provided does not contain the name of the contributor to the CreativeWork."^^xsd:string ;
    schema:copyrightHolder "The copyright holder for the Mistral-7B-Instruct-v0.2 model is not mentioned in the provided context."^^xsd:string ;
    schema:dateCreated "2024-03-04T01:31:41+00:00"^^xsd:dateTime ;
    schema:dateModified "2024-03-04T01:33:40+00:00"^^xsd:dateTime ;
    schema:datePublished "2024-03-04T01:31:41+00:00"^^xsd:dateTime ;
    schema:description """---
license: apache-2.0
pipeline_tag: text-generation
tags:
- finetuned
inference: true
widget:
- messages:
  - role: user
    content: What is your favorite condiment?
---

# Model Card for Mistral-7B-Instruct-v0.2

The Mistral-7B-Instruct-v0.2 Large Language Model (LLM) is an improved instruct fine-tuned version of [Mistral-7B-Instruct-v0.1](https://huggingface.co/mistralai/Mistral-7B-Instruct-v0.1).

For full details of this model please read our [paper](https://arxiv.org/abs/2310.06825) and [release blog post](https://mistral.ai/news/la-plateforme/).

## Instruction format

In order to leverage instruction fine-tuning, your prompt should be surrounded by `[INST]` and `[/INST]` tokens. The very first instruction should begin with a begin of sentence id. The next instructions should not. The assistant generation will be ended by the end-of-sentence token id.

E.g.
```
text = "<s>[INST] What is your favourite condiment? [/INST]"
"Well, I'm quite partial to a good squeeze of fresh lemon juice. It adds just the right amount of zesty flavour to whatever I'm cooking up in the kitchen!</s> "
"[INST] Do you have mayonnaise recipes? [/INST]"
```

This format is available as a [chat template](https://huggingface.co/docs/transformers/main/chat_templating) via the `apply_chat_template()` method:

```python
from transformers import AutoModelForCausalLM, AutoTokenizer

device = "cuda" # the device to load the model onto

model = AutoModelForCausalLM.from_pretrained("mistralai/Mistral-7B-Instruct-v0.2")
tokenizer = AutoTokenizer.from_pretrained("mistralai/Mistral-7B-Instruct-v0.2")

messages = [
    {"role": "user", "content": "What is your favourite condiment?"},
    {"role": "assistant", "content": "Well, I'm quite partial to a good squeeze of fresh lemon juice. It adds just the right amount of zesty flavour to whatever I'm cooking up in the kitchen!"},
    {"role": "user", "content": "Do you have mayonnaise recipes?"}
]

encodeds = tokenizer.apply_chat_template(messages, return_tensors="pt")

model_inputs = encodeds.to(device)
model.to(device)

generated_ids = model.generate(model_inputs, max_new_tokens=1000, do_sample=True)
decoded = tokenizer.batch_decode(generated_ids)
print(decoded[0])
```

## Model Architecture
This instruction model is based on Mistral-7B-v0.1, a transformer model with the following architecture choices:
- Grouped-Query Attention
- Sliding-Window Attention
- Byte-fallback BPE tokenizer

## Troubleshooting
- If you see the following error:
```
Traceback (most recent call last):
File "", line 1, in
File "/transformers/models/auto/auto_factory.py", line 482, in from_pretrained
config, kwargs = AutoConfig.from_pretrained(
File "/transformers/models/auto/configuration_auto.py", line 1022, in from_pretrained
config_class = CONFIG_MAPPING[config_dict["model_type"]]
File "/transformers/models/auto/configuration_auto.py", line 723, in getitem
raise KeyError(key)
KeyError: 'mistral'
```

Installing transformers from source should solve the issue
pip install git+https://github.com/huggingface/transformers

This should not be required after transformers-v4.33.4.

## Limitations

The Mistral 7B Instruct model is a quick demonstration that the base model can be easily fine-tuned to achieve compelling performance. 
It does not have any moderation mechanisms. We're looking forward to engaging with the community on ways to
make the model finely respect guardrails, allowing for deployment in environments requiring moderated outputs.

## The Mistral AI Team

Albert Jiang, Alexandre Sablayrolles, Arthur Mensch, Blanche Savary, Chris Bamford, Devendra Singh Chaplot, Diego de las Casas, Emma Bou Hanna, Florian Bressand, Gianna Lengyel, Guillaume Bour, Guillaume Lample, Lélio Renard Lavaud, Louis Ternon, Lucile Saulnier, Marie-Anne Lachaux, Pierre Stock, Teven Le Scao, Théophile Gervet, Thibaut Lavril, Thomas Wang, Timothée Lacroix, William El Sayed."""^^xsd:string ;
    schema:discussionUrl <https://huggingface.co/lachiewyoung/test-mistral-7b/discussions> ;
    schema:distribution "Information not found."^^xsd:string ;
    schema:funding "The context provided does not contain any information about the funding in the given text. Therefore, the answer is \"Information not found\"."^^xsd:string ;
    schema:identifier "https://huggingface.co/lachiewyoung/test-mistral-7b"^^xsd:string ;
    schema:inLanguage "Information not found"^^xsd:string ;
    schema:keywords <http://mlentory.zbmed.de/mlentory_graph/0dce0f5e7319b6178cd79d5f2163f0e134d0064f4ea4f93e8afeec1e7d78fa8d>,
        <http://mlentory.zbmed.de/mlentory_graph/3e9a4e1232f617b33fa8460d6c142ee49e69eb5c55acfd1e618d58e7495955e8>,
        <http://mlentory.zbmed.de/mlentory_graph/61cce84de930f0da8c78ddef3203a2afac70cf5e46684f0407180738cd821965>,
        <http://mlentory.zbmed.de/mlentory_graph/79cf083846a8329d2912fcd7f375233c37a54917af291bb945f0b58bc735b8ad>,
        <http://mlentory.zbmed.de/mlentory_graph/81c4f52fcccf6ef0d25453aedb7cebe30c7034e3b2fa752246d0e43da889a0e1>,
        <http://mlentory.zbmed.de/mlentory_graph/87b927fef88a46248b3b208472aec7bfeb38667386b309f46772e26b40f6affb>,
        <http://mlentory.zbmed.de/mlentory_graph/d24e90f006bf4dfce8be9dbaf9c92d1449f40b988b6cc52d60e48c40331dc607>,
        <http://mlentory.zbmed.de/mlentory_graph/ddb15bfa0ef843723bc4c8a81ab1d826b1fc4ff36ed13faf8f8f3841261978b8>,
        <http://mlentory.zbmed.de/mlentory_graph/df4982af808ead1a57663cc7a83e60059f6a6ae1baf83a270fdf8bdfef11a3de>,
        <http://mlentory.zbmed.de/mlentory_graph/f59cf55f3a86acf0bcfc020eac552a72c13f1212154211a7bf30504548661f8d>,
        "arxiv:2310.06825"^^xsd:string,
        "license:apache-2.0"^^xsd:string,
        "region:us"^^xsd:string ;
    schema:license "apache-2.0"^^xsd:string ;
    schema:maintainer "Information not found."^^xsd:string ;
    schema:memoryRequirements "Not available"^^xsd:string ;
    schema:name "test-mistral-7b"^^xsd:string ;
    schema:operatingSystem "The operating systems supported by the Mistral-7B-Instruct-v0.2 model are Windows 7, OSX 10.6, and Android 1.6."^^xsd:string ;
    schema:processorRequirements "Information not found."^^xsd:string ;
    schema:releaseNotes """---
license: apache-2.0
pipeline_tag: text-generation
tags:
- finetuned
inference: true
widget:
- messages:
  - role: user
    content: What is your favorite condiment?
---

# Model Card for Mistral-7B-Instruct-v0.2

The Mistral-7B-Instruct-v0.2 Large Language Model (LLM) is an improved instruct fine-tuned version of [Mistral-7B-Instruct-v0.1](https://huggingface.co/mistralai/Mistral-7B-Instruct-v0.1).

For full details of this model please read our [paper](https://arxiv.org/abs/2310.06825) and [release blog post](https://mistral.ai/news/la-plateforme/).

## Instruction format

In order to leverage instruction fine-tuning, your prompt should be surrounded by `[INST]` and `[/INST]` tokens. The very first instruction should begin with a begin of sentence id. The next instructions should not. The assistant generation will be ended by the end-of-sentence token id.

E.g.
```
text = "<s>[INST] What is your favourite condiment? [/INST]"
"Well, I'm quite partial to a good squeeze of fresh lemon juice. It adds just the right amount of zesty flavour to whatever I'm cooking up in the kitchen!</s> "
"[INST] Do you have mayonnaise recipes? [/INST]"
```

This format is available as a [chat template](https://huggingface.co/docs/transformers/main/chat_templating) via the `apply_chat_template()` method:

```python
from transformers import AutoModelForCausalLM, AutoTokenizer

device = "cuda" # the device to load the model onto

model = AutoModelForCausalLM.from_pretrained("mistralai/Mistral-7B-Instruct-v0.2")
tokenizer = AutoTokenizer.from_pretrained("mistralai/Mistral-7B-Instruct-v0.2")

messages = [
    {"role": "user", "content": "What is your favourite condiment?"},
    {"role": "assistant", "content": "Well, I'm quite partial to a good squeeze of fresh lemon juice. It adds just the right amount of zesty flavour to whatever I'm cooking up in the kitchen!"},
    {"role": "user", "content": "Do you have mayonnaise recipes?"}
]

encodeds = tokenizer.apply_chat_template(messages, return_tensors="pt")

model_inputs = encodeds.to(device)
model.to(device)

generated_ids = model.generate(model_inputs, max_new_tokens=1000, do_sample=True)
decoded = tokenizer.batch_decode(generated_ids)
print(decoded[0])
```

## Model Architecture
This instruction model is based on Mistral-7B-v0.1, a transformer model with the following architecture choices:
- Grouped-Query Attention
- Sliding-Window Attention
- Byte-fallback BPE tokenizer

## Troubleshooting
- If you see the following error:
```
Traceback (most recent call last):
File "", line 1, in
File "/transformers/models/auto/auto_factory.py", line 482, in from_pretrained
config, kwargs = AutoConfig.from_pretrained(
File "/transformers/models/auto/configuration_auto.py", line 1022, in from_pretrained
config_class = CONFIG_MAPPING[config_dict["model_type"]]
File "/transformers/models/auto/configuration_auto.py", line 723, in getitem
raise KeyError(key)
KeyError: 'mistral'
```

Installing transformers from source should solve the issue
pip install git+https://github.com/huggingface/transformers

This should not be required after transformers-v4.33.4.

## Limitations

The Mistral 7B Instruct model is a quick demonstration that the base model can be easily fine-tuned to achieve compelling performance. 
It does not have any moderation mechanisms. We're looking forward to engaging with the community on ways to
make the model finely respect guardrails, allowing for deployment in environments requiring moderated outputs.

## The Mistral AI Team

Albert Jiang, Alexandre Sablayrolles, Arthur Mensch, Blanche Savary, Chris Bamford, Devendra Singh Chaplot, Diego de las Casas, Emma Bou Hanna, Florian Bressand, Gianna Lengyel, Guillaume Bour, Guillaume Lample, Lélio Renard Lavaud, Louis Ternon, Lucile Saulnier, Marie-Anne Lachaux, Pierre Stock, Teven Le Scao, Théophile Gervet, Thibaut Lavril, Thomas Wang, Timothée Lacroix, William El Sayed."""^^xsd:string ;
    schema:softwareHelp "Information not found."^^xsd:string ;
    schema:softwareRequirements "The software requirements for the Mistral-7B-Instruct-v0.2 model are not explicitly mentioned in the provided context."^^xsd:string ;
    schema:storageRequirements "The storage requirements for the Mistral-7B-Instruct-v0.2 model are not explicitly mentioned in the provided context."^^xsd:string ;
    schema:url <https://huggingface.co/lachiewyoung/test-mistral-7b> ;
    schema:version "The version of the CreativeWork embodied by a specified resource is not mentioned in the provided context."^^xsd:string ;
    ns3:buildInstructions "Information not found."^^xsd:string ;
    ns3:developmentStatus "Information not found."^^xsd:string ;
    ns3:issueTracker <https://huggingface.co/lachiewyoung/test-mistral-7b/discussions> ;
    ns3:readme <https://huggingface.co/lachiewyoung/test-mistral-7b/blob/main/README.md> ;
    ns3:referencePublication <http://mlentory.zbmed.de/mlentory_graph/1fb09733dc3261eb13aa123f1d418af5be3d14c3a0d5b123fb23f1b9f5234a31> .

<http://mlentory.zbmed.de/mlentory_graph/5e9f8dc5efdf686d003f27fc61cf3a0b9e5dbed094499e8e3332f5c535d686f3> a schema:DefinedTerm ;
    schema:description "End-to-end speech processing toolkit covering ASR, TTS, speech translation, and speech enhancement."^^xsd:string ;
    schema:name "ESPnet"^^xsd:string .

<http://mlentory.zbmed.de/mlentory_graph/5f8c97c4aaca5a8c6afac1954a68be2dcb40698e64871f37e5fe5dc5849a3aab> a schema:DefinedTerm ;
    schema:description "Measures how similar two sentences are semantically."^^xsd:string ;
    schema:name "Sentence Similarity"^^xsd:string .

<http://mlentory.zbmed.de/mlentory_graph/6803a9142550ca466078b0794746397f37034f277ce6f45bb7f252be171ab407> a schema:DefinedTerm ;
    schema:description "Creates images without specific text prompts or conditions."^^xsd:string ;
    schema:name "Unconditional Image Generation"^^xsd:string .

<http://mlentory.zbmed.de/mlentory_graph/6839f153ace4a5cfe1e9a1cdb43c1bfc2260f4c85be0608af5ec84a75a205d2c> a schema:DefinedTerm ;
    schema:description "Converts written text into spoken audio."^^xsd:string ;
    schema:name "Text to Speech"^^xsd:string .

<http://mlentory.zbmed.de/mlentory_graph/6b72a43d7396497fe9733cb91a9e688db073b7c1c583e2c5fca339bd414a4dac> a schema:DefinedTerm ;
    schema:description "General label indicating the model or dataset has been categorized with specific keywords for discoverability."^^xsd:string ;
    schema:name "tags"^^xsd:string .

<http://mlentory.zbmed.de/mlentory_graph/6b75cb265aea0eff37651595203eec38a2a621d81df99e4cfcd5f30cef590384> a schema:DefinedTerm ;
    schema:description "Toolkit for building, training, and fine-tuning GPU-accelerated conversational AI models."^^xsd:string ;
    schema:name "NeMo"^^xsd:string .

<http://mlentory.zbmed.de/mlentory_graph/6bdae8c542a61819acfd0767eb5e55cafba29955aaefd1261c204618a4d3a487> a schema:DefinedTerm ;
    schema:description "Models with published evaluation metrics, benchmarks, or test results available for review."^^xsd:string ;
    schema:name "Eval Results"^^xsd:string .

<http://mlentory.zbmed.de/mlentory_graph/6fa5b295a0420d9a3cc819e672ebdd61720c48761f8c2960d28ff7f7655875be> a schema:DefinedTerm ;
    schema:description "Provides answers to questions based on given context."^^xsd:string ;
    schema:name "Question Answering"^^xsd:string .

<http://mlentory.zbmed.de/mlentory_graph/6fd4d85e3416654bf33d9c5f3803b3e9900ce78a6309e4e6a84b2499ad4b7981> a schema:DefinedTerm ;
    schema:description "Simple framework for state-of-the-art NLP supporting tasks like named entity recognition and part-of-speech tagging."^^xsd:string ;
    schema:name "Flair"^^xsd:string .

<http://mlentory.zbmed.de/mlentory_graph/71fca9a99f0a6b21e4190b00f3deaecb6263287540aeefc8857cd9ae9ef6b603> a ns1:ML_Model ;
    ns1:ethicalLegalSocial "Information not found."^^xsd:string ;
    ns1:evaluatedOn "Information not found"^^xsd:string ;
    ns1:fineTunedFrom "Information not found"^^xsd:string ;
    ns1:hasCO2eEmissions "Information not found."^^xsd:string ;
    ns1:intendedUse "The primary intended users of these models are AI researchers studying robustness, generalization, capabilities, biases, and constraints of the current model."^^xsd:string ;
    ns1:mlTask <http://mlentory.zbmed.de/mlentory_graph/db86f2c8ce693db878b689231690fab2fe37b7ae1abc1e54dca9fae35bc0df0d> ;
    ns1:modelCategory "Information not found"^^xsd:string ;
    ns1:modelRisks "Information not found."^^xsd:string ;
    ns1:sharedBy <http://mlentory.zbmed.de/mlentory_graph/863d9e15edc2c98657749abae884b48544051490f76ea0e913adf85a3f2727a5> ;
    ns1:testedOn "Information not found"^^xsd:string ;
    ns1:trainedOn "Information not found"^^xsd:string ;
    ns1:usageInstructions "Information not found."^^xsd:string ;
    ns1:validatedOn "The context provided does not contain information about the validated On."^^xsd:string ;
    schema:archivedAt <https://huggingface.co/openai/whisper-base.en> ;
    schema:author "The author of this content is the Hugging Face team."^^xsd:string ;
    schema:citation "Information not found."^^xsd:string ;
    schema:conditionsOfAccess "Information not found."^^xsd:string ;
    schema:contributor "Information not found"^^xsd:string ;
    schema:copyrightHolder "Information not found."^^xsd:string ;
    schema:dateCreated "2022-09-26T06:58:29+00:00"^^xsd:dateTime ;
    schema:dateModified "2024-01-22T17:55:08+00:00"^^xsd:dateTime ;
    schema:datePublished "2022-09-26T06:58:29+00:00"^^xsd:dateTime ;
    schema:description """---
language:
- en
tags:
- audio
- automatic-speech-recognition
- hf-asr-leaderboard
widget:
- example_title: Librispeech sample 1
  src: https://cdn-media.huggingface.co/speech_samples/sample1.flac
- example_title: Librispeech sample 2
  src: https://cdn-media.huggingface.co/speech_samples/sample2.flac
pipeline_tag: automatic-speech-recognition
license: apache-2.0
model-index:
- name: whisper-base.en
  results:
  - task:
      type: automatic-speech-recognition
      name: Automatic Speech Recognition
    dataset:
      name: LibriSpeech (clean)
      type: librispeech_asr
      config: clean
      split: test
      args:
        language: en
    metrics:
    - type: wer
      name: Test WER
  - task:
      type: automatic-speech-recognition
      name: Automatic Speech Recognition
    dataset:
      name: LibriSpeech (other)
      type: librispeech_asr
      config: other
      split: test
      args:
        language: en
    metrics:
    - type: wer
      value: 12.803978669490565
      name: Test WER
---

# Whisper

Whisper is a pre-trained model for automatic speech recognition (ASR) and speech translation. Trained on 680k hours 
of labelled data, Whisper models demonstrate a strong ability to generalise to many datasets and domains **without** the need 
for fine-tuning.

Whisper was proposed in the paper [Robust Speech Recognition via Large-Scale Weak Supervision](https://arxiv.org/abs/2212.04356) 
by Alec Radford et al. from OpenAI. The original code repository can be found [here](https://github.com/openai/whisper).

**Disclaimer**: Content for this model card has partly been written by the Hugging Face team, and parts of it were 
copied and pasted from the original model card.

## Model details

Whisper is a Transformer based encoder-decoder model, also referred to as a _sequence-to-sequence_ model. 
It was trained on 680k hours of labelled speech data annotated using large-scale weak supervision. 

The models were trained on either English-only data or multilingual data. The English-only models were trained 
on the task of speech recognition. The multilingual models were trained on both speech recognition and speech 
translation. For speech recognition, the model predicts transcriptions in the *same* language as the audio. 
For speech translation, the model predicts transcriptions to a *different* language to the audio.

Whisper checkpoints come in five configurations of varying model sizes.
The smallest four are trained on either English-only or multilingual data.
The largest checkpoints are multilingual only. All ten of the pre-trained checkpoints 
are available on the [Hugging Face Hub](https://huggingface.co/models?search=openai/whisper). The 
checkpoints are summarised in the following table with links to the models on the Hub:

| Size     | Parameters | English-only                                         | Multilingual                                        |
|----------|------------|------------------------------------------------------|-----------------------------------------------------|
| tiny     | 39 M       | [✓](https://huggingface.co/openai/whisper-tiny.en)   | [✓](https://huggingface.co/openai/whisper-tiny)     |
| base     | 74 M       | [✓](https://huggingface.co/openai/whisper-base.en)   | [✓](https://huggingface.co/openai/whisper-base)     |
| small    | 244 M      | [✓](https://huggingface.co/openai/whisper-small.en)  | [✓](https://huggingface.co/openai/whisper-small)    |
| medium   | 769 M      | [✓](https://huggingface.co/openai/whisper-medium.en) | [✓](https://huggingface.co/openai/whisper-medium)   |
| large    | 1550 M     | x                                                    | [✓](https://huggingface.co/openai/whisper-large)    |
| large-v2 | 1550 M     | x                                                    | [✓](https://huggingface.co/openai/whisper-large-v2) |

# Usage

This checkpoint is an *English-only* model, meaning it can be used for English speech recognition. Multilingual speech 
recognition or speech translation is possible through use of a multilingual checkpoint.

To transcribe audio samples, the model has to be used alongside a [`WhisperProcessor`](https://huggingface.co/docs/transformers/model_doc/whisper#transformers.WhisperProcessor).

The `WhisperProcessor` is used to:
1. Pre-process the audio inputs (converting them to log-Mel spectrograms for the model)
2. Post-process the model outputs (converting them from tokens to text)

## Transcription

```python
>>> from transformers import WhisperProcessor, WhisperForConditionalGeneration
>>> from datasets import load_dataset

>>> # load model and processor
>>> processor = WhisperProcessor.from_pretrained("openai/whisper-base.en")
>>> model = WhisperForConditionalGeneration.from_pretrained("openai/whisper-base.en")

>>> # load dummy dataset and read audio files
>>> ds = load_dataset("hf-internal-testing/librispeech_asr_dummy", "clean", split="validation")
>>> sample = ds[0]["audio"]
>>> input_features = processor(sample["array"], sampling_rate=sample["sampling_rate"], return_tensors="pt").input_features 

>>> # generate token ids
>>> predicted_ids = model.generate(input_features)
>>> # decode token ids to text
>>> transcription = processor.batch_decode(predicted_ids, skip_special_tokens=False)
['<|startoftranscript|><|notimestamps|> Mr. Quilter is the apostle of the middle classes, and we are glad to welcome his gospel.<|endoftext|>']

>>> transcription = processor.batch_decode(predicted_ids, skip_special_tokens=True)
[' Mr. Quilter is the apostle of the middle classes and we are glad to welcome his gospel.']
```
The context tokens can be removed from the start of the transcription by setting `skip_special_tokens=True`.

## Evaluation

This code snippet shows how to evaluate Whisper base.en on [LibriSpeech test-clean](https://huggingface.co/datasets/librispeech_asr):
 
```python
>>> from datasets import load_dataset
>>> from transformers import WhisperForConditionalGeneration, WhisperProcessor
>>> import torch
>>> from evaluate import load

>>> librispeech_test_clean = load_dataset("librispeech_asr", "clean", split="test")

>>> processor = WhisperProcessor.from_pretrained("openai/whisper-base.en")
>>> model = WhisperForConditionalGeneration.from_pretrained("openai/whisper-base.en").to("cuda")

>>> def map_to_pred(batch):
>>>     audio = batch["audio"]
>>>     input_features = processor(audio["array"], sampling_rate=audio["sampling_rate"], return_tensors="pt").input_features
>>>     batch["reference"] = processor.tokenizer._normalize(batch['text'])
>>> 
>>>     with torch.no_grad():
>>>         predicted_ids = model.generate(input_features.to("cuda"))[0]
>>>     transcription = processor.decode(predicted_ids)
>>>     batch["prediction"] = processor.tokenizer._normalize(transcription)
>>>     return batch

>>> result = librispeech_test_clean.map(map_to_pred)

>>> wer = load("wer")
>>> print(100 * wer.compute(references=result["reference"], predictions=result["prediction"]))
4.271408904897505
```

## Long-Form Transcription

The Whisper model is intrinsically designed to work on audio samples of up to 30s in duration. However, by using a chunking 
algorithm, it can be used to transcribe audio samples of up to arbitrary length. This is possible through Transformers 
[`pipeline`](https://huggingface.co/docs/transformers/main_classes/pipelines#transformers.AutomaticSpeechRecognitionPipeline) 
method. Chunking is enabled by setting `chunk_length_s=30` when instantiating the pipeline. With chunking enabled, the pipeline 
can be run with batched inference. It can also be extended to predict sequence level timestamps by passing `return_timestamps=True`:

```python
>>> import torch
>>> from transformers import pipeline
>>> from datasets import load_dataset

>>> device = "cuda:0" if torch.cuda.is_available() else "cpu"

>>> pipe = pipeline(
>>>   "automatic-speech-recognition",
>>>   model="openai/whisper-base.en",
>>>   chunk_length_s=30,
>>>   device=device,
>>> )

>>> ds = load_dataset("hf-internal-testing/librispeech_asr_dummy", "clean", split="validation")
>>> sample = ds[0]["audio"]

>>> prediction = pipe(sample.copy(), batch_size=8)["text"]
" Mr. Quilter is the apostle of the middle classes, and we are glad to welcome his gospel."

>>> # we can also return timestamps for the predictions
>>> prediction = pipe(sample.copy(), batch_size=8, return_timestamps=True)["chunks"]
[{'text': ' Mr. Quilter is the apostle of the middle classes and we are glad to welcome his gospel.',
  'timestamp': (0.0, 5.44)}]
```

Refer to the blog post [ASR Chunking](https://huggingface.co/blog/asr-chunking) for more details on the chunking algorithm.

## Fine-Tuning

The pre-trained Whisper model demonstrates a strong ability to generalise to different datasets and domains. However, 
its predictive capabilities can be improved further for certain languages and tasks through *fine-tuning*. The blog 
post [Fine-Tune Whisper with 🤗 Transformers](https://huggingface.co/blog/fine-tune-whisper) provides a step-by-step 
guide to fine-tuning the Whisper model with as little as 5 hours of labelled data.

### Evaluated Use

The primary intended users of these models are AI researchers studying robustness, generalization, capabilities, biases, and constraints of the current model. However, Whisper is also potentially quite useful as an ASR solution for developers, especially for English speech recognition. We recognize that once models are released, it is impossible to restrict access to only “intended” uses or to draw reasonable guidelines around what is or is not research.

The models are primarily trained and evaluated on ASR and speech translation to English tasks. They show strong ASR results in ~10 languages. They may exhibit additional capabilities, particularly if fine-tuned on certain tasks like voice activity detection, speaker classification, or speaker diarization but have not been robustly evaluated in these areas. We strongly recommend that users perform robust evaluations of the models in a particular context and domain before deploying them.

In particular, we caution against using Whisper models to transcribe recordings of individuals taken without their consent or purporting to use these models for any kind of subjective classification. We recommend against use in high-risk domains like decision-making contexts, where flaws in accuracy can lead to pronounced flaws in outcomes. The models are intended to transcribe and translate speech, use of the model for classification is not only not evaluated but also not appropriate, particularly to infer human attributes.


## Training Data

The models are trained on 680,000 hours of audio and the corresponding transcripts collected from the internet. 65% of this data (or 438,000 hours) represents English-language audio and matched English transcripts, roughly 18% (or 126,000 hours) represents non-English audio and English transcripts, while the final 17% (or 117,000 hours) represents non-English audio and the corresponding transcript. This non-English data represents 98 different languages. 

As discussed in [the accompanying paper](https://cdn.openai.com/papers/whisper.pdf), we see that performance on transcription in a given language is directly correlated with the amount of training data we employ in that language.


## Performance and Limitations

Our studies show that, over many existing ASR systems, the models exhibit improved robustness to accents, background noise, technical language, as well as zero shot translation from multiple languages into English; and that accuracy on speech recognition and translation is near the state-of-the-art level. 

However, because the models are trained in a weakly supervised manner using large-scale noisy data, the predictions may include texts that are not actually spoken in the audio input (i.e. hallucination). We hypothesize that this happens because, given their general knowledge of language, the models combine trying to predict the next word in audio with trying to transcribe the audio itself.

Our models perform unevenly across languages, and we observe lower accuracy on low-resource and/or low-discoverability languages or languages where we have less training data. The models also exhibit disparate performance on different accents and dialects of particular languages, which may include higher word error rate across speakers of different genders, races, ages, or other demographic criteria. Our full evaluation results are presented in [the paper accompanying this release](https://cdn.openai.com/papers/whisper.pdf). 

In addition, the sequence-to-sequence architecture of the model makes it prone to generating repetitive texts, which can be mitigated to some degree by beam search and temperature scheduling but not perfectly. Further analysis on these limitations are provided in [the paper](https://cdn.openai.com/papers/whisper.pdf). It is likely that this behavior and hallucinations may be worse on lower-resource and/or lower-discoverability languages.


## Broader Implications

We anticipate that Whisper models’ transcription capabilities may be used for improving accessibility tools. While Whisper models cannot be used for real-time transcription out of the box – their speed and size suggest that others may be able to build applications on top of them that allow for near-real-time speech recognition and translation. The real value of beneficial applications built on top of Whisper models suggests that the disparate performance of these models may have real economic implications.

There are also potential dual use concerns that come with releasing Whisper. While we hope the technology will be used primarily for beneficial purposes, making ASR technology more accessible could enable more actors to build capable surveillance technologies or scale up existing surveillance efforts, as the speed and accuracy allow for affordable automatic transcription and translation of large volumes of audio communication. Moreover, these models may have some capabilities to recognize specific individuals out of the box, which in turn presents safety concerns related both to dual use and disparate performance. In practice, we expect that the cost of transcription is not the limiting factor of scaling up surveillance projects.


### BibTeX entry and citation info
```bibtex
@misc{radford2022whisper,
  doi = {10.48550/ARXIV.2212.04356},
  url = {https://arxiv.org/abs/2212.04356},
  author = {Radford, Alec and Kim, Jong Wook and Xu, Tao and Brockman, Greg and McLeavey, Christine and Sutskever, Ilya},
  title = {Robust Speech Recognition via Large-Scale Weak Supervision},
  publisher = {arXiv},
  year = {2022},
  copyright = {arXiv.org perpetual, non-exclusive license}
}
```
"""^^xsd:string ;
    schema:discussionUrl <https://huggingface.co/openai/whisper-base.en/discussions> ;
    schema:distribution "Information not found."^^xsd:string ;
    schema:funding "Information not found."^^xsd:string ;
    schema:identifier "https://huggingface.co/openai/whisper-base.en"^^xsd:string ;
    schema:inLanguage "en"^^xsd:string ;
    schema:keywords <http://mlentory.zbmed.de/mlentory_graph/07456871ec04ff7e102a14a63ee4f77775baadaf5e404b74e2ab827a14335259>,
        <http://mlentory.zbmed.de/mlentory_graph/0dce0f5e7319b6178cd79d5f2163f0e134d0064f4ea4f93e8afeec1e7d78fa8d>,
        <http://mlentory.zbmed.de/mlentory_graph/13e6e4095523310627190177e08c0206ca97e76f4c4565c15c2b35270daa2588>,
        <http://mlentory.zbmed.de/mlentory_graph/29d9051dd7490ee997ef15f45bf916274706268eab63f2c7bff767388d51cf25>,
        <http://mlentory.zbmed.de/mlentory_graph/3e9a4e1232f617b33fa8460d6c142ee49e69eb5c55acfd1e618d58e7495955e8>,
        <http://mlentory.zbmed.de/mlentory_graph/87b927fef88a46248b3b208472aec7bfeb38667386b309f46772e26b40f6affb>,
        <http://mlentory.zbmed.de/mlentory_graph/8e9892e571845c79509180a69a268f19c0592a4e975a5fd3e16f2059af61ea75>,
        <http://mlentory.zbmed.de/mlentory_graph/9c51ba772888465129d6bda3b0b520a3a16960b8c108a8cd2276eb4fb85ee5f2>,
        <http://mlentory.zbmed.de/mlentory_graph/a7eca72cd0a3a0ce30e3b37b299034e8cf2e3b921a7deaf54545b7d00e88c5e4>,
        <http://mlentory.zbmed.de/mlentory_graph/df4982af808ead1a57663cc7a83e60059f6a6ae1baf83a270fdf8bdfef11a3de>,
        "arxiv:2212.04356"^^xsd:string,
        "en"^^xsd:string,
        "license:apache-2.0"^^xsd:string,
        "region:us"^^xsd:string,
        "tf"^^xsd:string ;
    schema:license "apache-2.0"^^xsd:string ;
    schema:maintainer "Information not found."^^xsd:string ;
    schema:memoryRequirements "Not available"^^xsd:string ;
    schema:name "whisper-base.en"^^xsd:string ;
    schema:operatingSystem "Information not found."^^xsd:string ;
    schema:processorRequirements "Information not found."^^xsd:string ;
    schema:releaseNotes """---
language:
- en
tags:
- audio
- automatic-speech-recognition
- hf-asr-leaderboard
widget:
- example_title: Librispeech sample 1
  src: https://cdn-media.huggingface.co/speech_samples/sample1.flac
- example_title: Librispeech sample 2
  src: https://cdn-media.huggingface.co/speech_samples/sample2.flac
pipeline_tag: automatic-speech-recognition
license: apache-2.0
model-index:
- name: whisper-base.en
  results:
  - task:
      type: automatic-speech-recognition
      name: Automatic Speech Recognition
    dataset:
      name: LibriSpeech (clean)
      type: librispeech_asr
      config: clean
      split: test
      args:
        language: en
    metrics:
    - type: wer
      name: Test WER
  - task:
      type: automatic-speech-recognition
      name: Automatic Speech Recognition
    dataset:
      name: LibriSpeech (other)
      type: librispeech_asr
      config: other
      split: test
      args:
        language: en
    metrics:
    - type: wer
      value: 12.803978669490565
      name: Test WER
---

# Whisper

Whisper is a pre-trained model for automatic speech recognition (ASR) and speech translation. Trained on 680k hours 
of labelled data, Whisper models demonstrate a strong ability to generalise to many datasets and domains **without** the need 
for fine-tuning.

Whisper was proposed in the paper [Robust Speech Recognition via Large-Scale Weak Supervision](https://arxiv.org/abs/2212.04356) 
by Alec Radford et al. from OpenAI. The original code repository can be found [here](https://github.com/openai/whisper).

**Disclaimer**: Content for this model card has partly been written by the Hugging Face team, and parts of it were 
copied and pasted from the original model card.

## Model details

Whisper is a Transformer based encoder-decoder model, also referred to as a _sequence-to-sequence_ model. 
It was trained on 680k hours of labelled speech data annotated using large-scale weak supervision. 

The models were trained on either English-only data or multilingual data. The English-only models were trained 
on the task of speech recognition. The multilingual models were trained on both speech recognition and speech 
translation. For speech recognition, the model predicts transcriptions in the *same* language as the audio. 
For speech translation, the model predicts transcriptions to a *different* language to the audio.

Whisper checkpoints come in five configurations of varying model sizes.
The smallest four are trained on either English-only or multilingual data.
The largest checkpoints are multilingual only. All ten of the pre-trained checkpoints 
are available on the [Hugging Face Hub](https://huggingface.co/models?search=openai/whisper). The 
checkpoints are summarised in the following table with links to the models on the Hub:

| Size     | Parameters | English-only                                         | Multilingual                                        |
|----------|------------|------------------------------------------------------|-----------------------------------------------------|
| tiny     | 39 M       | [✓](https://huggingface.co/openai/whisper-tiny.en)   | [✓](https://huggingface.co/openai/whisper-tiny)     |
| base     | 74 M       | [✓](https://huggingface.co/openai/whisper-base.en)   | [✓](https://huggingface.co/openai/whisper-base)     |
| small    | 244 M      | [✓](https://huggingface.co/openai/whisper-small.en)  | [✓](https://huggingface.co/openai/whisper-small)    |
| medium   | 769 M      | [✓](https://huggingface.co/openai/whisper-medium.en) | [✓](https://huggingface.co/openai/whisper-medium)   |
| large    | 1550 M     | x                                                    | [✓](https://huggingface.co/openai/whisper-large)    |
| large-v2 | 1550 M     | x                                                    | [✓](https://huggingface.co/openai/whisper-large-v2) |

# Usage

This checkpoint is an *English-only* model, meaning it can be used for English speech recognition. Multilingual speech 
recognition or speech translation is possible through use of a multilingual checkpoint.

To transcribe audio samples, the model has to be used alongside a [`WhisperProcessor`](https://huggingface.co/docs/transformers/model_doc/whisper#transformers.WhisperProcessor).

The `WhisperProcessor` is used to:
1. Pre-process the audio inputs (converting them to log-Mel spectrograms for the model)
2. Post-process the model outputs (converting them from tokens to text)

## Transcription

```python
>>> from transformers import WhisperProcessor, WhisperForConditionalGeneration
>>> from datasets import load_dataset

>>> # load model and processor
>>> processor = WhisperProcessor.from_pretrained("openai/whisper-base.en")
>>> model = WhisperForConditionalGeneration.from_pretrained("openai/whisper-base.en")

>>> # load dummy dataset and read audio files
>>> ds = load_dataset("hf-internal-testing/librispeech_asr_dummy", "clean", split="validation")
>>> sample = ds[0]["audio"]
>>> input_features = processor(sample["array"], sampling_rate=sample["sampling_rate"], return_tensors="pt").input_features 

>>> # generate token ids
>>> predicted_ids = model.generate(input_features)
>>> # decode token ids to text
>>> transcription = processor.batch_decode(predicted_ids, skip_special_tokens=False)
['<|startoftranscript|><|notimestamps|> Mr. Quilter is the apostle of the middle classes, and we are glad to welcome his gospel.<|endoftext|>']

>>> transcription = processor.batch_decode(predicted_ids, skip_special_tokens=True)
[' Mr. Quilter is the apostle of the middle classes and we are glad to welcome his gospel.']
```
The context tokens can be removed from the start of the transcription by setting `skip_special_tokens=True`.

## Evaluation

This code snippet shows how to evaluate Whisper base.en on [LibriSpeech test-clean](https://huggingface.co/datasets/librispeech_asr):
 
```python
>>> from datasets import load_dataset
>>> from transformers import WhisperForConditionalGeneration, WhisperProcessor
>>> import torch
>>> from evaluate import load

>>> librispeech_test_clean = load_dataset("librispeech_asr", "clean", split="test")

>>> processor = WhisperProcessor.from_pretrained("openai/whisper-base.en")
>>> model = WhisperForConditionalGeneration.from_pretrained("openai/whisper-base.en").to("cuda")

>>> def map_to_pred(batch):
>>>     audio = batch["audio"]
>>>     input_features = processor(audio["array"], sampling_rate=audio["sampling_rate"], return_tensors="pt").input_features
>>>     batch["reference"] = processor.tokenizer._normalize(batch['text'])
>>> 
>>>     with torch.no_grad():
>>>         predicted_ids = model.generate(input_features.to("cuda"))[0]
>>>     transcription = processor.decode(predicted_ids)
>>>     batch["prediction"] = processor.tokenizer._normalize(transcription)
>>>     return batch

>>> result = librispeech_test_clean.map(map_to_pred)

>>> wer = load("wer")
>>> print(100 * wer.compute(references=result["reference"], predictions=result["prediction"]))
4.271408904897505
```

## Long-Form Transcription

The Whisper model is intrinsically designed to work on audio samples of up to 30s in duration. However, by using a chunking 
algorithm, it can be used to transcribe audio samples of up to arbitrary length. This is possible through Transformers 
[`pipeline`](https://huggingface.co/docs/transformers/main_classes/pipelines#transformers.AutomaticSpeechRecognitionPipeline) 
method. Chunking is enabled by setting `chunk_length_s=30` when instantiating the pipeline. With chunking enabled, the pipeline 
can be run with batched inference. It can also be extended to predict sequence level timestamps by passing `return_timestamps=True`:

```python
>>> import torch
>>> from transformers import pipeline
>>> from datasets import load_dataset

>>> device = "cuda:0" if torch.cuda.is_available() else "cpu"

>>> pipe = pipeline(
>>>   "automatic-speech-recognition",
>>>   model="openai/whisper-base.en",
>>>   chunk_length_s=30,
>>>   device=device,
>>> )

>>> ds = load_dataset("hf-internal-testing/librispeech_asr_dummy", "clean", split="validation")
>>> sample = ds[0]["audio"]

>>> prediction = pipe(sample.copy(), batch_size=8)["text"]
" Mr. Quilter is the apostle of the middle classes, and we are glad to welcome his gospel."

>>> # we can also return timestamps for the predictions
>>> prediction = pipe(sample.copy(), batch_size=8, return_timestamps=True)["chunks"]
[{'text': ' Mr. Quilter is the apostle of the middle classes and we are glad to welcome his gospel.',
  'timestamp': (0.0, 5.44)}]
```

Refer to the blog post [ASR Chunking](https://huggingface.co/blog/asr-chunking) for more details on the chunking algorithm.

## Fine-Tuning

The pre-trained Whisper model demonstrates a strong ability to generalise to different datasets and domains. However, 
its predictive capabilities can be improved further for certain languages and tasks through *fine-tuning*. The blog 
post [Fine-Tune Whisper with 🤗 Transformers](https://huggingface.co/blog/fine-tune-whisper) provides a step-by-step 
guide to fine-tuning the Whisper model with as little as 5 hours of labelled data.

### Evaluated Use

The primary intended users of these models are AI researchers studying robustness, generalization, capabilities, biases, and constraints of the current model. However, Whisper is also potentially quite useful as an ASR solution for developers, especially for English speech recognition. We recognize that once models are released, it is impossible to restrict access to only “intended” uses or to draw reasonable guidelines around what is or is not research.

The models are primarily trained and evaluated on ASR and speech translation to English tasks. They show strong ASR results in ~10 languages. They may exhibit additional capabilities, particularly if fine-tuned on certain tasks like voice activity detection, speaker classification, or speaker diarization but have not been robustly evaluated in these areas. We strongly recommend that users perform robust evaluations of the models in a particular context and domain before deploying them.

In particular, we caution against using Whisper models to transcribe recordings of individuals taken without their consent or purporting to use these models for any kind of subjective classification. We recommend against use in high-risk domains like decision-making contexts, where flaws in accuracy can lead to pronounced flaws in outcomes. The models are intended to transcribe and translate speech, use of the model for classification is not only not evaluated but also not appropriate, particularly to infer human attributes.


## Training Data

The models are trained on 680,000 hours of audio and the corresponding transcripts collected from the internet. 65% of this data (or 438,000 hours) represents English-language audio and matched English transcripts, roughly 18% (or 126,000 hours) represents non-English audio and English transcripts, while the final 17% (or 117,000 hours) represents non-English audio and the corresponding transcript. This non-English data represents 98 different languages. 

As discussed in [the accompanying paper](https://cdn.openai.com/papers/whisper.pdf), we see that performance on transcription in a given language is directly correlated with the amount of training data we employ in that language.


## Performance and Limitations

Our studies show that, over many existing ASR systems, the models exhibit improved robustness to accents, background noise, technical language, as well as zero shot translation from multiple languages into English; and that accuracy on speech recognition and translation is near the state-of-the-art level. 

However, because the models are trained in a weakly supervised manner using large-scale noisy data, the predictions may include texts that are not actually spoken in the audio input (i.e. hallucination). We hypothesize that this happens because, given their general knowledge of language, the models combine trying to predict the next word in audio with trying to transcribe the audio itself.

Our models perform unevenly across languages, and we observe lower accuracy on low-resource and/or low-discoverability languages or languages where we have less training data. The models also exhibit disparate performance on different accents and dialects of particular languages, which may include higher word error rate across speakers of different genders, races, ages, or other demographic criteria. Our full evaluation results are presented in [the paper accompanying this release](https://cdn.openai.com/papers/whisper.pdf). 

In addition, the sequence-to-sequence architecture of the model makes it prone to generating repetitive texts, which can be mitigated to some degree by beam search and temperature scheduling but not perfectly. Further analysis on these limitations are provided in [the paper](https://cdn.openai.com/papers/whisper.pdf). It is likely that this behavior and hallucinations may be worse on lower-resource and/or lower-discoverability languages.


## Broader Implications

We anticipate that Whisper models’ transcription capabilities may be used for improving accessibility tools. While Whisper models cannot be used for real-time transcription out of the box – their speed and size suggest that others may be able to build applications on top of them that allow for near-real-time speech recognition and translation. The real value of beneficial applications built on top of Whisper models suggests that the disparate performance of these models may have real economic implications.

There are also potential dual use concerns that come with releasing Whisper. While we hope the technology will be used primarily for beneficial purposes, making ASR technology more accessible could enable more actors to build capable surveillance technologies or scale up existing surveillance efforts, as the speed and accuracy allow for affordable automatic transcription and translation of large volumes of audio communication. Moreover, these models may have some capabilities to recognize specific individuals out of the box, which in turn presents safety concerns related both to dual use and disparate performance. In practice, we expect that the cost of transcription is not the limiting factor of scaling up surveillance projects.


### BibTeX entry and citation info
```bibtex
@misc{radford2022whisper,
  doi = {10.48550/ARXIV.2212.04356},
  url = {https://arxiv.org/abs/2212.04356},
  author = {Radford, Alec and Kim, Jong Wook and Xu, Tao and Brockman, Greg and McLeavey, Christine and Sutskever, Ilya},
  title = {Robust Speech Recognition via Large-Scale Weak Supervision},
  publisher = {arXiv},
  year = {2022},
  copyright = {arXiv.org perpetual, non-exclusive license}
}
```
"""^^xsd:string ;
    schema:softwareHelp "Information not found."^^xsd:string ;
    schema:softwareRequirements "Information not found."^^xsd:string ;
    schema:storageRequirements "Information not found."^^xsd:string ;
    schema:url <https://huggingface.co/openai/whisper-base.en> ;
    schema:version "Information not found"^^xsd:string ;
    ns3:buildInstructions "Information not found."^^xsd:string ;
    ns3:developmentStatus "Information not found."^^xsd:string ;
    ns3:issueTracker <https://huggingface.co/openai/whisper-base.en/discussions> ;
    ns3:readme <https://huggingface.co/openai/whisper-base.en/blob/main/README.md> ;
    ns3:referencePublication <http://mlentory.zbmed.de/mlentory_graph/79549f00e6767e7c56b491b734b5ec351d3faaae4afc546b64c29d0146128a68> .

<http://mlentory.zbmed.de/mlentory_graph/746e796ec31ad9ad2b517555a4e91b2e3dfff187021fd0255aae50476624430d> a schema:DefinedTerm ;
    schema:description "Extracts meaningful features from input data for downstream tasks."^^xsd:string ;
    schema:name "Feature Extraction"^^xsd:string .

<http://mlentory.zbmed.de/mlentory_graph/771e059c7890ae196a3227d36771c27f019638d33a819ca19bef2ae302b92b44> a schema:DefinedTerm ;
    schema:description "PyTorch-based audio source separation toolkit for researchers."^^xsd:string ;
    schema:name "Asteroid"^^xsd:string .

<http://mlentory.zbmed.de/mlentory_graph/79765e8db24271bde7a56b897b0b6c389d5be642563652aae56b6253290a801e> a schema:DefinedTerm ;
    schema:description "Classifies content into categories not seen during training."^^xsd:string ;
    schema:name "Zero Shot Classification"^^xsd:string .

<http://mlentory.zbmed.de/mlentory_graph/7daea98679eae3b5819f476833cada39b566629edb49ee1f55db0016e8ecf118> a schema:DefinedTerm ;
    schema:description "Python NLP library for accurate multilingual text analysis, including tokenization, POS tagging, and dependency parsing."^^xsd:string ;
    schema:name "Stanza"^^xsd:string .

<http://mlentory.zbmed.de/mlentory_graph/85b6833a0e3a566c8de87c0f42b57ec97f67e03180245edb416823e240ee11d1> a schema:DefinedTerm ;
    schema:description "Array framework for machine learning on Apple silicon, designed for efficiency and ease of use."^^xsd:string ;
    schema:name "MLX"^^xsd:string .

<http://mlentory.zbmed.de/mlentory_graph/85f0e69a70ce025a206d6ddbf78d989a3cabbdae215f2045df9b67b21a9d6780> a schema:DefinedTerm ;
    schema:description "Categorizes text documents into predefined classes."^^xsd:string ;
    schema:name "Text Classification"^^xsd:string .

<http://mlentory.zbmed.de/mlentory_graph/86f52aa6369c70ec009cd27198c0d2e52782b473507c01a7426d4c1bf4185e05> a schema:DefinedTerm ;
    schema:description "Optimized backend for deploying and serving text embedding models with high performance."^^xsd:string ;
    schema:name "text-embedding-inference"^^xsd:string .

<http://mlentory.zbmed.de/mlentory_graph/8c47ad9f935d95019e8ffaaae3b458d998d1a068ef4d8dfec71b304f4e4b1d52> a schema:Organization .

<http://mlentory.zbmed.de/mlentory_graph/8fd2e8ec655b6111cc83724fbc62c13d0c8b3442b1768b9bc35e0eceae0ebe85> a schema:DefinedTerm ;
    schema:description "Creates masks for objects or regions in images."^^xsd:string ;
    schema:name "Mask Generation"^^xsd:string .

<http://mlentory.zbmed.de/mlentory_graph/9132b663f2893be0a7b034405164be91c4fe250d2b1ecd3390fb9b9bd689997b> a schema:DefinedTerm ;
    schema:description "Categorizes video content into predefined classes."^^xsd:string ;
    schema:name "Video Classification"^^xsd:string .

<http://mlentory.zbmed.de/mlentory_graph/934dea1e0796f0376db45e4b74e093aeb422ffdf79cf5c4aaea1e5e84969c76e> a schema:DefinedTerm ;
    schema:description "A file format for efficiently storing and loading large language models with quantization options."^^xsd:string ;
    schema:name "GGUF"^^xsd:string .

<http://mlentory.zbmed.de/mlentory_graph/948f12027813055af3dcb960da569e2eae02f39632eb0850253a6c353ee892cd> a ns1:ML_Model ;
    ns1:ethicalLegalSocial "Ethical Considerations and Limitations: Llama 2 is a new technology that carries risks with use. Testing conducted to date has been in English, and has not covered, nor could it cover all scenarios. For these reasons, as with all LLMs, Llama 2’s potential outputs cannot be predicted in advance, and the model may in some instances produce inaccurate, biased or other objectionable responses to user prompts. Therefore, before deploying any applications of Llama 2, developers should perform safety testing and tuning tailored to their specific applications of the model."^^xsd:string ;
    ns1:evaluatedOn "Information not found"^^xsd:string ;
    ns1:fineTunedFrom "Information not found"^^xsd:string ;
    ns1:hasCO2eEmissions "Information not found."^^xsd:string ;
    ns1:intendedUse "The intended use of Llama 2 is for commercial and research use in English."^^xsd:string ;
    ns1:mlTask <http://mlentory.zbmed.de/mlentory_graph/6925cb204ab4d5280c948ac7e23dd8f7b48d1de433cf9edc5c30a8d87ce3b317> ;
    ns1:modelCategory "Information not found."^^xsd:string ;
    ns1:modelRisks "The potential risks associated with the model are not explicitly mentioned in the provided context."^^xsd:string ;
    ns1:sharedBy <http://mlentory.zbmed.de/mlentory_graph/9c03090b68b1e45d6bebe9b9d1ea103b6a4c064ceb71f16f08a5ae59d9bac70e> ;
    ns1:testedOn "Information not found"^^xsd:string ;
    ns1:trainedOn "Information not found"^^xsd:string ;
    ns1:usageInstructions "Information not found."^^xsd:string ;
    ns1:validatedOn "Information not found."^^xsd:string ;
    schema:archivedAt <https://huggingface.co/meta-llama/Llama-2-7b-hf> ;
    schema:author "The author of this content is not explicitly mentioned in the provided context."^^xsd:string ;
    schema:citation "Information not found."^^xsd:string ;
    schema:conditionsOfAccess "Information not found"^^xsd:string ;
    schema:contributor "Information not found."^^xsd:string ;
    schema:copyrightHolder "The information provided in the context does not contain the copyright holder for the Llama 2 model."^^xsd:string ;
    schema:dateCreated "2023-07-13T16:16:13+00:00"^^xsd:dateTime ;
    schema:dateModified "2024-04-17T08:40:16+00:00"^^xsd:dateTime ;
    schema:datePublished "2023-07-13T16:16:13+00:00"^^xsd:dateTime ;
    schema:description """---
extra_gated_heading: You need to share contact information with Meta to access this
  model
extra_gated_prompt: "### LLAMA 2 COMMUNITY LICENSE AGREEMENT\\n\\"Agreement\\" means\\
  \\ the terms and conditions for use, reproduction, distribution and  modification\\
  \\ of the Llama Materials set forth herein. \\n\\"Documentation\\" means the specifications,\\
  \\ manuals and documentation  accompanying Llama 2 distributed by Meta at https://ai.meta.com/resources/models-and-libraries/llama-downloads/.\\
  \\  \\n\\"Licensee\\" or \\"you\\" means you, or your employer or any other person or\\
  \\ entity (if you are entering into this Agreement on such person or entity's behalf),\\
  \\ of the age required under applicable laws, rules or regulations to provide legal\\
  \\ consent and that has legal authority to bind your employer or such other person\\
  \\ or  entity if you are  entering in this Agreement on their behalf. \\n\\"Llama 2\\"\\
  \\ means the foundational large language models and software and algorithms, including\\
  \\ machine-learning model code, trained model weights, inference-enabling code, training-enabling\\
  \\ code, fine-tuning enabling code and other  elements of the foregoing distributed\\
  \\ by Meta at ai.meta.com/resources/models-and-libraries/llama-downloads/.\\n\\"Llama\\
  \\ Materials\\" means, collectively, Meta's proprietary Llama 2 and documentation\\
  \\ (and any portion thereof) made available under this Agreement.\\n\\"Meta\\" or \\"\\
  we\\" means Meta Platforms Ireland Limited (if you are located in or, if you are\\
  \\ an entity, your principal place of business is in the EEA or Switzerland) and\\
  \\ Meta Platforms, Inc. (if you are located outside of the EEA or Switzerland). \\n\\
  \\nBy clicking \\"I Accept\\" below or by using or distributing any portion or element\\
  \\ of the Llama Materials, you agree to be bound by this Agreement.\\n1. License Rights\\
  \\ and Redistribution. \\na. Grant of Rights. You are granted a non-exclusive, worldwide,\\
  \\ non- transferable and royalty-free limited license under Meta's intellectual property\\
  \\ or  other rights owned by Meta embodied in the Llama Materials to use, reproduce,\\
  \\  distribute, copy, create derivative works of, and make modifications to the Llama\\
  \\  Materials.  \\nb. Redistribution and Use.\\ni. If you distribute or make the Llama\\
  \\ Materials, or any derivative works  thereof, available to a third party, you shall\\
  \\ provide a copy of this Agreement to such  third party. \\nii.  If you receive Llama\\
  \\ Materials, or any derivative works thereof, from  a Licensee as part of an integrated\\
  \\ end user product, then Section 2 of this  Agreement will not apply to you. \\n\\
  iii. You must retain in all copies of the Llama Materials that you  distribute the\\
  \\ following attribution notice within a \\"Notice\\" text file distributed as a  part\\
  \\ of such copies: \\"Llama 2 is licensed under the LLAMA 2 Community License,  Copyright\\
  \\ (c) Meta Platforms, Inc. All Rights Reserved.\\"\\niv. Your use of the Llama Materials\\
  \\ must comply with applicable laws  and regulations (including trade compliance\\
  \\ laws and regulations) and adhere to the  Acceptable Use Policy for the Llama Materials\\
  \\ (available at  https://ai.meta.com/llama/use-policy), which is hereby incorporated\\
  \\ by reference into  this Agreement.\\nv. You will not use the Llama Materials or\\
  \\ any output or results of the  Llama Materials to improve any other large language\\
  \\ model (excluding Llama 2 or  derivative works thereof).  \\n\\n2. Additional Commercial\\
  \\ Terms. If, on the Llama 2 version release date, the  monthly active users of the\\
  \\ products or services made available by or for Licensee,  or Licensee's affiliates,\\
  \\ is greater than 700 million monthly active users in the  preceding calendar month,\\
  \\ you must request a license from Meta, which Meta may  grant to you in its sole\\
  \\ discretion, and you are not authorized to exercise any of the  rights under this\\
  \\ Agreement unless or until Meta otherwise expressly grants you  such rights.\\n\\
  3. Disclaimer of Warranty. UNLESS REQUIRED BY APPLICABLE LAW, THE  LLAMA MATERIALS\\
  \\ AND ANY OUTPUT AND RESULTS THEREFROM ARE  PROVIDED ON AN \\"AS IS\\" BASIS, WITHOUT\\
  \\ WARRANTIES OF ANY KIND,  EITHER EXPRESS OR IMPLIED, INCLUDING, WITHOUT LIMITATION,\\
  \\ ANY  WARRANTIES OF TITLE, NON-INFRINGEMENT, MERCHANTABILITY, OR  FITNESS FOR A\\
  \\ PARTICULAR PURPOSE. YOU ARE SOLELY RESPONSIBLE  FOR DETERMINING THE APPROPRIATENESS\\
  \\ OF USING OR REDISTRIBUTING  THE LLAMA MATERIALS AND ASSUME ANY RISKS ASSOCIATED\\
  \\ WITH YOUR  USE OF THE LLAMA MATERIALS AND ANY OUTPUT AND RESULTS.\\n4. Limitation\\
  \\ of Liability. IN NO EVENT WILL META OR ITS AFFILIATES BE  LIABLE UNDER ANY THEORY\\
  \\ OF LIABILITY, WHETHER IN CONTRACT, TORT,  NEGLIGENCE, PRODUCTS LIABILITY, OR OTHERWISE,\\
  \\ ARISING OUT OF THIS  AGREEMENT, FOR ANY LOST PROFITS OR ANY INDIRECT, SPECIAL,\\
  \\  CONSEQUENTIAL, INCIDENTAL, EXEMPLARY OR PUNITIVE DAMAGES, EVEN  IF META OR ITS\\
  \\ AFFILIATES HAVE BEEN ADVISED OF THE POSSIBILITY OF  ANY OF THE FOREGOING.\\n\\n\\
  5. Intellectual Property.\\na. No trademark licenses are granted under this Agreement,\\
  \\ and in  connection with the Llama Materials, neither Meta nor Licensee may use\\
  \\ any name  or mark owned by or associated with the other or any of its affiliates,\\
  \\ except as  required for reasonable and customary use in describing and redistributing\\
  \\ the  Llama Materials.\\nb. Subject to Meta's ownership of Llama Materials and derivatives\\
  \\ made by or  for Meta, with respect to any derivative works and modifications of\\
  \\ the Llama  Materials that are made by you, as between you and Meta, you are and\\
  \\ will be the  owner of such derivative works and modifications.\\nc. If you institute\\
  \\ litigation or other proceedings against Meta or any entity  (including a cross-claim\\
  \\ or counterclaim in a lawsuit) alleging that the Llama  Materials or Llama 2 outputs\\
  \\ or results, or any portion of any of the foregoing,  constitutes infringement\\
  \\ of intellectual property or other rights owned or licensable  by you, then any\\
  \\ licenses granted to you under this Agreement shall terminate as of  the date such\\
  \\ litigation or claim is filed or instituted. You will indemnify and hold  harmless\\
  \\ Meta from and against any claim by any third party arising out of or related \\
  \\ to your use or distribution of the Llama Materials.\\n6. Term and Termination.\\
  \\ The term of this Agreement will commence upon your  acceptance of this Agreement\\
  \\ or access to the Llama Materials and will continue in  full force and effect until\\
  \\ terminated in accordance with the terms and conditions  herein. Meta may terminate\\
  \\ this Agreement if you are in breach of any term or  condition of this Agreement.\\
  \\ Upon termination of this Agreement, you shall delete  and cease use of the Llama\\
  \\ Materials. Sections 3, 4 and 7 shall survive the  termination of this Agreement.\\
  \\ \\n7. Governing Law and Jurisdiction. This Agreement will be governed and  construed\\
  \\ under the laws of the State of California without regard to choice of law  principles,\\
  \\ and the UN Convention on Contracts for the International Sale of Goods  does not\\
  \\ apply to this Agreement. The courts of California shall have exclusive  jurisdiction\\
  \\ of any dispute arising out of this Agreement. \\n### Llama 2 Acceptable Use Policy\\n\\
  Meta is committed to promoting safe and fair use of its tools and features, including\\
  \\ Llama 2. If you access or use Llama 2, you agree to this Acceptable Use Policy\\
  \\ (“Policy”). The most recent copy of this policy can be found at [ai.meta.com/llama/use-policy](http://ai.meta.com/llama/use-policy).\\n\\
  #### Prohibited Uses\\nWe want everyone to use Llama 2 safely and responsibly. You\\
  \\ agree you will not use, or allow others to use, Llama 2 to:\\n1. Violate the law\\
  \\ or others’ rights, including to:\\n      1. Engage in, promote, generate, contribute\\
  \\ to, encourage, plan, incite, or further illegal or unlawful activity or content,\\
  \\ such as: \\n          1. Violence or terrorism \\n          2. Exploitation or harm\\
  \\ to children, including the solicitation, creation, acquisition, or dissemination\\
  \\ of child exploitative content or failure to report Child Sexual Abuse Material\\n\\
  \\          3. Human trafficking, exploitation, and sexual violence\\n          4.\\
  \\ The illegal distribution of information or materials to minors, including obscene\\
  \\ materials, or failure to employ legally required age-gating in connection with\\
  \\ such information or materials.\\n          5. Sexual solicitation\\n          6.\\
  \\ Any other criminal activity\\n      2. Engage in, promote, incite, or facilitate\\
  \\ the harassment, abuse, threatening, or bullying of individuals or groups of individuals\\n\\
  \\      3. Engage in, promote, incite, or facilitate discrimination or other unlawful\\
  \\ or harmful conduct in the provision of employment, employment benefits, credit,\\
  \\ housing, other economic benefits, or other essential goods and services\\n    \\
  \\  4. Engage in the unauthorized or unlicensed practice of any profession including,\\
  \\ but not limited to, financial, legal, medical/health, or related professional\\
  \\ practices \\n      5. Collect, process, disclose, generate, or infer health, demographic,\\
  \\ or other sensitive personal or private information about individuals without rights\\
  \\ and consents required by applicable laws\\n      6. Engage in or facilitate any\\
  \\ action or generate any content that infringes, misappropriates, or otherwise violates\\
  \\ any third-party rights, including the outputs or results of any products or services\\
  \\ using the Llama 2 Materials\\n      7. Create, generate, or facilitate the creation\\
  \\ of malicious code, malware, computer viruses or do anything else that could disable,\\
  \\ overburden, interfere with or impair the proper working, integrity, operation\\
  \\ or appearance of a website or computer system \\n2. Engage in, promote, incite,\\
  \\ facilitate, or assist in the planning or development of activities that present\\
  \\ a risk of death or bodily harm to individuals, including use of Llama 2 related\\
  \\ to the following:\\n    1. Military, warfare, nuclear industries or applications,\\
  \\ espionage, use for materials or activities that are subject to the International\\
  \\ Traffic Arms Regulations (ITAR) maintained by the United States Department of\\
  \\ State\\n    2. Guns and illegal weapons (including weapon development)\\n    3.\\
  \\ Illegal drugs and regulated/controlled substances\\n    4. Operation of critical\\
  \\ infrastructure, transportation technologies, or heavy machinery\\n    5. Self-harm\\
  \\ or harm to others, including suicide, cutting, and eating disorders\\n    6. Any\\
  \\ content intended to incite or promote violence, abuse, or any infliction of bodily\\
  \\ harm to an individual\\n3. Intentionally deceive or mislead others, including use\\
  \\ of Llama 2 related to the following:\\n    1. Generating, promoting, or furthering\\
  \\ fraud or the creation or promotion of disinformation\\n    2. Generating, promoting,\\
  \\ or furthering defamatory content, including the creation of defamatory statements,\\
  \\ images, or other content\\n    3. Generating, promoting, or further distributing\\
  \\ spam\\n    4. Impersonating another individual without consent, authorization,\\
  \\ or legal right\\n    5. Representing that the use of Llama 2 or outputs are human-generated\\n\\
  \\    6. Generating or facilitating false online engagement, including fake reviews\\
  \\ and other means of fake online engagement \\n    4. Fail to appropriately disclose\\
  \\ to end users any known dangers of your AI system \\nPlease report any violation\\
  \\ of this Policy, software “bug,” or other problems that could lead to a violation\\
  \\ of this Policy through one of the following means: \\n    * Reporting issues with\\
  \\ the model: [github.com/facebookresearch/llama](http://github.com/facebookresearch/llama)\\n\\
  \\    * Reporting risky content generated by the model: [developers.facebook.com/llama_output_feedback](http://developers.facebook.com/llama_output_feedback)\\n\\
  \\    * Reporting bugs and security concerns: [facebook.com/whitehat/info](http://facebook.com/whitehat/info)\\
  \\ \\n    * Reporting violations of the Acceptable Use Policy or unlicensed uses of\\
  \\ Llama: [LlamaUseReport@meta.com](mailto:LlamaUseReport@meta.com)"
extra_gated_fields:
  First Name: text
  Last Name: text
  Date of birth: date_picker
  Country: country
  Affiliation: text
  geo: ip_location
  ? By clicking Submit below I accept the terms of the license and acknowledge that
    the information I provide will be collected stored processed and shared in accordance
    with the Meta Privacy Policy
  : checkbox
extra_gated_description: The information you provide will be collected, stored, processed
  and shared in accordance with the [Meta Privacy Policy](https://www.facebook.com/privacy/policy/).
extra_gated_button_content: Submit
language:
- en
pipeline_tag: text-generation
tags:
- facebook
- meta
- pytorch
- llama
- llama-2
license: llama2
---
# **Llama 2**
Llama 2 is a collection of pretrained and fine-tuned generative text models ranging in scale from 7 billion to 70 billion parameters. This is the repository for the 7B pretrained model, converted for the Hugging Face Transformers format. Links to other models can be found in the index at the bottom.

## Model Details
*Note: Use of this model is governed by the Meta license. In order to download the model weights and tokenizer, please visit the [website](https://ai.meta.com/resources/models-and-libraries/llama-downloads/) and accept our License before requesting access here.*

Meta developed and publicly released the Llama 2 family of large language models (LLMs), a collection of pretrained and fine-tuned generative text models ranging in scale from 7 billion to 70 billion parameters. Our fine-tuned LLMs, called Llama-2-Chat, are optimized for dialogue use cases. Llama-2-Chat models outperform open-source chat models on most benchmarks we tested, and in our human evaluations for helpfulness and safety, are on par with some popular closed-source models like ChatGPT and PaLM.

**Model Developers** Meta

**Variations** Llama 2 comes in a range of parameter sizes — 7B, 13B, and 70B — as well as pretrained and fine-tuned variations.

**Input** Models input text only.

**Output** Models generate text only.

**Model Architecture** Llama 2 is an auto-regressive language model that uses an optimized transformer architecture. The tuned versions use supervised fine-tuning (SFT) and reinforcement learning with human feedback (RLHF) to align to human preferences for helpfulness and safety.


||Training Data|Params|Content Length|GQA|Tokens|LR|
|---|---|---|---|---|---|---|
|Llama 2|*A new mix of publicly available online data*|7B|4k|&#10007;|2.0T|3.0 x 10<sup>-4</sup>|
|Llama 2|*A new mix of publicly available online data*|13B|4k|&#10007;|2.0T|3.0 x 10<sup>-4</sup>|
|Llama 2|*A new mix of publicly available online data*|70B|4k|&#10004;|2.0T|1.5 x 10<sup>-4</sup>|

*Llama 2 family of models.* Token counts refer to pretraining data only. All models are trained with a global batch-size of 4M tokens. Bigger models -  70B -- use Grouped-Query Attention (GQA) for improved inference scalability.

**Model Dates** Llama 2 was trained between January 2023 and July 2023.

**Status** This is a static model trained on an offline dataset. Future versions of the tuned models will be released as we improve model safety with community feedback.

**License** A custom commercial license is available at: [https://ai.meta.com/resources/models-and-libraries/llama-downloads/](https://ai.meta.com/resources/models-and-libraries/llama-downloads/)

**Research Paper** ["Llama-2: Open Foundation and Fine-tuned Chat Models"](arxiv.org/abs/2307.09288)

## Intended Use
**Intended Use Cases** Llama 2 is intended for commercial and research use in English. Tuned models are intended for assistant-like chat, whereas pretrained models can be adapted for a variety of natural language generation tasks.

To get the expected features and performance for the chat versions, a specific formatting needs to be followed, including the `INST` and `<<SYS>>` tags, `BOS` and `EOS` tokens, and the whitespaces and breaklines in between (we recommend calling `strip()` on inputs to avoid double-spaces). See our reference code in github for details: [`chat_completion`](https://github.com/facebookresearch/llama/blob/main/llama/generation.py#L212).

**Out-of-scope Uses** Use in any manner that violates applicable laws or regulations (including trade compliance laws).Use in languages other than English. Use in any other way that is prohibited by the Acceptable Use Policy and Licensing Agreement for Llama 2.

## Hardware and Software
**Training Factors** We used custom training libraries, Meta's Research Super Cluster, and production clusters for pretraining. Fine-tuning, annotation, and evaluation were also performed on third-party cloud compute.

**Carbon Footprint** Pretraining utilized a cumulative 3.3M GPU hours of computation on hardware of type A100-80GB (TDP of 350-400W). Estimated total emissions were 539 tCO2eq, 100% of which were offset by Meta’s sustainability program.

||Time (GPU hours)|Power Consumption (W)|Carbon Emitted(tCO<sub>2</sub>eq)|
|---|---|---|---|
|Llama 2 7B|184320|400|31.22|
|Llama 2 13B|368640|400|62.44|
|Llama 2 70B|1720320|400|291.42|
|Total|3311616||539.00|

**CO<sub>2</sub> emissions during pretraining.** Time: total GPU time required for training each model. Power Consumption: peak power capacity per GPU device for the GPUs used adjusted for power usage efficiency. 100% of the emissions are directly offset by Meta's sustainability program, and because we are openly releasing these models, the pretraining costs do not need to be incurred by others.

## Training Data
**Overview** Llama 2 was pretrained on 2 trillion tokens of data from publicly available sources. The fine-tuning data includes publicly available instruction datasets, as well as over one million new human-annotated examples. Neither the pretraining nor the fine-tuning datasets include Meta user data.

**Data Freshness** The pretraining data has a cutoff of September 2022, but some tuning data is more recent, up to July 2023.

## Evaluation Results

In this section, we report the results for the Llama 1 and Llama 2 models on standard academic benchmarks.For all the evaluations, we use our internal evaluations library.

|Model|Size|Code|Commonsense Reasoning|World Knowledge|Reading Comprehension|Math|MMLU|BBH|AGI Eval|
|---|---|---|---|---|---|---|---|---|---|
|Llama 1|7B|14.1|60.8|46.2|58.5|6.95|35.1|30.3|23.9|
|Llama 1|13B|18.9|66.1|52.6|62.3|10.9|46.9|37.0|33.9|
|Llama 1|33B|26.0|70.0|58.4|67.6|21.4|57.8|39.8|41.7|
|Llama 1|65B|30.7|70.7|60.5|68.6|30.8|63.4|43.5|47.6|
|Llama 2|7B|16.8|63.9|48.9|61.3|14.6|45.3|32.6|29.3|
|Llama 2|13B|24.5|66.9|55.4|65.8|28.7|54.8|39.4|39.1|
|Llama 2|70B|**37.5**|**71.9**|**63.6**|**69.4**|**35.2**|**68.9**|**51.2**|**54.2**|

**Overall performance on grouped academic benchmarks.** *Code:* We report the average pass@1 scores of our models on HumanEval and MBPP. *Commonsense Reasoning:* We report the average of PIQA, SIQA, HellaSwag, WinoGrande, ARC easy and challenge, OpenBookQA, and CommonsenseQA. We report 7-shot results for CommonSenseQA and 0-shot results for all other benchmarks. *World Knowledge:* We evaluate the 5-shot performance on NaturalQuestions and TriviaQA and report the average. *Reading Comprehension:* For reading comprehension, we report the 0-shot average on SQuAD, QuAC, and BoolQ. *MATH:* We report the average of the GSM8K (8 shot) and MATH (4 shot) benchmarks at top 1.

|||TruthfulQA|Toxigen|
|---|---|---|---|
|Llama 1|7B|27.42|23.00|
|Llama 1|13B|41.74|23.08|
|Llama 1|33B|44.19|22.57|
|Llama 1|65B|48.71|21.77|
|Llama 2|7B|33.29|**21.25**|
|Llama 2|13B|41.86|26.10|
|Llama 2|70B|**50.18**|24.60|

**Evaluation of pretrained LLMs on automatic safety benchmarks.** For TruthfulQA, we present the percentage of generations that are both truthful and informative (the higher the better). For ToxiGen, we present the percentage of toxic generations (the smaller the better).


|||TruthfulQA|Toxigen|
|---|---|---|---|
|Llama-2-Chat|7B|57.04|**0.00**|
|Llama-2-Chat|13B|62.18|**0.00**|
|Llama-2-Chat|70B|**64.14**|0.01|

**Evaluation of fine-tuned LLMs on different safety datasets.** Same metric definitions as above.

## Ethical Considerations and Limitations
Llama 2 is a new technology that carries risks with use. Testing conducted to date has been in English, and has not covered, nor could it cover all scenarios. For these reasons, as with all LLMs, Llama 2’s potential outputs cannot be predicted in advance, and the model may in some instances produce inaccurate, biased or other objectionable responses to user prompts. Therefore, before deploying any applications of Llama 2, developers should perform safety testing and tuning tailored to their specific applications of the model.

Please see the Responsible Use Guide available at [https://ai.meta.com/llama/responsible-use-guide/](https://ai.meta.com/llama/responsible-use-guide)

## Reporting Issues
Please report any software “bug,” or other problems with the models through one of the following means:
- Reporting issues with the model: [github.com/facebookresearch/llama](http://github.com/facebookresearch/llama)
- Reporting problematic content generated by the model: [developers.facebook.com/llama_output_feedback](http://developers.facebook.com/llama_output_feedback)
- Reporting bugs and security concerns: [facebook.com/whitehat/info](http://facebook.com/whitehat/info)

## Llama Model Index
|Model|Llama2|Llama2-hf|Llama2-chat|Llama2-chat-hf|
|---|---|---|---|---|
|7B| [Link](https://huggingface.co/meta-llama/Llama-2-7b) | [Link](https://huggingface.co/meta-llama/Llama-2-7b-hf) | [Link](https://huggingface.co/meta-llama/Llama-2-7b-chat) | [Link](https://huggingface.co/meta-llama/Llama-2-7b-chat-hf)|
|13B| [Link](https://huggingface.co/meta-llama/Llama-2-13b) | [Link](https://huggingface.co/meta-llama/Llama-2-13b-hf) | [Link](https://huggingface.co/meta-llama/Llama-2-13b-chat) | [Link](https://huggingface.co/meta-llama/Llama-2-13b-chat-hf)|
|70B| [Link](https://huggingface.co/meta-llama/Llama-2-70b) | [Link](https://huggingface.co/meta-llama/Llama-2-70b-hf) | [Link](https://huggingface.co/meta-llama/Llama-2-70b-chat) | [Link](https://huggingface.co/meta-llama/Llama-2-70b-chat-hf)|"""^^xsd:string ;
    schema:discussionUrl <https://huggingface.co/meta-llama/Llama-2-7b-hf/discussions> ;
    schema:distribution "Information not found."^^xsd:string ;
    schema:funding "Information not found."^^xsd:string ;
    schema:identifier "https://huggingface.co/meta-llama/Llama-2-7b-hf"^^xsd:string ;
    schema:inLanguage "en"^^xsd:string ;
    schema:keywords <http://mlentory.zbmed.de/mlentory_graph/0dce0f5e7319b6178cd79d5f2163f0e134d0064f4ea4f93e8afeec1e7d78fa8d>,
        <http://mlentory.zbmed.de/mlentory_graph/11ee21b926795a2b7d2cb2d939044519ace34ac86e6b6a59a47dcb4bba5eb7a4>,
        <http://mlentory.zbmed.de/mlentory_graph/1f1b91c653f20f0cf893aeb65fa83459983d2cb51e18030488be0e30b0e6db67>,
        <http://mlentory.zbmed.de/mlentory_graph/32934a13e4d01c327dbef8b4279d190d77f3095d7022f9465dc377bbb3565c94>,
        <http://mlentory.zbmed.de/mlentory_graph/3e9a4e1232f617b33fa8460d6c142ee49e69eb5c55acfd1e618d58e7495955e8>,
        <http://mlentory.zbmed.de/mlentory_graph/759dcfce11b186065b46fb94fef1c569da9001c123861ba72ba0708e554bd6c4>,
        <http://mlentory.zbmed.de/mlentory_graph/79cf083846a8329d2912fcd7f375233c37a54917af291bb945f0b58bc735b8ad>,
        <http://mlentory.zbmed.de/mlentory_graph/81c4f52fcccf6ef0d25453aedb7cebe30c7034e3b2fa752246d0e43da889a0e1>,
        <http://mlentory.zbmed.de/mlentory_graph/87b927fef88a46248b3b208472aec7bfeb38667386b309f46772e26b40f6affb>,
        <http://mlentory.zbmed.de/mlentory_graph/df4982af808ead1a57663cc7a83e60059f6a6ae1baf83a270fdf8bdfef11a3de>,
        <http://mlentory.zbmed.de/mlentory_graph/f59cf55f3a86acf0bcfc020eac552a72c13f1212154211a7bf30504548661f8d>,
        "arxiv:2307.09288"^^xsd:string,
        "en"^^xsd:string,
        "license:llama2"^^xsd:string,
        "region:us"^^xsd:string ;
    schema:license "llama2"^^xsd:string ;
    schema:maintainer "Information not found."^^xsd:string ;
    schema:memoryRequirements "Not available"^^xsd:string ;
    schema:name "Llama-2-7b-hf"^^xsd:string ;
    schema:operatingSystem "Information not found."^^xsd:string ;
    schema:processorRequirements "The context provided does not contain information about the processor requirements for running the application."^^xsd:string ;
    schema:releaseNotes """---
extra_gated_heading: You need to share contact information with Meta to access this
  model
extra_gated_prompt: "### LLAMA 2 COMMUNITY LICENSE AGREEMENT\\n\\"Agreement\\" means\\
  \\ the terms and conditions for use, reproduction, distribution and  modification\\
  \\ of the Llama Materials set forth herein. \\n\\"Documentation\\" means the specifications,\\
  \\ manuals and documentation  accompanying Llama 2 distributed by Meta at https://ai.meta.com/resources/models-and-libraries/llama-downloads/.\\
  \\  \\n\\"Licensee\\" or \\"you\\" means you, or your employer or any other person or\\
  \\ entity (if you are entering into this Agreement on such person or entity's behalf),\\
  \\ of the age required under applicable laws, rules or regulations to provide legal\\
  \\ consent and that has legal authority to bind your employer or such other person\\
  \\ or  entity if you are  entering in this Agreement on their behalf. \\n\\"Llama 2\\"\\
  \\ means the foundational large language models and software and algorithms, including\\
  \\ machine-learning model code, trained model weights, inference-enabling code, training-enabling\\
  \\ code, fine-tuning enabling code and other  elements of the foregoing distributed\\
  \\ by Meta at ai.meta.com/resources/models-and-libraries/llama-downloads/.\\n\\"Llama\\
  \\ Materials\\" means, collectively, Meta's proprietary Llama 2 and documentation\\
  \\ (and any portion thereof) made available under this Agreement.\\n\\"Meta\\" or \\"\\
  we\\" means Meta Platforms Ireland Limited (if you are located in or, if you are\\
  \\ an entity, your principal place of business is in the EEA or Switzerland) and\\
  \\ Meta Platforms, Inc. (if you are located outside of the EEA or Switzerland). \\n\\
  \\nBy clicking \\"I Accept\\" below or by using or distributing any portion or element\\
  \\ of the Llama Materials, you agree to be bound by this Agreement.\\n1. License Rights\\
  \\ and Redistribution. \\na. Grant of Rights. You are granted a non-exclusive, worldwide,\\
  \\ non- transferable and royalty-free limited license under Meta's intellectual property\\
  \\ or  other rights owned by Meta embodied in the Llama Materials to use, reproduce,\\
  \\  distribute, copy, create derivative works of, and make modifications to the Llama\\
  \\  Materials.  \\nb. Redistribution and Use.\\ni. If you distribute or make the Llama\\
  \\ Materials, or any derivative works  thereof, available to a third party, you shall\\
  \\ provide a copy of this Agreement to such  third party. \\nii.  If you receive Llama\\
  \\ Materials, or any derivative works thereof, from  a Licensee as part of an integrated\\
  \\ end user product, then Section 2 of this  Agreement will not apply to you. \\n\\
  iii. You must retain in all copies of the Llama Materials that you  distribute the\\
  \\ following attribution notice within a \\"Notice\\" text file distributed as a  part\\
  \\ of such copies: \\"Llama 2 is licensed under the LLAMA 2 Community License,  Copyright\\
  \\ (c) Meta Platforms, Inc. All Rights Reserved.\\"\\niv. Your use of the Llama Materials\\
  \\ must comply with applicable laws  and regulations (including trade compliance\\
  \\ laws and regulations) and adhere to the  Acceptable Use Policy for the Llama Materials\\
  \\ (available at  https://ai.meta.com/llama/use-policy), which is hereby incorporated\\
  \\ by reference into  this Agreement.\\nv. You will not use the Llama Materials or\\
  \\ any output or results of the  Llama Materials to improve any other large language\\
  \\ model (excluding Llama 2 or  derivative works thereof).  \\n\\n2. Additional Commercial\\
  \\ Terms. If, on the Llama 2 version release date, the  monthly active users of the\\
  \\ products or services made available by or for Licensee,  or Licensee's affiliates,\\
  \\ is greater than 700 million monthly active users in the  preceding calendar month,\\
  \\ you must request a license from Meta, which Meta may  grant to you in its sole\\
  \\ discretion, and you are not authorized to exercise any of the  rights under this\\
  \\ Agreement unless or until Meta otherwise expressly grants you  such rights.\\n\\
  3. Disclaimer of Warranty. UNLESS REQUIRED BY APPLICABLE LAW, THE  LLAMA MATERIALS\\
  \\ AND ANY OUTPUT AND RESULTS THEREFROM ARE  PROVIDED ON AN \\"AS IS\\" BASIS, WITHOUT\\
  \\ WARRANTIES OF ANY KIND,  EITHER EXPRESS OR IMPLIED, INCLUDING, WITHOUT LIMITATION,\\
  \\ ANY  WARRANTIES OF TITLE, NON-INFRINGEMENT, MERCHANTABILITY, OR  FITNESS FOR A\\
  \\ PARTICULAR PURPOSE. YOU ARE SOLELY RESPONSIBLE  FOR DETERMINING THE APPROPRIATENESS\\
  \\ OF USING OR REDISTRIBUTING  THE LLAMA MATERIALS AND ASSUME ANY RISKS ASSOCIATED\\
  \\ WITH YOUR  USE OF THE LLAMA MATERIALS AND ANY OUTPUT AND RESULTS.\\n4. Limitation\\
  \\ of Liability. IN NO EVENT WILL META OR ITS AFFILIATES BE  LIABLE UNDER ANY THEORY\\
  \\ OF LIABILITY, WHETHER IN CONTRACT, TORT,  NEGLIGENCE, PRODUCTS LIABILITY, OR OTHERWISE,\\
  \\ ARISING OUT OF THIS  AGREEMENT, FOR ANY LOST PROFITS OR ANY INDIRECT, SPECIAL,\\
  \\  CONSEQUENTIAL, INCIDENTAL, EXEMPLARY OR PUNITIVE DAMAGES, EVEN  IF META OR ITS\\
  \\ AFFILIATES HAVE BEEN ADVISED OF THE POSSIBILITY OF  ANY OF THE FOREGOING.\\n\\n\\
  5. Intellectual Property.\\na. No trademark licenses are granted under this Agreement,\\
  \\ and in  connection with the Llama Materials, neither Meta nor Licensee may use\\
  \\ any name  or mark owned by or associated with the other or any of its affiliates,\\
  \\ except as  required for reasonable and customary use in describing and redistributing\\
  \\ the  Llama Materials.\\nb. Subject to Meta's ownership of Llama Materials and derivatives\\
  \\ made by or  for Meta, with respect to any derivative works and modifications of\\
  \\ the Llama  Materials that are made by you, as between you and Meta, you are and\\
  \\ will be the  owner of such derivative works and modifications.\\nc. If you institute\\
  \\ litigation or other proceedings against Meta or any entity  (including a cross-claim\\
  \\ or counterclaim in a lawsuit) alleging that the Llama  Materials or Llama 2 outputs\\
  \\ or results, or any portion of any of the foregoing,  constitutes infringement\\
  \\ of intellectual property or other rights owned or licensable  by you, then any\\
  \\ licenses granted to you under this Agreement shall terminate as of  the date such\\
  \\ litigation or claim is filed or instituted. You will indemnify and hold  harmless\\
  \\ Meta from and against any claim by any third party arising out of or related \\
  \\ to your use or distribution of the Llama Materials.\\n6. Term and Termination.\\
  \\ The term of this Agreement will commence upon your  acceptance of this Agreement\\
  \\ or access to the Llama Materials and will continue in  full force and effect until\\
  \\ terminated in accordance with the terms and conditions  herein. Meta may terminate\\
  \\ this Agreement if you are in breach of any term or  condition of this Agreement.\\
  \\ Upon termination of this Agreement, you shall delete  and cease use of the Llama\\
  \\ Materials. Sections 3, 4 and 7 shall survive the  termination of this Agreement.\\
  \\ \\n7. Governing Law and Jurisdiction. This Agreement will be governed and  construed\\
  \\ under the laws of the State of California without regard to choice of law  principles,\\
  \\ and the UN Convention on Contracts for the International Sale of Goods  does not\\
  \\ apply to this Agreement. The courts of California shall have exclusive  jurisdiction\\
  \\ of any dispute arising out of this Agreement. \\n### Llama 2 Acceptable Use Policy\\n\\
  Meta is committed to promoting safe and fair use of its tools and features, including\\
  \\ Llama 2. If you access or use Llama 2, you agree to this Acceptable Use Policy\\
  \\ (“Policy”). The most recent copy of this policy can be found at [ai.meta.com/llama/use-policy](http://ai.meta.com/llama/use-policy).\\n\\
  #### Prohibited Uses\\nWe want everyone to use Llama 2 safely and responsibly. You\\
  \\ agree you will not use, or allow others to use, Llama 2 to:\\n1. Violate the law\\
  \\ or others’ rights, including to:\\n      1. Engage in, promote, generate, contribute\\
  \\ to, encourage, plan, incite, or further illegal or unlawful activity or content,\\
  \\ such as: \\n          1. Violence or terrorism \\n          2. Exploitation or harm\\
  \\ to children, including the solicitation, creation, acquisition, or dissemination\\
  \\ of child exploitative content or failure to report Child Sexual Abuse Material\\n\\
  \\          3. Human trafficking, exploitation, and sexual violence\\n          4.\\
  \\ The illegal distribution of information or materials to minors, including obscene\\
  \\ materials, or failure to employ legally required age-gating in connection with\\
  \\ such information or materials.\\n          5. Sexual solicitation\\n          6.\\
  \\ Any other criminal activity\\n      2. Engage in, promote, incite, or facilitate\\
  \\ the harassment, abuse, threatening, or bullying of individuals or groups of individuals\\n\\
  \\      3. Engage in, promote, incite, or facilitate discrimination or other unlawful\\
  \\ or harmful conduct in the provision of employment, employment benefits, credit,\\
  \\ housing, other economic benefits, or other essential goods and services\\n    \\
  \\  4. Engage in the unauthorized or unlicensed practice of any profession including,\\
  \\ but not limited to, financial, legal, medical/health, or related professional\\
  \\ practices \\n      5. Collect, process, disclose, generate, or infer health, demographic,\\
  \\ or other sensitive personal or private information about individuals without rights\\
  \\ and consents required by applicable laws\\n      6. Engage in or facilitate any\\
  \\ action or generate any content that infringes, misappropriates, or otherwise violates\\
  \\ any third-party rights, including the outputs or results of any products or services\\
  \\ using the Llama 2 Materials\\n      7. Create, generate, or facilitate the creation\\
  \\ of malicious code, malware, computer viruses or do anything else that could disable,\\
  \\ overburden, interfere with or impair the proper working, integrity, operation\\
  \\ or appearance of a website or computer system \\n2. Engage in, promote, incite,\\
  \\ facilitate, or assist in the planning or development of activities that present\\
  \\ a risk of death or bodily harm to individuals, including use of Llama 2 related\\
  \\ to the following:\\n    1. Military, warfare, nuclear industries or applications,\\
  \\ espionage, use for materials or activities that are subject to the International\\
  \\ Traffic Arms Regulations (ITAR) maintained by the United States Department of\\
  \\ State\\n    2. Guns and illegal weapons (including weapon development)\\n    3.\\
  \\ Illegal drugs and regulated/controlled substances\\n    4. Operation of critical\\
  \\ infrastructure, transportation technologies, or heavy machinery\\n    5. Self-harm\\
  \\ or harm to others, including suicide, cutting, and eating disorders\\n    6. Any\\
  \\ content intended to incite or promote violence, abuse, or any infliction of bodily\\
  \\ harm to an individual\\n3. Intentionally deceive or mislead others, including use\\
  \\ of Llama 2 related to the following:\\n    1. Generating, promoting, or furthering\\
  \\ fraud or the creation or promotion of disinformation\\n    2. Generating, promoting,\\
  \\ or furthering defamatory content, including the creation of defamatory statements,\\
  \\ images, or other content\\n    3. Generating, promoting, or further distributing\\
  \\ spam\\n    4. Impersonating another individual without consent, authorization,\\
  \\ or legal right\\n    5. Representing that the use of Llama 2 or outputs are human-generated\\n\\
  \\    6. Generating or facilitating false online engagement, including fake reviews\\
  \\ and other means of fake online engagement \\n    4. Fail to appropriately disclose\\
  \\ to end users any known dangers of your AI system \\nPlease report any violation\\
  \\ of this Policy, software “bug,” or other problems that could lead to a violation\\
  \\ of this Policy through one of the following means: \\n    * Reporting issues with\\
  \\ the model: [github.com/facebookresearch/llama](http://github.com/facebookresearch/llama)\\n\\
  \\    * Reporting risky content generated by the model: [developers.facebook.com/llama_output_feedback](http://developers.facebook.com/llama_output_feedback)\\n\\
  \\    * Reporting bugs and security concerns: [facebook.com/whitehat/info](http://facebook.com/whitehat/info)\\
  \\ \\n    * Reporting violations of the Acceptable Use Policy or unlicensed uses of\\
  \\ Llama: [LlamaUseReport@meta.com](mailto:LlamaUseReport@meta.com)"
extra_gated_fields:
  First Name: text
  Last Name: text
  Date of birth: date_picker
  Country: country
  Affiliation: text
  geo: ip_location
  ? By clicking Submit below I accept the terms of the license and acknowledge that
    the information I provide will be collected stored processed and shared in accordance
    with the Meta Privacy Policy
  : checkbox
extra_gated_description: The information you provide will be collected, stored, processed
  and shared in accordance with the [Meta Privacy Policy](https://www.facebook.com/privacy/policy/).
extra_gated_button_content: Submit
language:
- en
pipeline_tag: text-generation
tags:
- facebook
- meta
- pytorch
- llama
- llama-2
license: llama2
---
# **Llama 2**
Llama 2 is a collection of pretrained and fine-tuned generative text models ranging in scale from 7 billion to 70 billion parameters. This is the repository for the 7B pretrained model, converted for the Hugging Face Transformers format. Links to other models can be found in the index at the bottom.

## Model Details
*Note: Use of this model is governed by the Meta license. In order to download the model weights and tokenizer, please visit the [website](https://ai.meta.com/resources/models-and-libraries/llama-downloads/) and accept our License before requesting access here.*

Meta developed and publicly released the Llama 2 family of large language models (LLMs), a collection of pretrained and fine-tuned generative text models ranging in scale from 7 billion to 70 billion parameters. Our fine-tuned LLMs, called Llama-2-Chat, are optimized for dialogue use cases. Llama-2-Chat models outperform open-source chat models on most benchmarks we tested, and in our human evaluations for helpfulness and safety, are on par with some popular closed-source models like ChatGPT and PaLM.

**Model Developers** Meta

**Variations** Llama 2 comes in a range of parameter sizes — 7B, 13B, and 70B — as well as pretrained and fine-tuned variations.

**Input** Models input text only.

**Output** Models generate text only.

**Model Architecture** Llama 2 is an auto-regressive language model that uses an optimized transformer architecture. The tuned versions use supervised fine-tuning (SFT) and reinforcement learning with human feedback (RLHF) to align to human preferences for helpfulness and safety.


||Training Data|Params|Content Length|GQA|Tokens|LR|
|---|---|---|---|---|---|---|
|Llama 2|*A new mix of publicly available online data*|7B|4k|&#10007;|2.0T|3.0 x 10<sup>-4</sup>|
|Llama 2|*A new mix of publicly available online data*|13B|4k|&#10007;|2.0T|3.0 x 10<sup>-4</sup>|
|Llama 2|*A new mix of publicly available online data*|70B|4k|&#10004;|2.0T|1.5 x 10<sup>-4</sup>|

*Llama 2 family of models.* Token counts refer to pretraining data only. All models are trained with a global batch-size of 4M tokens. Bigger models -  70B -- use Grouped-Query Attention (GQA) for improved inference scalability.

**Model Dates** Llama 2 was trained between January 2023 and July 2023.

**Status** This is a static model trained on an offline dataset. Future versions of the tuned models will be released as we improve model safety with community feedback.

**License** A custom commercial license is available at: [https://ai.meta.com/resources/models-and-libraries/llama-downloads/](https://ai.meta.com/resources/models-and-libraries/llama-downloads/)

**Research Paper** ["Llama-2: Open Foundation and Fine-tuned Chat Models"](arxiv.org/abs/2307.09288)

## Intended Use
**Intended Use Cases** Llama 2 is intended for commercial and research use in English. Tuned models are intended for assistant-like chat, whereas pretrained models can be adapted for a variety of natural language generation tasks.

To get the expected features and performance for the chat versions, a specific formatting needs to be followed, including the `INST` and `<<SYS>>` tags, `BOS` and `EOS` tokens, and the whitespaces and breaklines in between (we recommend calling `strip()` on inputs to avoid double-spaces). See our reference code in github for details: [`chat_completion`](https://github.com/facebookresearch/llama/blob/main/llama/generation.py#L212).

**Out-of-scope Uses** Use in any manner that violates applicable laws or regulations (including trade compliance laws).Use in languages other than English. Use in any other way that is prohibited by the Acceptable Use Policy and Licensing Agreement for Llama 2.

## Hardware and Software
**Training Factors** We used custom training libraries, Meta's Research Super Cluster, and production clusters for pretraining. Fine-tuning, annotation, and evaluation were also performed on third-party cloud compute.

**Carbon Footprint** Pretraining utilized a cumulative 3.3M GPU hours of computation on hardware of type A100-80GB (TDP of 350-400W). Estimated total emissions were 539 tCO2eq, 100% of which were offset by Meta’s sustainability program.

||Time (GPU hours)|Power Consumption (W)|Carbon Emitted(tCO<sub>2</sub>eq)|
|---|---|---|---|
|Llama 2 7B|184320|400|31.22|
|Llama 2 13B|368640|400|62.44|
|Llama 2 70B|1720320|400|291.42|
|Total|3311616||539.00|

**CO<sub>2</sub> emissions during pretraining.** Time: total GPU time required for training each model. Power Consumption: peak power capacity per GPU device for the GPUs used adjusted for power usage efficiency. 100% of the emissions are directly offset by Meta's sustainability program, and because we are openly releasing these models, the pretraining costs do not need to be incurred by others.

## Training Data
**Overview** Llama 2 was pretrained on 2 trillion tokens of data from publicly available sources. The fine-tuning data includes publicly available instruction datasets, as well as over one million new human-annotated examples. Neither the pretraining nor the fine-tuning datasets include Meta user data.

**Data Freshness** The pretraining data has a cutoff of September 2022, but some tuning data is more recent, up to July 2023.

## Evaluation Results

In this section, we report the results for the Llama 1 and Llama 2 models on standard academic benchmarks.For all the evaluations, we use our internal evaluations library.

|Model|Size|Code|Commonsense Reasoning|World Knowledge|Reading Comprehension|Math|MMLU|BBH|AGI Eval|
|---|---|---|---|---|---|---|---|---|---|
|Llama 1|7B|14.1|60.8|46.2|58.5|6.95|35.1|30.3|23.9|
|Llama 1|13B|18.9|66.1|52.6|62.3|10.9|46.9|37.0|33.9|
|Llama 1|33B|26.0|70.0|58.4|67.6|21.4|57.8|39.8|41.7|
|Llama 1|65B|30.7|70.7|60.5|68.6|30.8|63.4|43.5|47.6|
|Llama 2|7B|16.8|63.9|48.9|61.3|14.6|45.3|32.6|29.3|
|Llama 2|13B|24.5|66.9|55.4|65.8|28.7|54.8|39.4|39.1|
|Llama 2|70B|**37.5**|**71.9**|**63.6**|**69.4**|**35.2**|**68.9**|**51.2**|**54.2**|

**Overall performance on grouped academic benchmarks.** *Code:* We report the average pass@1 scores of our models on HumanEval and MBPP. *Commonsense Reasoning:* We report the average of PIQA, SIQA, HellaSwag, WinoGrande, ARC easy and challenge, OpenBookQA, and CommonsenseQA. We report 7-shot results for CommonSenseQA and 0-shot results for all other benchmarks. *World Knowledge:* We evaluate the 5-shot performance on NaturalQuestions and TriviaQA and report the average. *Reading Comprehension:* For reading comprehension, we report the 0-shot average on SQuAD, QuAC, and BoolQ. *MATH:* We report the average of the GSM8K (8 shot) and MATH (4 shot) benchmarks at top 1.

|||TruthfulQA|Toxigen|
|---|---|---|---|
|Llama 1|7B|27.42|23.00|
|Llama 1|13B|41.74|23.08|
|Llama 1|33B|44.19|22.57|
|Llama 1|65B|48.71|21.77|
|Llama 2|7B|33.29|**21.25**|
|Llama 2|13B|41.86|26.10|
|Llama 2|70B|**50.18**|24.60|

**Evaluation of pretrained LLMs on automatic safety benchmarks.** For TruthfulQA, we present the percentage of generations that are both truthful and informative (the higher the better). For ToxiGen, we present the percentage of toxic generations (the smaller the better).


|||TruthfulQA|Toxigen|
|---|---|---|---|
|Llama-2-Chat|7B|57.04|**0.00**|
|Llama-2-Chat|13B|62.18|**0.00**|
|Llama-2-Chat|70B|**64.14**|0.01|

**Evaluation of fine-tuned LLMs on different safety datasets.** Same metric definitions as above.

## Ethical Considerations and Limitations
Llama 2 is a new technology that carries risks with use. Testing conducted to date has been in English, and has not covered, nor could it cover all scenarios. For these reasons, as with all LLMs, Llama 2’s potential outputs cannot be predicted in advance, and the model may in some instances produce inaccurate, biased or other objectionable responses to user prompts. Therefore, before deploying any applications of Llama 2, developers should perform safety testing and tuning tailored to their specific applications of the model.

Please see the Responsible Use Guide available at [https://ai.meta.com/llama/responsible-use-guide/](https://ai.meta.com/llama/responsible-use-guide)

## Reporting Issues
Please report any software “bug,” or other problems with the models through one of the following means:
- Reporting issues with the model: [github.com/facebookresearch/llama](http://github.com/facebookresearch/llama)
- Reporting problematic content generated by the model: [developers.facebook.com/llama_output_feedback](http://developers.facebook.com/llama_output_feedback)
- Reporting bugs and security concerns: [facebook.com/whitehat/info](http://facebook.com/whitehat/info)

## Llama Model Index
|Model|Llama2|Llama2-hf|Llama2-chat|Llama2-chat-hf|
|---|---|---|---|---|
|7B| [Link](https://huggingface.co/meta-llama/Llama-2-7b) | [Link](https://huggingface.co/meta-llama/Llama-2-7b-hf) | [Link](https://huggingface.co/meta-llama/Llama-2-7b-chat) | [Link](https://huggingface.co/meta-llama/Llama-2-7b-chat-hf)|
|13B| [Link](https://huggingface.co/meta-llama/Llama-2-13b) | [Link](https://huggingface.co/meta-llama/Llama-2-13b-hf) | [Link](https://huggingface.co/meta-llama/Llama-2-13b-chat) | [Link](https://huggingface.co/meta-llama/Llama-2-13b-chat-hf)|
|70B| [Link](https://huggingface.co/meta-llama/Llama-2-70b) | [Link](https://huggingface.co/meta-llama/Llama-2-70b-hf) | [Link](https://huggingface.co/meta-llama/Llama-2-70b-chat) | [Link](https://huggingface.co/meta-llama/Llama-2-70b-chat-hf)|"""^^xsd:string ;
    schema:softwareHelp "Information not found."^^xsd:string ;
    schema:softwareRequirements "Information not found."^^xsd:string ;
    schema:storageRequirements "Information not found."^^xsd:string ;
    schema:url <https://huggingface.co/meta-llama/Llama-2-7b-hf> ;
    schema:version "Information not found."^^xsd:string ;
    ns3:buildInstructions "Information not found."^^xsd:string ;
    ns3:developmentStatus "The development status of Llama 2 is described as \"This is a static model trained on an offline dataset. Future versions of the tuned models will be released as we improve model safety with community feedback.\""^^xsd:string ;
    ns3:issueTracker <https://huggingface.co/meta-llama/Llama-2-7b-hf/discussions> ;
    ns3:readme <https://huggingface.co/meta-llama/Llama-2-7b-hf/blob/main/README.md> ;
    ns3:referencePublication <http://mlentory.zbmed.de/mlentory_graph/eecd2795372f69eac8c76964a6326966b25f090f48f4e8b55cbde405af29a119> .

<http://mlentory.zbmed.de/mlentory_graph/956922acae22f21b82ce000e45d4739baf3f94e8b6eb2825a93166a8ccfc2fbf> a schema:DefinedTerm ;
    schema:description "NLP library developed by Baidu based on PaddlePaddle, offering Chinese and multilingual support."^^xsd:string ;
    schema:name "paddlenlp"^^xsd:string .

<http://mlentory.zbmed.de/mlentory_graph/9db08d1a554609ae7c645781f30f4c335c5142d3c63fde5964e29f8a404c9566> a schema:DefinedTerm ;
    schema:description "Efficient framework for few-shot text classification using Sentence Transformers."^^xsd:string ;
    schema:name "setfit"^^xsd:string .

<http://mlentory.zbmed.de/mlentory_graph/a0e0c1ddbfc3fa3aaab6bbd4ee4022410d9adc63e05996f59a545a7929aaf019> a schema:DefinedTerm ;
    schema:description "Open-source implementation of CLIP (Contrastive Language-Image Pre-Training) models."^^xsd:string ;
    schema:name "OpenCLIP"^^xsd:string .

<http://mlentory.zbmed.de/mlentory_graph/a225e69a17f4be8c51cc1f1852c40371a478cfa95661008284bc676564a876e9> a schema:DefinedTerm ;
    schema:description "High-level neural networks API, designed for human beings, not machines, focusing on enabling fast experimentation."^^xsd:string ;
    schema:name "Keras"^^xsd:string .

<http://mlentory.zbmed.de/mlentory_graph/a2f3a1fe1480acaf0753eb2d5ef88519c7b81e26e6505fed6d5c93c3a5119a65> a schema:DefinedTerm ;
    schema:description "Framework for efficiently deploying models on Intelligence Processing Unit (IPU) hardware."^^xsd:string ;
    schema:name "Graphcore"^^xsd:string .

<http://mlentory.zbmed.de/mlentory_graph/a3c9ca93ab7ec29d067dd25733037f174c1326ef487292e5e1c9eea5cb35feb1> a schema:DefinedTerm ;
    schema:description "Set of reliable implementations of reinforcement learning algorithms in PyTorch."^^xsd:string ;
    schema:name "stable-baselines3"^^xsd:string .

<http://mlentory.zbmed.de/mlentory_graph/a464d85abf29c8b2f8dc299e9fe390a547c8450e42b7ab0ccaac88fdcaeaaa84> a schema:DefinedTerm ;
    schema:description "Predicts missing words or tokens in masked text."^^xsd:string ;
    schema:name "Fill Mask"^^xsd:string .

<http://mlentory.zbmed.de/mlentory_graph/ab2624f913f0d530408cbfa25c29a33523a1a481ba19c3d46f91a6fac4e63844> a schema:DefinedTerm ;
    schema:description "Detects objects in categories not seen during training."^^xsd:string ;
    schema:name "Zero Shot Object Detection"^^xsd:string .

<http://mlentory.zbmed.de/mlentory_graph/ae90ef66c09404023339909f0f1856b23a74105facc2f47abece54a0793d7e33> a schema:Person .

<http://mlentory.zbmed.de/mlentory_graph/b07372cae2aaf834044064c3f58684a47c8f4685d11fccf85dbb95dac4dc7141> a schema:DefinedTerm ;
    schema:description "Neural building blocks for speaker diarization in Python, supporting voice activity detection and speaker embedding."^^xsd:string ;
    schema:name "pyannote.audio"^^xsd:string .

<http://mlentory.zbmed.de/mlentory_graph/b47d8ed02d0fc1a7d72d5d61255296300a82f2caa55dd809c63448bfdd9b4284> a schema:DefinedTerm ;
    schema:description "Analyzes and learns from graph-structured data."^^xsd:string ;
    schema:name "Graph Machine Learning"^^xsd:string .

<http://mlentory.zbmed.de/mlentory_graph/b6726f6435b32ab359d8c48bd5f24d3180c4c1772a769d50d3b4c8cf8f0ecd46> a schema:DefinedTerm ;
    schema:description "Models created by merging multiple other models, often to combine their strengths or capabilities."^^xsd:string ;
    schema:name "Merge"^^xsd:string .

<http://mlentory.zbmed.de/mlentory_graph/b6bffbd25ee4f19a8e55b6c7f32040744865e1e7d74080964d19fac6f207948c> a schema:DefinedTerm ;
    schema:description "Lightweight solution for mobile and embedded devices to run optimized TensorFlow models with low latency."^^xsd:string ;
    schema:name "TF Lite"^^xsd:string .

<http://mlentory.zbmed.de/mlentory_graph/b9cbedab515a4ba3d4c78d2aaebae3eaaa730c9bfc49212dad2910d0f2c63595> a schema:DefinedTerm ;
    schema:description "Categorizes audio clips into predefined classes."^^xsd:string ;
    schema:name "Audio Classification"^^xsd:string .

<http://mlentory.zbmed.de/mlentory_graph/bbf4caca758174ac9ca1258e1174d6c6d75a330218b88807385547a31f8229ab> a schema:DefinedTerm ;
    schema:description "Comprehensive machine learning library for Python featuring various classification, regression, and clustering algorithms."^^xsd:string ;
    schema:name "Scikit-learn"^^xsd:string .

<http://mlentory.zbmed.de/mlentory_graph/bc53f85f6e664d1c6ece992a9d80b2e0705d1b3c75028563adb2ed9f36aedec9> a schema:DefinedTerm ;
    schema:description "Memory-safe, high-performance language used for building efficient ML systems and infrastructure."^^xsd:string ;
    schema:name "Rust"^^xsd:string .

<http://mlentory.zbmed.de/mlentory_graph/bc69543009040d6e8dba73b201af25ed291f7933acca2056091eb5f643c4f919> a schema:DefinedTerm ;
    schema:description "Models based on RoBERTa (Robustly Optimized BERT Approach), an optimized BERT variant with improved pretraining and performance."^^xsd:string ;
    schema:name "roberta"^^xsd:string .

<http://mlentory.zbmed.de/mlentory_graph/c0097ccf601f8114782f9c0c86386c6c995d5b2e12eddde21fdd7251761ee1fd> a schema:DefinedTerm ;
    schema:description "Framework for running ML workloads on Habana Gaudi accelerators with performance optimization."^^xsd:string ;
    schema:name "Habana"^^xsd:string .

<http://mlentory.zbmed.de/mlentory_graph/c6a31d1f7013eb41349bc590b0cc16d51b0a1706fa3f70c1337a8eecf06d2173> a schema:DefinedTerm ;
    schema:description "Identifies and locates objects within images using bounding boxes."^^xsd:string ;
    schema:name "Object Detection"^^xsd:string .

<http://mlentory.zbmed.de/mlentory_graph/c7062dc4cfa463be9c92783a4d2c8abb9a4b37f71f4caef7c07cd6787e1843ed> a schema:DefinedTerm ;
    schema:description "Transforms static images into video sequences."^^xsd:string ;
    schema:name "Imageto Video"^^xsd:string .

<http://mlentory.zbmed.de/mlentory_graph/c736da741f27fe816e63dbbfd53bc7e85fcc1276fc2e38ffea11708f1297d3b1> a schema:Organization .

<http://mlentory.zbmed.de/mlentory_graph/cb9bd15fb27d24d93383343fa6ee37e644b0a41da399de954b0a5cf93c7b3501> a schema:DefinedTerm ;
    schema:description "Labels individual tokens (words) in text with specific categories."^^xsd:string ;
    schema:name "Token Classification"^^xsd:string .

<http://mlentory.zbmed.de/mlentory_graph/cba5458c023bd0e333fefb47511914b963716a71b0356b435370871727585038> a schema:DefinedTerm ;
    schema:description "Generates video content based on textual descriptions."^^xsd:string ;
    schema:name "Text to Video"^^xsd:string .

<http://mlentory.zbmed.de/mlentory_graph/d1054f9c274823fbeb3d1ab19d0f2344791cee18915cdb21fb1437bba03ba8fb> a schema:DefinedTerm ;
    schema:description "Predicts continuous values from tabular data."^^xsd:string ;
    schema:name "Tabular Regression"^^xsd:string .

<http://mlentory.zbmed.de/mlentory_graph/d462b48c96b732d754a938aa86dbd16bfb7478ca5b0c1f1f006c611c112094e9> a schema:DefinedTerm ;
    schema:description "State-of-the-art library for diffusion models across multiple modalities like vision and audio."^^xsd:string ;
    schema:name "Diffusers"^^xsd:string .

<http://mlentory.zbmed.de/mlentory_graph/d6f86ddd52b22c26a6970ea3473a2f8e657e9600a3cea6dd33e7307bf848d475> a schema:DefinedTerm ;
    schema:description "All-in-one toolkit for speech technology research, including ASR, speaker recognition, and speech enhancement."^^xsd:string ;
    schema:name "speechbrain"^^xsd:string .

<http://mlentory.zbmed.de/mlentory_graph/d75a16357850d2896a768db42c912a9487fd97a50f3358217d5bbb602c39b195> a schema:DefinedTerm ;
    schema:description "Indicates a HuggingFace Space demo exists for this model allowing interactive testing without setup."^^xsd:string ;
    schema:name "Has a Space"^^xsd:string .

<http://mlentory.zbmed.de/mlentory_graph/dc96ea445d125873bc02183accca8dffafbc58c6100167ef5b113919f5afb57e> a schema:DefinedTerm ;
    schema:description "Generates 3D models or scenes from textual descriptions."^^xsd:string ;
    schema:name "Text to 3D"^^xsd:string .

<http://mlentory.zbmed.de/mlentory_graph/dd477ce37bc2c08950a1d845aa243dff8c0e03de15cc42b9b35295d514538a84> a schema:DefinedTerm ;
    schema:description "Converts text from one language to another."^^xsd:string ;
    schema:name "Translation"^^xsd:string .

<http://mlentory.zbmed.de/mlentory_graph/default> a ns2:RecordSet ;
    ns2:field <http://mlentory.zbmed.de/mlentory_graph/default/cf_contest_id>,
        <http://mlentory.zbmed.de/mlentory_graph/default/cf_index>,
        <http://mlentory.zbmed.de/mlentory_graph/default/cf_points>,
        <http://mlentory.zbmed.de/mlentory_graph/default/cf_rating>,
        <http://mlentory.zbmed.de/mlentory_graph/default/cf_tags>,
        <http://mlentory.zbmed.de/mlentory_graph/default/description>,
        <http://mlentory.zbmed.de/mlentory_graph/default/difficulty>,
        <http://mlentory.zbmed.de/mlentory_graph/default/generated_tests>,
        <http://mlentory.zbmed.de/mlentory_graph/default/incorrect_solutions>,
        <http://mlentory.zbmed.de/mlentory_graph/default/input_file>,
        <http://mlentory.zbmed.de/mlentory_graph/default/is_description_translated>,
        <http://mlentory.zbmed.de/mlentory_graph/default/memory_limit_bytes>,
        <http://mlentory.zbmed.de/mlentory_graph/default/name>,
        <http://mlentory.zbmed.de/mlentory_graph/default/output_file>,
        <http://mlentory.zbmed.de/mlentory_graph/default/private_tests>,
        <http://mlentory.zbmed.de/mlentory_graph/default/public_tests>,
        <http://mlentory.zbmed.de/mlentory_graph/default/solutions>,
        <http://mlentory.zbmed.de/mlentory_graph/default/source>,
        <http://mlentory.zbmed.de/mlentory_graph/default/split>,
        <http://mlentory.zbmed.de/mlentory_graph/default/time_limit>,
        <http://mlentory.zbmed.de/mlentory_graph/default/untranslated_description> ;
    schema:description """deepmind/code_contests - 'default' subset (first 5GB)

Additional information:
- 3 splits: train, test, valid"""@en ;
    schema:name "default"@en .

<http://mlentory.zbmed.de/mlentory_graph/default_splits> a ns2:RecordSet ;
    ns2:data "[{\"default_splits/split_name\":\"train\"},{\"default_splits/split_name\":\"test\"},{\"default_splits/split_name\":\"valid\"}]"^^rdf:JSON ;
    ns2:dataType ns2:Split ;
    ns2:field <http://mlentory.zbmed.de/mlentory_graph/default_splits/split_name> ;
    ns2:key <http://mlentory.zbmed.de/mlentory_graph/default_splits/split_name> ;
    schema:description "Splits for the default config."@en ;
    schema:name "default_splits"@en .

<http://mlentory.zbmed.de/mlentory_graph/df2c9c7dc08f5514331c35b3bf3e4da58de6a14c0724dc40f90a3e588f9844dd> a schema:DefinedTerm ;
    schema:description "Models quantized to 4-bit precision, reducing memory footprint while maintaining reasonable performance."^^xsd:string ;
    schema:name "4-bit precision"^^xsd:string .

<http://mlentory.zbmed.de/mlentory_graph/df3db739a5d22c6a5829694aeecdedee4e20b5804f1345689c8abd3350883e54> a schema:DefinedTerm ;
    schema:description "Indicates the model supports deployment through HuggingFace's managed inference API service for production environments."^^xsd:string ;
    schema:name "Inference Endpoints"^^xsd:string .

<http://mlentory.zbmed.de/mlentory_graph/e078bed1369c8c5fcce2b7a45592d476d0658167bd45796ebb54e7af3d414ab4> a ns1:ML_Model ;
    ns1:ethicalLegalSocial "Information not found."^^xsd:string ;
    ns1:evaluatedOn "Information not found"^^xsd:string ;
    ns1:fineTunedFrom <http://mlentory.zbmed.de/mlentory_graph/35ddc796a6d136e9bf8810f1907a6a31657c5fb80bef078ab577c5edc3f59cc0> ;
    ns1:hasCO2eEmissions "Information not found."^^xsd:string ;
    ns1:intendedUse "Information not found."^^xsd:string ;
    ns1:mlTask <http://mlentory.zbmed.de/mlentory_graph/6925cb204ab4d5280c948ac7e23dd8f7b48d1de433cf9edc5c30a8d87ce3b317> ;
    ns1:modelCategory "The model category is not explicitly mentioned in the provided context."^^xsd:string ;
    ns1:modelRisks "Information not found."^^xsd:string ;
    ns1:sharedBy <http://mlentory.zbmed.de/mlentory_graph/f68885f104a68685936c980fdc14f386a9ccf26d5fa89b57ee217dbaf592e58a> ;
    ns1:testedOn "Information not found"^^xsd:string ;
    ns1:trainedOn "Information not found"^^xsd:string ;
    ns1:usageInstructions "Information not found."^^xsd:string ;
    ns1:validatedOn "Information not found."^^xsd:string ;
    schema:archivedAt <https://huggingface.co/Xinging/llama2-7b_sft_0.1_ratio_alpaca_gpt4_proj_by_bbh_ntrain_4096> ;
    schema:author "The author of this content is not explicitly mentioned in the provided context."^^xsd:string ;
    schema:citation "Information not found."^^xsd:string ;
    schema:conditionsOfAccess "Information not found."^^xsd:string ;
    schema:contributor "Information not found."^^xsd:string ;
    schema:copyrightHolder "Information not found."^^xsd:string ;
    schema:dateCreated "2025-02-07T15:09:13+00:00"^^xsd:dateTime ;
    schema:dateModified "2025-02-07T17:17:17+00:00"^^xsd:dateTime ;
    schema:datePublished "2025-02-07T15:09:13+00:00"^^xsd:dateTime ;
    schema:description """---
library_name: transformers
license: other
base_model: meta-llama/Llama-2-7b-hf
tags:
- llama-factory
- full
- generated_from_trainer
model-index:
- name: llama2-7b_sft_0.1_ratio_alpaca_gpt4_proj_by_bbh_ntrain_4096
  results: []
---

<!-- This model card has been generated automatically according to the information the Trainer had access to. You
should probably proofread and complete it, then remove this comment. -->

# llama2-7b_sft_0.1_ratio_alpaca_gpt4_proj_by_bbh_ntrain_4096

This model is a fine-tuned version of [meta-llama/Llama-2-7b-hf](https://huggingface.co/meta-llama/Llama-2-7b-hf) on the 0.1_ratio_alpaca_gpt4_proj_by_bbh_ntrain_4096 dataset.

## Model description

More information needed

## Intended uses & limitations

More information needed

## Training and evaluation data

More information needed

## Training procedure

### Training hyperparameters

The following hyperparameters were used during training:
- learning_rate: 2e-05
- train_batch_size: 32
- eval_batch_size: 8
- seed: 42
- distributed_type: multi-GPU
- num_devices: 4
- total_train_batch_size: 128
- total_eval_batch_size: 32
- optimizer: Use adamw_torch with betas=(0.9,0.999) and epsilon=1e-08 and optimizer_args=No additional optimizer arguments
- lr_scheduler_type: cosine
- lr_scheduler_warmup_ratio: 0.03
- num_epochs: 3.0

### Training results



### Framework versions

- Transformers 4.46.1
- Pytorch 2.4.0+cu121
- Datasets 2.20.0
- Tokenizers 0.20.3
"""^^xsd:string ;
    schema:discussionUrl <https://huggingface.co/Xinging/llama2-7b_sft_0.1_ratio_alpaca_gpt4_proj_by_bbh_ntrain_4096/discussions> ;
    schema:distribution "Information not found."^^xsd:string ;
    schema:funding "Information not found."^^xsd:string ;
    schema:identifier "https://huggingface.co/Xinging/llama2-7b_sft_0.1_ratio_alpaca_gpt4_proj_by_bbh_ntrain_4096"^^xsd:string ;
    schema:inLanguage "Information not found"^^xsd:string ;
    schema:keywords <http://mlentory.zbmed.de/mlentory_graph/04151ef09fe56a2be18a7d842066720d6e7cee10ed5bf1a3363193444decd94d>,
        <http://mlentory.zbmed.de/mlentory_graph/0dce0f5e7319b6178cd79d5f2163f0e134d0064f4ea4f93e8afeec1e7d78fa8d>,
        <http://mlentory.zbmed.de/mlentory_graph/1f1b91c653f20f0cf893aeb65fa83459983d2cb51e18030488be0e30b0e6db67>,
        <http://mlentory.zbmed.de/mlentory_graph/61cce84de930f0da8c78ddef3203a2afac70cf5e46684f0407180738cd821965>,
        <http://mlentory.zbmed.de/mlentory_graph/79cf083846a8329d2912fcd7f375233c37a54917af291bb945f0b58bc735b8ad>,
        <http://mlentory.zbmed.de/mlentory_graph/81c4f52fcccf6ef0d25453aedb7cebe30c7034e3b2fa752246d0e43da889a0e1>,
        <http://mlentory.zbmed.de/mlentory_graph/87b927fef88a46248b3b208472aec7bfeb38667386b309f46772e26b40f6affb>,
        <http://mlentory.zbmed.de/mlentory_graph/974df5e3234c3601080dac4fa96eebf5d19d40df41e9e30cb61084d9fbefea1e>,
        <http://mlentory.zbmed.de/mlentory_graph/97a327fc7cf14c750f068bdf3aab8cf61c95e2b04079bd1772d37c385f2b1088>,
        <http://mlentory.zbmed.de/mlentory_graph/b751528b59fc7a0677c52c99b85d41f69866dad58deffdbf1e33a510f27bc2f5>,
        <http://mlentory.zbmed.de/mlentory_graph/df4982af808ead1a57663cc7a83e60059f6a6ae1baf83a270fdf8bdfef11a3de>,
        <http://mlentory.zbmed.de/mlentory_graph/f59cf55f3a86acf0bcfc020eac552a72c13f1212154211a7bf30504548661f8d>,
        "base_model:finetune:meta-llama/Llama-2-7b-hf"^^xsd:string,
        "base_model:meta-llama/Llama-2-7b-hf"^^xsd:string,
        "license:other"^^xsd:string,
        "region:us"^^xsd:string ;
    schema:license "other"^^xsd:string ;
    schema:maintainer "Information not found."^^xsd:string ;
    schema:memoryRequirements "Not available"^^xsd:string ;
    schema:name "llama2-7b_sft_0.1_ratio_alpaca_gpt4_proj_by_bbh_ntrain_4096"^^xsd:string ;
    schema:operatingSystem "Information not found."^^xsd:string ;
    schema:processorRequirements "Information not found."^^xsd:string ;
    schema:releaseNotes """---
library_name: transformers
license: other
base_model: meta-llama/Llama-2-7b-hf
tags:
- llama-factory
- full
- generated_from_trainer
model-index:
- name: llama2-7b_sft_0.1_ratio_alpaca_gpt4_proj_by_bbh_ntrain_4096
  results: []
---

<!-- This model card has been generated automatically according to the information the Trainer had access to. You
should probably proofread and complete it, then remove this comment. -->

# llama2-7b_sft_0.1_ratio_alpaca_gpt4_proj_by_bbh_ntrain_4096

This model is a fine-tuned version of [meta-llama/Llama-2-7b-hf](https://huggingface.co/meta-llama/Llama-2-7b-hf) on the 0.1_ratio_alpaca_gpt4_proj_by_bbh_ntrain_4096 dataset.

## Model description

More information needed

## Intended uses & limitations

More information needed

## Training and evaluation data

More information needed

## Training procedure

### Training hyperparameters

The following hyperparameters were used during training:
- learning_rate: 2e-05
- train_batch_size: 32
- eval_batch_size: 8
- seed: 42
- distributed_type: multi-GPU
- num_devices: 4
- total_train_batch_size: 128
- total_eval_batch_size: 32
- optimizer: Use adamw_torch with betas=(0.9,0.999) and epsilon=1e-08 and optimizer_args=No additional optimizer arguments
- lr_scheduler_type: cosine
- lr_scheduler_warmup_ratio: 0.03
- num_epochs: 3.0

### Training results



### Framework versions

- Transformers 4.46.1
- Pytorch 2.4.0+cu121
- Datasets 2.20.0
- Tokenizers 0.20.3
"""^^xsd:string ;
    schema:softwareHelp "Information not found."^^xsd:string ;
    schema:softwareRequirements """The software requirements for the model are as follows:

- Transformers 4.46.1
- Pytorch 2.4.0+cu121
- Datasets 2.20.0
- Tokenizers 0.20.3

These are the required software dependencies for the model."""^^xsd:string ;
    schema:storageRequirements "Information not found."^^xsd:string ;
    schema:url <https://huggingface.co/Xinging/llama2-7b_sft_0.1_ratio_alpaca_gpt4_proj_by_bbh_ntrain_4096> ;
    schema:version "The version of the CreativeWork embodied by a specified resource is not found in the provided context."^^xsd:string ;
    ns3:buildInstructions "Information not found."^^xsd:string ;
    ns3:developmentStatus "Information not found."^^xsd:string ;
    ns3:issueTracker <https://huggingface.co/Xinging/llama2-7b_sft_0.1_ratio_alpaca_gpt4_proj_by_bbh_ntrain_4096/discussions> ;
    ns3:readme <https://huggingface.co/Xinging/llama2-7b_sft_0.1_ratio_alpaca_gpt4_proj_by_bbh_ntrain_4096/blob/main/README.md> ;
    ns3:referencePublication "Information not found"^^xsd:string .

<http://mlentory.zbmed.de/mlentory_graph/e2cb5f7dba65387f6ecd56e7a642d33df8fca1197b2ac918cd629a6cd9b294b2> a schema:DefinedTerm ;
    schema:description "Framework for computing dense vector representations of sentences and paragraphs using transformer models."^^xsd:string ;
    schema:name "sentence-transformers"^^xsd:string .

<http://mlentory.zbmed.de/mlentory_graph/ebbad1761fb8870fe41c968d83d4055b2799265db268338f3fa38c3849f7932a> a schema:DefinedTerm ;
    schema:description "Comprehensive deep learning platform developed by Baidu, supporting industrial applications."^^xsd:string ;
    schema:name "PaddlePaddle"^^xsd:string .

<http://mlentory.zbmed.de/mlentory_graph/ee41d767ffa75d0037ac340fa59164645b363ea8891e2a3f815c644b81ea9fbd> a schema:DefinedTerm ;
    schema:description "Python implementation of state-of-the-art variational autoencoders for generative modeling."^^xsd:string ;
    schema:name "pythae"^^xsd:string .

<http://mlentory.zbmed.de/mlentory_graph/ef8c453c903ecc79a3f941fc76e3fb554c3c0e3459f4a7a1755e64539b934598> a schema:DefinedTerm ;
    schema:description "Library for parameter-efficient transfer learning through adapter modules in transformer models."^^xsd:string ;
    schema:name "Adapters"^^xsd:string .

<http://mlentory.zbmed.de/mlentory_graph/f38a4d1014d3cc9f5709e2ecd78f5809ca2397dd49ed420aa2e4a0ab4210a289> a schema:DefinedTerm ;
    schema:description "End-to-end open source platform for ML with comprehensive tools and libraries for building and deploying models at scale."^^xsd:string ;
    schema:name "TensorFlow"^^xsd:string .

<http://mlentory.zbmed.de/mlentory_graph/f398a6ed462d305d58506b378a7b488c448115a8aef746a62331a8435d54a72b> a schema:DefinedTerm ;
    schema:description "Open-source NLP research library built on PyTorch for developing state-of-the-art models."^^xsd:string ;
    schema:name "AllenNLP"^^xsd:string .

<http://mlentory.zbmed.de/mlentory_graph/f4f5c02149ef4c63e1abfb237a7efd73b36b96243fa20ee9a3b83ab914689b18> a schema:DefinedTerm ;
    schema:description "Assigns each pixel in an image to a specific class or object."^^xsd:string ;
    schema:name "Image Segmentation"^^xsd:string .

<http://mlentory.zbmed.de/mlentory_graph/f83566aa690a65900e25f19b29d427ae3a9b752766d6d3892299a866feca3edd> a schema:DefinedTerm ;
    schema:description "Parameter-Efficient Fine-Tuning methods that enable efficient adaptation of pre-trained language models."^^xsd:string ;
    schema:name "PEFT"^^xsd:string .

<http://mlentory.zbmed.de/mlentory_graph/fd4e2f28de7e36539eda0f2e74a9e9b30f10d77fee3b927dc3aa5419c43369da> a schema:DefinedTerm ;
    schema:description "Converts 2D images into 3D representations or models."^^xsd:string ;
    schema:name "Image to 3D"^^xsd:string .

<http://mlentory.zbmed.de/mlentory_graph/ff7e16d40feb7d4c633834d7dbc7d52497c682b7bfaf2c103d82af436916cd86> a ns1:ML_Model ;
    ns1:ethicalLegalSocial "Information not found."^^xsd:string ;
    ns1:evaluatedOn <http://mlentory.zbmed.de/mlentory_graph/63c4690edf3557f17b07f48296b33ccc383956a845d01233d59d9e359bf38c99> ;
    ns1:fineTunedFrom <http://mlentory.zbmed.de/mlentory_graph/01ce031a92b6a44f90635a9aa473acc02c379a53ef7b0a0d8f88b6027a9ad64e> ;
    ns1:hasCO2eEmissions "Information not found."^^xsd:string ;
    ns1:intendedUse "The intended use of jinkrsmodel is not specified in the given context."^^xsd:string ;
    ns1:mlTask <http://mlentory.zbmed.de/mlentory_graph/db86f2c8ce693db878b689231690fab2fe37b7ae1abc1e54dca9fae35bc0df0d> ;
    ns1:modelCategory "Information not found."^^xsd:string ;
    ns1:modelRisks "Information not found."^^xsd:string ;
    ns1:sharedBy <http://mlentory.zbmed.de/mlentory_graph/8c29861cff92b34ba1887aa267cf20a6a2124ec092919b27c388fb31ecb5f269> ;
    ns1:testedOn <http://mlentory.zbmed.de/mlentory_graph/63c4690edf3557f17b07f48296b33ccc383956a845d01233d59d9e359bf38c99> ;
    ns1:trainedOn <http://mlentory.zbmed.de/mlentory_graph/63c4690edf3557f17b07f48296b33ccc383956a845d01233d59d9e359bf38c99> ;
    ns1:usageInstructions "Information not found."^^xsd:string ;
    ns1:validatedOn "Information not found."^^xsd:string ;
    schema:archivedAt <https://huggingface.co/DianaJin/sample> ;
    schema:author "The author of this content is not mentioned in the provided context."^^xsd:string ;
    schema:citation "Information not found."^^xsd:string ;
    schema:conditionsOfAccess "Information not found."^^xsd:string ;
    schema:contributor "Information not found."^^xsd:string ;
    schema:copyrightHolder "Information not found."^^xsd:string ;
    schema:dateCreated "2023-11-30T05:06:05+00:00"^^xsd:dateTime ;
    schema:dateModified "2023-11-30T05:32:06+00:00"^^xsd:dateTime ;
    schema:datePublished "2023-11-30T05:06:05+00:00"^^xsd:dateTime ;
    schema:description """---
language:
- ko
license: apache-2.0
base_model: openai/whisper-base
tags:
- hf-asr-leaderboard
- generated_from_trainer
datasets:
- DianaJin/sample
model-index:
- name: jinkrsmodel
  results: []
---

<!-- This model card has been generated automatically according to the information the Trainer had access to. You
should probably proofread and complete it, then remove this comment. -->

# jinkrsmodel

This model is a fine-tuned version of [openai/whisper-base](https://huggingface.co/openai/whisper-base) on the DianaJin/voice dataset.
It achieves the following results on the evaluation set:
- Loss: 1.2017
- Cer: 134.5133

## Model description

More information needed

## Intended uses & limitations

More information needed

## Training and evaluation data

More information needed

## Training procedure

### Training hyperparameters

The following hyperparameters were used during training:
- learning_rate: 1e-05
- train_batch_size: 16
- eval_batch_size: 8
- seed: 42
- optimizer: Adam with betas=(0.9,0.999) and epsilon=1e-08
- lr_scheduler_type: linear
- lr_scheduler_warmup_steps: 5
- training_steps: 40
- mixed_precision_training: Native AMP

### Training results

| Training Loss | Epoch | Step | Validation Loss | Cer      |
|:-------------:|:-----:|:----:|:---------------:|:--------:|
| No log        | 3.33  | 10   | 2.1701          | 13.2743  |
| No log        | 6.67  | 20   | 1.3824          | 55.3097  |
| 1.7663        | 10.0  | 30   | 1.2305          | 164.1593 |
| 1.7663        | 13.33 | 40   | 1.2017          | 134.5133 |


### Framework versions

- Transformers 4.36.0.dev0
- Pytorch 2.1.0+cu118
- Datasets 2.15.0
- Tokenizers 0.15.0
"""^^xsd:string ;
    schema:discussionUrl <https://huggingface.co/DianaJin/sample/discussions> ;
    schema:distribution "Information not found."^^xsd:string ;
    schema:funding "Information not found."^^xsd:string ;
    schema:identifier "https://huggingface.co/DianaJin/sample"^^xsd:string ;
    schema:inLanguage "ko"^^xsd:string ;
    schema:keywords <http://mlentory.zbmed.de/mlentory_graph/04151ef09fe56a2be18a7d842066720d6e7cee10ed5bf1a3363193444decd94d>,
        <http://mlentory.zbmed.de/mlentory_graph/07456871ec04ff7e102a14a63ee4f77775baadaf5e404b74e2ab827a14335259>,
        <http://mlentory.zbmed.de/mlentory_graph/0dce0f5e7319b6178cd79d5f2163f0e134d0064f4ea4f93e8afeec1e7d78fa8d>,
        <http://mlentory.zbmed.de/mlentory_graph/87b927fef88a46248b3b208472aec7bfeb38667386b309f46772e26b40f6affb>,
        <http://mlentory.zbmed.de/mlentory_graph/8e9892e571845c79509180a69a268f19c0592a4e975a5fd3e16f2059af61ea75>,
        <http://mlentory.zbmed.de/mlentory_graph/974df5e3234c3601080dac4fa96eebf5d19d40df41e9e30cb61084d9fbefea1e>,
        <http://mlentory.zbmed.de/mlentory_graph/a7eca72cd0a3a0ce30e3b37b299034e8cf2e3b921a7deaf54545b7d00e88c5e4>,
        <http://mlentory.zbmed.de/mlentory_graph/df4982af808ead1a57663cc7a83e60059f6a6ae1baf83a270fdf8bdfef11a3de>,
        "base_model:finetune:openai/whisper-base"^^xsd:string,
        "base_model:openai/whisper-base"^^xsd:string,
        "dataset:DianaJin/sample"^^xsd:string,
        "ko"^^xsd:string,
        "license:apache-2.0"^^xsd:string,
        "region:us"^^xsd:string ;
    schema:license "apache-2.0"^^xsd:string ;
    schema:maintainer "Information not found."^^xsd:string ;
    schema:memoryRequirements "Not available"^^xsd:string ;
    schema:name "sample"^^xsd:string ;
    schema:operatingSystem "The operating systems supported by jinkrsmodel are Windows 7, OSX 10.6, and Android 1.6."^^xsd:string ;
    schema:processorRequirements "Information not found."^^xsd:string ;
    schema:releaseNotes """---
language:
- ko
license: apache-2.0
base_model: openai/whisper-base
tags:
- hf-asr-leaderboard
- generated_from_trainer
datasets:
- DianaJin/sample
model-index:
- name: jinkrsmodel
  results: []
---

<!-- This model card has been generated automatically according to the information the Trainer had access to. You
should probably proofread and complete it, then remove this comment. -->

# jinkrsmodel

This model is a fine-tuned version of [openai/whisper-base](https://huggingface.co/openai/whisper-base) on the DianaJin/voice dataset.
It achieves the following results on the evaluation set:
- Loss: 1.2017
- Cer: 134.5133

## Model description

More information needed

## Intended uses & limitations

More information needed

## Training and evaluation data

More information needed

## Training procedure

### Training hyperparameters

The following hyperparameters were used during training:
- learning_rate: 1e-05
- train_batch_size: 16
- eval_batch_size: 8
- seed: 42
- optimizer: Adam with betas=(0.9,0.999) and epsilon=1e-08
- lr_scheduler_type: linear
- lr_scheduler_warmup_steps: 5
- training_steps: 40
- mixed_precision_training: Native AMP

### Training results

| Training Loss | Epoch | Step | Validation Loss | Cer      |
|:-------------:|:-----:|:----:|:---------------:|:--------:|
| No log        | 3.33  | 10   | 2.1701          | 13.2743  |
| No log        | 6.67  | 20   | 1.3824          | 55.3097  |
| 1.7663        | 10.0  | 30   | 1.2305          | 164.1593 |
| 1.7663        | 13.33 | 40   | 1.2017          | 134.5133 |


### Framework versions

- Transformers 4.36.0.dev0
- Pytorch 2.1.0+cu118
- Datasets 2.15.0
- Tokenizers 0.15.0
"""^^xsd:string ;
    schema:softwareHelp "Information not found."^^xsd:string ;
    schema:softwareRequirements "Information not found."^^xsd:string ;
    schema:storageRequirements "Information not found."^^xsd:string ;
    schema:url <https://huggingface.co/DianaJin/sample> ;
    schema:version "Information not found."^^xsd:string ;
    ns3:buildInstructions "Information not found."^^xsd:string ;
    ns3:developmentStatus "Information not found."^^xsd:string ;
    ns3:issueTracker <https://huggingface.co/DianaJin/sample/discussions> ;
    ns3:readme <https://huggingface.co/DianaJin/sample/blob/main/README.md> ;
    ns3:referencePublication "Information not found"^^xsd:string .

<http://mlentory.zbmed.de/mlentory_graph/main> a ns2:RecordSet ;
    ns2:field <http://mlentory.zbmed.de/mlentory_graph/main/answer>,
        <http://mlentory.zbmed.de/mlentory_graph/main/question>,
        <http://mlentory.zbmed.de/mlentory_graph/main/split> ;
    schema:description """openai/gsm8k - 'main' subset

Additional information:
- 2 splits: train, test"""@en ;
    schema:name "main"@en .

<http://mlentory.zbmed.de/mlentory_graph/main_splits> a ns2:RecordSet ;
    ns2:data "[{\"main_splits/split_name\":\"train\"},{\"main_splits/split_name\":\"test\"}]"^^rdf:JSON ;
    ns2:dataType ns2:Split ;
    ns2:field <http://mlentory.zbmed.de/mlentory_graph/main_splits/split_name> ;
    ns2:key <http://mlentory.zbmed.de/mlentory_graph/main_splits/split_name> ;
    schema:description "Splits for the main config."@en ;
    schema:name "main_splits"@en .

<http://mlentory.zbmed.de/mlentory_graph/plain_text> a ns2:RecordSet ;
    ns2:field <http://mlentory.zbmed.de/mlentory_graph/plain_text/domain>,
        <http://mlentory.zbmed.de/mlentory_graph/plain_text/split>,
        <http://mlentory.zbmed.de/mlentory_graph/plain_text/text> ;
    schema:description """cimec/lambada - 'plain_text' subset

Additional information:
- 3 splits: train, test, validation"""@en ;
    schema:name "plain_text"@en .

<http://mlentory.zbmed.de/mlentory_graph/plain_text_splits> a ns2:RecordSet ;
    ns2:data "[{\"plain_text_splits/split_name\":\"train\"},{\"plain_text_splits/split_name\":\"test\"},{\"plain_text_splits/split_name\":\"validation\"}]"^^rdf:JSON ;
    ns2:dataType ns2:Split ;
    ns2:field <http://mlentory.zbmed.de/mlentory_graph/plain_text_splits/split_name> ;
    ns2:key <http://mlentory.zbmed.de/mlentory_graph/plain_text_splits/split_name> ;
    schema:description "Splits for the plain_text config."@en ;
    schema:name "plain_text_splits"@en .

<http://mlentory.zbmed.de/mlentory_graph/raw> a ns2:RecordSet ;
    ns2:field <http://mlentory.zbmed.de/mlentory_graph/raw/correct>,
        <http://mlentory.zbmed.de/mlentory_graph/raw/options>,
        <http://mlentory.zbmed.de/mlentory_graph/raw/question>,
        <http://mlentory.zbmed.de/mlentory_graph/raw/rationale>,
        <http://mlentory.zbmed.de/mlentory_graph/raw/split> ;
    schema:description """deepmind/aqua_rat - 'raw' subset

Additional information:
- 3 splits: train, test, validation"""@en ;
    schema:name "raw"@en .

<http://mlentory.zbmed.de/mlentory_graph/raw_splits> a ns2:RecordSet ;
    ns2:data "[{\"raw_splits/split_name\":\"train\"},{\"raw_splits/split_name\":\"test\"},{\"raw_splits/split_name\":\"validation\"}]"^^rdf:JSON ;
    ns2:dataType ns2:Split ;
    ns2:field <http://mlentory.zbmed.de/mlentory_graph/raw_splits/split_name> ;
    ns2:key <http://mlentory.zbmed.de/mlentory_graph/raw_splits/split_name> ;
    schema:description "Splits for the raw config."@en ;
    schema:name "raw_splits"@en .

<http://mlentory.zbmed.de/mlentory_graph/socratic> a ns2:RecordSet ;
    ns2:field <http://mlentory.zbmed.de/mlentory_graph/socratic/answer>,
        <http://mlentory.zbmed.de/mlentory_graph/socratic/question>,
        <http://mlentory.zbmed.de/mlentory_graph/socratic/split> ;
    schema:description """openai/gsm8k - 'socratic' subset

Additional information:
- 2 splits: train, test"""@en ;
    schema:name "socratic"@en .

<http://mlentory.zbmed.de/mlentory_graph/socratic_splits> a ns2:RecordSet ;
    ns2:data "[{\"socratic_splits/split_name\":\"train\"},{\"socratic_splits/split_name\":\"test\"}]"^^rdf:JSON ;
    ns2:dataType ns2:Split ;
    ns2:field <http://mlentory.zbmed.de/mlentory_graph/socratic_splits/split_name> ;
    ns2:key <http://mlentory.zbmed.de/mlentory_graph/socratic_splits/split_name> ;
    schema:description "Splits for the socratic config."@en ;
    schema:name "socratic_splits"@en .

<http://mlentory.zbmed.de/mlentory_graph/tokenized> a ns2:RecordSet ;
    ns2:field <http://mlentory.zbmed.de/mlentory_graph/tokenized/correct>,
        <http://mlentory.zbmed.de/mlentory_graph/tokenized/options>,
        <http://mlentory.zbmed.de/mlentory_graph/tokenized/question>,
        <http://mlentory.zbmed.de/mlentory_graph/tokenized/rationale>,
        <http://mlentory.zbmed.de/mlentory_graph/tokenized/split> ;
    schema:description """deepmind/aqua_rat - 'tokenized' subset

Additional information:
- 3 splits: train, test, validation"""@en ;
    schema:name "tokenized"@en .

<http://mlentory.zbmed.de/mlentory_graph/tokenized_splits> a ns2:RecordSet ;
    ns2:data "[{\"tokenized_splits/split_name\":\"train\"},{\"tokenized_splits/split_name\":\"test\"},{\"tokenized_splits/split_name\":\"validation\"}]"^^rdf:JSON ;
    ns2:dataType ns2:Split ;
    ns2:field <http://mlentory.zbmed.de/mlentory_graph/tokenized_splits/split_name> ;
    ns2:key <http://mlentory.zbmed.de/mlentory_graph/tokenized_splits/split_name> ;
    schema:description "Splits for the tokenized config."@en ;
    schema:name "tokenized_splits"@en .

<http://mlentory.zbmed.de/mlentory_graph/01ce031a92b6a44f90635a9aa473acc02c379a53ef7b0a0d8f88b6027a9ad64e> a ns1:MLModel ;
    schema:name "openai/whisper-base"^^xsd:string ;
    schema:url <https://huggingface.co/openai/whisper-base> .

<http://mlentory.zbmed.de/mlentory_graph/09f6dc26b905f28e537bf583c1483f6a6629d85e5d00dc7b22aab54f60cdd7b3> a schema:ScholarlyArticle ;
    schema:abstract """Finetuning language models on a collection of datasets phrased as
instructions has been shown to improve model performance and generalization to
unseen tasks. In this paper we explore instruction finetuning with a particular
focus on (1) scaling the number of tasks, (2) scaling the model size, and (3)
finetuning on chain-of-thought data. We find that instruction finetuning with
the above aspects dramatically improves performance on a variety of model
classes (PaLM, T5, U-PaLM), prompting setups (zero-shot, few-shot, CoT), and
evaluation benchmarks (MMLU, BBH, TyDiQA, MGSM, open-ended generation). For
instance, Flan-PaLM 540B instruction-finetuned on 1.8K tasks outperforms PALM
540B by a large margin (+9.4% on average). Flan-PaLM 540B achieves
state-of-the-art performance on several benchmarks, such as 75.2% on five-shot
MMLU. We also publicly release Flan-T5 checkpoints, which achieve strong
few-shot performance even compared to much larger models, such as PaLM 62B.
Overall, instruction finetuning is a general method for improving the
performance and usability of pretrained language models."""^^xsd:string ;
    schema:author "{'name': 'Aakanksha Chowdhery', 'affiliation': None}"^^xsd:string,
        "{'name': 'Adam Roberts', 'affiliation': None}"^^xsd:string,
        "{'name': 'Adams Yu', 'affiliation': None}"^^xsd:string,
        "{'name': 'Albert Webson', 'affiliation': None}"^^xsd:string,
        "{'name': 'Alex Castro-Ros', 'affiliation': None}"^^xsd:string,
        "{'name': 'Andrew Dai', 'affiliation': None}"^^xsd:string,
        "{'name': 'Barret Zoph', 'affiliation': None}"^^xsd:string,
        "{'name': 'Dasha Valter', 'affiliation': None}"^^xsd:string,
        "{'name': 'Denny Zhou', 'affiliation': None}"^^xsd:string,
        "{'name': 'Ed H. Chi', 'affiliation': None}"^^xsd:string,
        "{'name': 'Gaurav Mishra', 'affiliation': None}"^^xsd:string,
        "{'name': 'Hongkun Yu', 'affiliation': None}"^^xsd:string,
        "{'name': 'Hyung Won Chung', 'affiliation': None}"^^xsd:string,
        "{'name': 'Jacob Devlin', 'affiliation': None}"^^xsd:string,
        "{'name': 'Jason Wei', 'affiliation': None}"^^xsd:string,
        "{'name': 'Jeff Dean', 'affiliation': None}"^^xsd:string,
        "{'name': 'Kevin Robinson', 'affiliation': None}"^^xsd:string,
        "{'name': 'Le Hou', 'affiliation': None}"^^xsd:string,
        "{'name': 'Marie Pellat', 'affiliation': None}"^^xsd:string,
        "{'name': 'Mirac Suzgun', 'affiliation': None}"^^xsd:string,
        "{'name': 'Mostafa Dehghani', 'affiliation': None}"^^xsd:string,
        "{'name': 'Quoc V. Le', 'affiliation': None}"^^xsd:string,
        "{'name': 'Sharan Narang', 'affiliation': None}"^^xsd:string,
        "{'name': 'Shayne Longpre', 'affiliation': None}"^^xsd:string,
        "{'name': 'Shixiang Shane Gu', 'affiliation': None}"^^xsd:string,
        "{'name': 'Siddhartha Brahma', 'affiliation': None}"^^xsd:string,
        "{'name': 'Slav Petrov', 'affiliation': None}"^^xsd:string,
        "{'name': 'Vincent Zhao', 'affiliation': None}"^^xsd:string,
        "{'name': 'William Fedus', 'affiliation': None}"^^xsd:string,
        "{'name': 'Xinyun Chen', 'affiliation': None}"^^xsd:string,
        "{'name': 'Xuezhi Wang', 'affiliation': None}"^^xsd:string,
        "{'name': 'Yanping Huang', 'affiliation': None}"^^xsd:string,
        "{'name': 'Yi Tay', 'affiliation': None}"^^xsd:string,
        "{'name': 'Yunxuan Li', 'affiliation': None}"^^xsd:string,
        "{'name': 'Zhuyun Dai', 'affiliation': None}"^^xsd:string ;
    schema:datePublished "2022-10-20"^^xsd:date ;
    schema:keywords "cs.CL"^^xsd:string,
        "cs.LG"^^xsd:string ;
    schema:name "Scaling Instruction-Finetuned Language Models"^^xsd:string ;
    schema:url "https://arxiv.org/abs/2210.11416"^^xsd:anyURI,
        "https://arxiv.org/abs/2210.11416"^^xsd:string .

<http://mlentory.zbmed.de/mlentory_graph/11ee21b926795a2b7d2cb2d939044519ace34ac86e6b6a59a47dcb4bba5eb7a4> a schema:DefinedTerm ;
    schema:name "facebook"^^xsd:string .

<http://mlentory.zbmed.de/mlentory_graph/125d01550d26a191f055cd53b0b7bf0298ef4a173496f10aa09a87ca1b3fdcbe> a schema:Person ;
    schema:name "google"^^xsd:string ;
    schema:url "https://huggingface.co/google"^^xsd:anyURI .

<http://mlentory.zbmed.de/mlentory_graph/1aa60aa9719223ac8750af1366d4a56166214022d0d069d1412225070d1275b9> a schema:DefinedTerm ;
    schema:name "multilingual"^^xsd:string .

<http://mlentory.zbmed.de/mlentory_graph/1fb09733dc3261eb13aa123f1d418af5be3d14c3a0d5b123fb23f1b9f5234a31> a schema:ScholarlyArticle ;
    schema:abstract """We introduce Mistral 7B v0.1, a 7-billion-parameter language model engineered
for superior performance and efficiency. Mistral 7B outperforms Llama 2 13B
across all evaluated benchmarks, and Llama 1 34B in reasoning, mathematics, and
code generation. Our model leverages grouped-query attention (GQA) for faster
inference, coupled with sliding window attention (SWA) to effectively handle
sequences of arbitrary length with a reduced inference cost. We also provide a
model fine-tuned to follow instructions, Mistral 7B -- Instruct, that surpasses
the Llama 2 13B -- Chat model both on human and automated benchmarks. Our
models are released under the Apache 2.0 license."""^^xsd:string ;
    schema:author "{'name': 'Albert Q. Jiang', 'affiliation': None}"^^xsd:string,
        "{'name': 'Alexandre Sablayrolles', 'affiliation': None}"^^xsd:string,
        "{'name': 'Arthur Mensch', 'affiliation': None}"^^xsd:string,
        "{'name': 'Chris Bamford', 'affiliation': None}"^^xsd:string,
        "{'name': 'Devendra Singh Chaplot', 'affiliation': None}"^^xsd:string,
        "{'name': 'Diego de las Casas', 'affiliation': None}"^^xsd:string,
        "{'name': 'Florian Bressand', 'affiliation': None}"^^xsd:string,
        "{'name': 'Gianna Lengyel', 'affiliation': None}"^^xsd:string,
        "{'name': 'Guillaume Lample', 'affiliation': None}"^^xsd:string,
        "{'name': 'Lucile Saulnier', 'affiliation': None}"^^xsd:string,
        "{'name': 'Lélio Renard Lavaud', 'affiliation': None}"^^xsd:string,
        "{'name': 'Marie-Anne Lachaux', 'affiliation': None}"^^xsd:string,
        "{'name': 'Pierre Stock', 'affiliation': None}"^^xsd:string,
        "{'name': 'Teven Le Scao', 'affiliation': None}"^^xsd:string,
        "{'name': 'Thibaut Lavril', 'affiliation': None}"^^xsd:string,
        "{'name': 'Thomas Wang', 'affiliation': None}"^^xsd:string,
        "{'name': 'Timothée Lacroix', 'affiliation': None}"^^xsd:string,
        "{'name': 'William El Sayed', 'affiliation': None}"^^xsd:string ;
    schema:datePublished "2023-10-10"^^xsd:date ;
    schema:keywords "cs.AI"^^xsd:string,
        "cs.CL"^^xsd:string,
        "cs.LG"^^xsd:string ;
    schema:name "Mistral 7B"^^xsd:string ;
    schema:url "https://arxiv.org/abs/2310.06825"^^xsd:anyURI,
        "https://arxiv.org/abs/2310.06825"^^xsd:string .

<http://mlentory.zbmed.de/mlentory_graph/24d02c4c9af718667adb32f98890ccae3daa567e09e890fbcc6baa38ee130dd0> a schema:ScholarlyArticle ;
    schema:abstract """From an environmental standpoint, there are a few crucial aspects of training
a neural network that have a major impact on the quantity of carbon that it
emits. These factors include: the location of the server used for training and
the energy grid that it uses, the length of the training procedure, and even
the make and model of hardware on which the training takes place. In order to
approximate these emissions, we present our Machine Learning Emissions
Calculator, a tool for our community to better understand the environmental
impact of training ML models. We accompany this tool with an explanation of the
factors cited above, as well as concrete actions that individual practitioners
and organizations can take to mitigate their carbon emissions."""^^xsd:string ;
    schema:author "{'name': 'Alexandra Luccioni', 'affiliation': None}"^^xsd:string,
        "{'name': 'Alexandre Lacoste', 'affiliation': None}"^^xsd:string,
        "{'name': 'Thomas Dandres', 'affiliation': None}"^^xsd:string,
        "{'name': 'Victor Schmidt', 'affiliation': None}"^^xsd:string ;
    schema:datePublished "2019-10-21"^^xsd:date ;
    schema:keywords "cs.CY"^^xsd:string,
        "cs.LG"^^xsd:string ;
    schema:name "Quantifying the Carbon Emissions of Machine Learning"^^xsd:string ;
    schema:url "https://arxiv.org/abs/1910.09700"^^xsd:anyURI,
        "https://arxiv.org/abs/1910.09700"^^xsd:string .

<http://mlentory.zbmed.de/mlentory_graph/32934a13e4d01c327dbef8b4279d190d77f3095d7022f9465dc377bbb3565c94> a schema:DefinedTerm ;
    schema:name "llama-2"^^xsd:string .

<http://mlentory.zbmed.de/mlentory_graph/35ddc796a6d136e9bf8810f1907a6a31657c5fb80bef078ab577c5edc3f59cc0> a ns1:MLModel ;
    schema:name "meta-llama/Llama-2-7b-hf"^^xsd:string ;
    schema:url <https://huggingface.co/meta-llama/Llama-2-7b-hf> .

<http://mlentory.zbmed.de/mlentory_graph/660591e88f00e321049a76543ded76af3005cf92f0a834054184e0177278716c> a schema:DefinedTerm ;
    schema:description "Generates images from textual descriptions or prompts."^^xsd:string ;
    schema:name "Text to Image"^^xsd:string,
        "text to image"^^xsd:string .

<http://mlentory.zbmed.de/mlentory_graph/759dcfce11b186065b46fb94fef1c569da9001c123861ba72ba0708e554bd6c4> a schema:DefinedTerm ;
    schema:name "meta"^^xsd:string .

<http://mlentory.zbmed.de/mlentory_graph/8c29861cff92b34ba1887aa267cf20a6a2124ec092919b27c388fb31ecb5f269> a schema:Person ;
    schema:name "DianaJin"^^xsd:string ;
    schema:url "https://huggingface.co/DianaJin"^^xsd:anyURI .

<http://mlentory.zbmed.de/mlentory_graph/907291d3b7300a7e84345915ff883a4d8615166ada0751e1be974994397ea77a> a schema:Person ;
    schema:name "CyberHarem"^^xsd:string ;
    schema:url "https://huggingface.co/CyberHarem"^^xsd:anyURI .

<http://mlentory.zbmed.de/mlentory_graph/97a327fc7cf14c750f068bdf3aab8cf61c95e2b04079bd1772d37c385f2b1088> a schema:DefinedTerm ;
    schema:name "llama-factory"^^xsd:string .

<http://mlentory.zbmed.de/mlentory_graph/9abc397b7489422e962aeae20a5ed774806c8bd8f47e9008eef451699b8a61c1> a schema:DefinedTerm ;
    schema:description "Transforms input text into a different textual form."^^xsd:string ;
    schema:name "Text2Text Generation"^^xsd:string,
        "text2text generation"^^xsd:string .

<http://mlentory.zbmed.de/mlentory_graph/9c03090b68b1e45d6bebe9b9d1ea103b6a4c064ceb71f16f08a5ae59d9bac70e> a schema:Person ;
    schema:name "meta-llama"^^xsd:string ;
    schema:url "https://huggingface.co/meta-llama"^^xsd:anyURI .

<http://mlentory.zbmed.de/mlentory_graph/b751528b59fc7a0677c52c99b85d41f69866dad58deffdbf1e33a510f27bc2f5> a schema:DefinedTerm ;
    schema:name "full"^^xsd:string .

<http://mlentory.zbmed.de/mlentory_graph/ba386c19594b5e2c45538f0ad668a14203edcbe442437836169ed56795dd7abb> a schema:DefinedTerm ;
    schema:name "art"^^xsd:string .

<http://mlentory.zbmed.de/mlentory_graph/d24e90f006bf4dfce8be9dbaf9c92d1449f40b988b6cc52d60e48c40331dc607> a schema:DefinedTerm ;
    schema:name "finetuned"^^xsd:string .

<http://mlentory.zbmed.de/mlentory_graph/dabb9d310d39a47f81f009cd476a41773667de14be41c930213432a06ad59fb0> a schema:DefinedTerm ;
    schema:name "haw"^^xsd:string .

<http://mlentory.zbmed.de/mlentory_graph/ddb15bfa0ef843723bc4c8a81ab1d826b1fc4ff36ed13faf8f8f3841261978b8> a schema:DefinedTerm ;
    schema:description "Models created by Mistral, a French artificial intelligence startup, headquartered in Paris. It specializes in open-weight large language models."^^xsd:string ;
    schema:name "mistral"^^xsd:string .

<http://mlentory.zbmed.de/mlentory_graph/default/cf_contest_id> a ns2:Field ;
    ns2:dataType schema:Integer ;
    schema:description "Column 'cf_contest_id' from the Hugging Face parquet file."@en ;
    schema:name "default/cf_contest_id"@en .

<http://mlentory.zbmed.de/mlentory_graph/default/cf_index> a ns2:Field ;
    ns2:dataType schema:Text ;
    schema:description "Column 'cf_index' from the Hugging Face parquet file."@en ;
    schema:name "default/cf_index"@en .

<http://mlentory.zbmed.de/mlentory_graph/default/cf_points> a ns2:Field ;
    ns2:dataType schema:Float ;
    schema:description "Column 'cf_points' from the Hugging Face parquet file."@en ;
    schema:name "default/cf_points"@en .

<http://mlentory.zbmed.de/mlentory_graph/default/cf_rating> a ns2:Field ;
    ns2:dataType schema:Integer ;
    schema:description "Column 'cf_rating' from the Hugging Face parquet file."@en ;
    schema:name "default/cf_rating"@en .

<http://mlentory.zbmed.de/mlentory_graph/default/cf_tags> a ns2:Field ;
    ns2:dataType schema:Text ;
    ns2:repeated true ;
    schema:description "Column 'cf_tags' from the Hugging Face parquet file."@en ;
    schema:name "default/cf_tags"@en .

<http://mlentory.zbmed.de/mlentory_graph/default/description> a ns2:Field ;
    ns2:dataType schema:Text ;
    schema:description "Column 'description' from the Hugging Face parquet file."@en ;
    schema:name "default/description"@en .

<http://mlentory.zbmed.de/mlentory_graph/default/difficulty> a ns2:Field ;
    ns2:dataType schema:Integer ;
    schema:description """ClassLabel column 'difficulty' from the Hugging Face parquet file.
Labels:
UNKNOWN_DIFFICULTY (0), EASY (1), MEDIUM (2), HARD (3), HARDER (4), HARDEST (5), EXTERNAL (6), A (7), B (8), C (9), D (10), E (11), F (12), G (13), H (14), I (15), J (16), K (17), L (18), M (19), N (20), O (21), P (22), Q (23), R (24), S (25), T (26), U (27), V (28)"""@en ;
    schema:name "default/difficulty"@en .

<http://mlentory.zbmed.de/mlentory_graph/default/generated_tests> a ns2:Field ;
    ns2:repeated true ;
    ns2:subField <http://mlentory.zbmed.de/mlentory_graph/default/generated_tests/input>,
        <http://mlentory.zbmed.de/mlentory_graph/default/generated_tests/output> ;
    schema:description "Column 'generated_tests' from the Hugging Face parquet file."@en ;
    schema:name "default/generated_tests"@en .

<http://mlentory.zbmed.de/mlentory_graph/default/generated_tests/input> a ns2:Field ;
    ns2:dataType schema:Text ;
    schema:description "Column 'generated_tests' from the Hugging Face parquet file."@en ;
    schema:name "default/generated_tests/input"@en .

<http://mlentory.zbmed.de/mlentory_graph/default/generated_tests/output> a ns2:Field ;
    ns2:dataType schema:Text ;
    schema:description "Column 'generated_tests' from the Hugging Face parquet file."@en ;
    schema:name "default/generated_tests/output"@en .

<http://mlentory.zbmed.de/mlentory_graph/default/incorrect_solutions> a ns2:Field ;
    ns2:repeated true ;
    ns2:subField <http://mlentory.zbmed.de/mlentory_graph/default/incorrect_solutions/language>,
        <http://mlentory.zbmed.de/mlentory_graph/default/incorrect_solutions/solution> ;
    schema:description "Column 'incorrect_solutions' from the Hugging Face parquet file."@en ;
    schema:name "default/incorrect_solutions"@en .

<http://mlentory.zbmed.de/mlentory_graph/default/incorrect_solutions/language> a ns2:Field ;
    ns2:dataType schema:Integer ;
    schema:description """ClassLabel column 'incorrect_solutions' from the Hugging Face parquet file.
Labels:
UNKNOWN_LANGUAGE (0), PYTHON (1), CPP (2), PYTHON3 (3), JAVA (4)"""@en ;
    schema:name "default/incorrect_solutions/language"@en .

<http://mlentory.zbmed.de/mlentory_graph/default/incorrect_solutions/solution> a ns2:Field ;
    ns2:dataType schema:Text ;
    schema:description "Column 'incorrect_solutions' from the Hugging Face parquet file."@en ;
    schema:name "default/incorrect_solutions/solution"@en .

<http://mlentory.zbmed.de/mlentory_graph/default/input_file> a ns2:Field ;
    ns2:dataType schema:Text ;
    schema:description "Column 'input_file' from the Hugging Face parquet file."@en ;
    schema:name "default/input_file"@en .

<http://mlentory.zbmed.de/mlentory_graph/default/is_description_translated> a ns2:Field ;
    ns2:dataType schema:Boolean ;
    schema:description "Column 'is_description_translated' from the Hugging Face parquet file."@en ;
    schema:name "default/is_description_translated"@en .

<http://mlentory.zbmed.de/mlentory_graph/default/memory_limit_bytes> a ns2:Field ;
    ns2:dataType schema:Integer ;
    schema:description "Column 'memory_limit_bytes' from the Hugging Face parquet file."@en ;
    schema:name "default/memory_limit_bytes"@en .

<http://mlentory.zbmed.de/mlentory_graph/default/name> a ns2:Field ;
    ns2:dataType schema:Text ;
    schema:description "Column 'name' from the Hugging Face parquet file."@en ;
    schema:name "default/name"@en .

<http://mlentory.zbmed.de/mlentory_graph/default/output_file> a ns2:Field ;
    ns2:dataType schema:Text ;
    schema:description "Column 'output_file' from the Hugging Face parquet file."@en ;
    schema:name "default/output_file"@en .

<http://mlentory.zbmed.de/mlentory_graph/default/private_tests> a ns2:Field ;
    ns2:repeated true ;
    ns2:subField <http://mlentory.zbmed.de/mlentory_graph/default/private_tests/input>,
        <http://mlentory.zbmed.de/mlentory_graph/default/private_tests/output> ;
    schema:description "Column 'private_tests' from the Hugging Face parquet file."@en ;
    schema:name "default/private_tests"@en .

<http://mlentory.zbmed.de/mlentory_graph/default/private_tests/input> a ns2:Field ;
    ns2:dataType schema:Text ;
    schema:description "Column 'private_tests' from the Hugging Face parquet file."@en ;
    schema:name "default/private_tests/input"@en .

<http://mlentory.zbmed.de/mlentory_graph/default/private_tests/output> a ns2:Field ;
    ns2:dataType schema:Text ;
    schema:description "Column 'private_tests' from the Hugging Face parquet file."@en ;
    schema:name "default/private_tests/output"@en .

<http://mlentory.zbmed.de/mlentory_graph/default/public_tests> a ns2:Field ;
    ns2:repeated true ;
    ns2:subField <http://mlentory.zbmed.de/mlentory_graph/default/public_tests/input>,
        <http://mlentory.zbmed.de/mlentory_graph/default/public_tests/output> ;
    schema:description "Column 'public_tests' from the Hugging Face parquet file."@en ;
    schema:name "default/public_tests"@en .

<http://mlentory.zbmed.de/mlentory_graph/default/public_tests/input> a ns2:Field ;
    ns2:dataType schema:Text ;
    schema:description "Column 'public_tests' from the Hugging Face parquet file."@en ;
    schema:name "default/public_tests/input"@en .

<http://mlentory.zbmed.de/mlentory_graph/default/public_tests/output> a ns2:Field ;
    ns2:dataType schema:Text ;
    schema:description "Column 'public_tests' from the Hugging Face parquet file."@en ;
    schema:name "default/public_tests/output"@en .

<http://mlentory.zbmed.de/mlentory_graph/default/solutions> a ns2:Field ;
    ns2:repeated true ;
    ns2:subField <http://mlentory.zbmed.de/mlentory_graph/default/solutions/language>,
        <http://mlentory.zbmed.de/mlentory_graph/default/solutions/solution> ;
    schema:description "Column 'solutions' from the Hugging Face parquet file."@en ;
    schema:name "default/solutions"@en .

<http://mlentory.zbmed.de/mlentory_graph/default/solutions/language> a ns2:Field ;
    ns2:dataType schema:Integer ;
    schema:description """ClassLabel column 'solutions' from the Hugging Face parquet file.
Labels:
UNKNOWN_LANGUAGE (0), PYTHON (1), CPP (2), PYTHON3 (3), JAVA (4)"""@en ;
    schema:name "default/solutions/language"@en .

<http://mlentory.zbmed.de/mlentory_graph/default/solutions/solution> a ns2:Field ;
    ns2:dataType schema:Text ;
    schema:description "Column 'solutions' from the Hugging Face parquet file."@en ;
    schema:name "default/solutions/solution"@en .

<http://mlentory.zbmed.de/mlentory_graph/default/source> a ns2:Field ;
    ns2:dataType schema:Integer ;
    schema:description """ClassLabel column 'source' from the Hugging Face parquet file.
Labels:
UNKNOWN_SOURCE (0), CODECHEF (1), CODEFORCES (2), HACKEREARTH (3), CODEJAM (4), ATCODER (5), AIZU (6)"""@en ;
    schema:name "default/source"@en .

<http://mlentory.zbmed.de/mlentory_graph/default/split> a ns2:Field ;
    ns2:dataType schema:Text ;
    schema:description "Split to which the example belongs to."@en ;
    schema:name "default/split"@en .

<http://mlentory.zbmed.de/mlentory_graph/default/time_limit> a ns2:Field ;
    ns2:subField <http://mlentory.zbmed.de/mlentory_graph/default/time_limit/nanos>,
        <http://mlentory.zbmed.de/mlentory_graph/default/time_limit/seconds> ;
    schema:description "Column 'time_limit' from the Hugging Face parquet file."@en ;
    schema:name "default/time_limit"@en .

<http://mlentory.zbmed.de/mlentory_graph/default/time_limit/nanos> a ns2:Field ;
    ns2:dataType schema:Integer ;
    schema:description "Column 'time_limit' from the Hugging Face parquet file."@en ;
    schema:name "default/time_limit/nanos"@en .

<http://mlentory.zbmed.de/mlentory_graph/default/time_limit/seconds> a ns2:Field ;
    ns2:dataType schema:Integer ;
    schema:description "Column 'time_limit' from the Hugging Face parquet file."@en ;
    schema:name "default/time_limit/seconds"@en .

<http://mlentory.zbmed.de/mlentory_graph/default/untranslated_description> a ns2:Field ;
    ns2:dataType schema:Text ;
    schema:description "Column 'untranslated_description' from the Hugging Face parquet file."@en ;
    schema:name "default/untranslated_description"@en .

<http://mlentory.zbmed.de/mlentory_graph/e694cb482434e33f5aadafc7ba5607930722b2bd1b0cb252690679261c8692f4> a schema:DefinedTerm ;
    schema:name "text2text-generation"^^xsd:string .

<http://mlentory.zbmed.de/mlentory_graph/eecd2795372f69eac8c76964a6326966b25f090f48f4e8b55cbde405af29a119> a schema:ScholarlyArticle ;
    schema:abstract """In this work, we develop and release Llama 2, a collection of pretrained and
fine-tuned large language models (LLMs) ranging in scale from 7 billion to 70
billion parameters. Our fine-tuned LLMs, called Llama 2-Chat, are optimized for
dialogue use cases. Our models outperform open-source chat models on most
benchmarks we tested, and based on our human evaluations for helpfulness and
safety, may be a suitable substitute for closed-source models. We provide a
detailed description of our approach to fine-tuning and safety improvements of
Llama 2-Chat in order to enable the community to build on our work and
contribute to the responsible development of LLMs."""^^xsd:string ;
    schema:author "{'name': 'Adina Williams', 'affiliation': None}"^^xsd:string,
        "{'name': 'Alan Schelten', 'affiliation': None}"^^xsd:string,
        "{'name': 'Amjad Almahairi', 'affiliation': None}"^^xsd:string,
        "{'name': 'Andrew Poulton', 'affiliation': None}"^^xsd:string,
        "{'name': 'Angela Fan', 'affiliation': None}"^^xsd:string,
        "{'name': 'Anthony Hartshorn', 'affiliation': None}"^^xsd:string,
        "{'name': 'Artem Korenev', 'affiliation': None}"^^xsd:string,
        "{'name': 'Aurelien Rodriguez', 'affiliation': None}"^^xsd:string,
        "{'name': 'Binh Tang', 'affiliation': None}"^^xsd:string,
        "{'name': 'Brian Fuller', 'affiliation': None}"^^xsd:string,
        "{'name': 'Cristian Canton Ferrer', 'affiliation': None}"^^xsd:string,
        "{'name': 'Cynthia Gao', 'affiliation': None}"^^xsd:string,
        "{'name': 'Dan Bikel', 'affiliation': None}"^^xsd:string,
        "{'name': 'David Esiobu', 'affiliation': None}"^^xsd:string,
        "{'name': 'Diana Liskovich', 'affiliation': None}"^^xsd:string,
        "{'name': 'Eric Michael Smith', 'affiliation': None}"^^xsd:string,
        "{'name': 'Guillem Cucurull', 'affiliation': None}"^^xsd:string,
        "{'name': 'Hakan Inan', 'affiliation': None}"^^xsd:string,
        "{'name': 'Hugo Touvron', 'affiliation': None}"^^xsd:string,
        "{'name': 'Igor Molybog', 'affiliation': None}"^^xsd:string,
        "{'name': 'Iliyan Zarov', 'affiliation': None}"^^xsd:string,
        "{'name': 'Isabel Kloumann', 'affiliation': None}"^^xsd:string,
        "{'name': 'Jenya Lee', 'affiliation': None}"^^xsd:string,
        "{'name': 'Jeremy Fu', 'affiliation': None}"^^xsd:string,
        "{'name': 'Jeremy Reizenstein', 'affiliation': None}"^^xsd:string,
        "{'name': 'Jian Xiang Kuan', 'affiliation': None}"^^xsd:string,
        "{'name': 'Jude Fernandes', 'affiliation': None}"^^xsd:string,
        "{'name': 'Kalyan Saladi', 'affiliation': None}"^^xsd:string,
        "{'name': 'Kevin Stone', 'affiliation': None}"^^xsd:string,
        "{'name': 'Louis Martin', 'affiliation': None}"^^xsd:string,
        "{'name': 'Lukas Blecher', 'affiliation': None}"^^xsd:string,
        "{'name': 'Madian Khabsa', 'affiliation': None}"^^xsd:string,
        "{'name': 'Marcin Kardas', 'affiliation': None}"^^xsd:string,
        "{'name': 'Marie-Anne Lachaux', 'affiliation': None}"^^xsd:string,
        "{'name': 'Melanie Kambadur', 'affiliation': None}"^^xsd:string,
        "{'name': 'Moya Chen', 'affiliation': None}"^^xsd:string,
        "{'name': 'Naman Goyal', 'affiliation': None}"^^xsd:string,
        "{'name': 'Nikolay Bashlykov', 'affiliation': None}"^^xsd:string,
        "{'name': 'Peter Albert', 'affiliation': None}"^^xsd:string,
        "{'name': 'Prajjwal Bhargava', 'affiliation': None}"^^xsd:string,
        "{'name': 'Punit Singh Koura', 'affiliation': None}"^^xsd:string,
        "{'name': 'Pushkar Mishra', 'affiliation': None}"^^xsd:string,
        "{'name': 'Puxin Xu', 'affiliation': None}"^^xsd:string,
        "{'name': 'Ranjan Subramanian', 'affiliation': None}"^^xsd:string,
        "{'name': 'Rashi Rungta', 'affiliation': None}"^^xsd:string,
        "{'name': 'Robert Stojnic', 'affiliation': None}"^^xsd:string,
        "{'name': 'Ross Taylor', 'affiliation': None}"^^xsd:string,
        "{'name': 'Ruan Silva', 'affiliation': None}"^^xsd:string,
        "{'name': 'Rui Hou', 'affiliation': None}"^^xsd:string,
        "{'name': 'Saghar Hosseini', 'affiliation': None}"^^xsd:string,
        "{'name': 'Sergey Edunov', 'affiliation': None}"^^xsd:string,
        "{'name': 'Sharan Narang', 'affiliation': None}"^^xsd:string,
        "{'name': 'Shruti Bhosale', 'affiliation': None}"^^xsd:string,
        "{'name': 'Soumya Batra', 'affiliation': None}"^^xsd:string,
        "{'name': 'Thibaut Lavril', 'affiliation': None}"^^xsd:string,
        "{'name': 'Thomas Scialom', 'affiliation': None}"^^xsd:string,
        "{'name': 'Todor Mihaylov', 'affiliation': None}"^^xsd:string,
        "{'name': 'Vedanuj Goswami', 'affiliation': None}"^^xsd:string,
        "{'name': 'Viktor Kerkez', 'affiliation': None}"^^xsd:string,
        "{'name': 'Wenyin Fu', 'affiliation': None}"^^xsd:string,
        "{'name': 'Xavier Martinet', 'affiliation': None}"^^xsd:string,
        "{'name': 'Xiaoqing Ellen Tan', 'affiliation': None}"^^xsd:string,
        "{'name': 'Yasmine Babaei', 'affiliation': None}"^^xsd:string,
        "{'name': 'Yinghai Lu', 'affiliation': None}"^^xsd:string,
        "{'name': 'Yixin Nie', 'affiliation': None}"^^xsd:string,
        "{'name': 'Yuchen Zhang', 'affiliation': None}"^^xsd:string,
        "{'name': 'Yuning Mao', 'affiliation': None}"^^xsd:string,
        "{'name': 'Zheng Yan', 'affiliation': None}"^^xsd:string ;
    schema:datePublished "2023-07-18"^^xsd:date ;
    schema:keywords "cs.AI"^^xsd:string,
        "cs.CL"^^xsd:string ;
    schema:name "Llama 2: Open Foundation and Fine-Tuned Chat Models"^^xsd:string ;
    schema:url "https://arxiv.org/abs/2307.09288"^^xsd:anyURI,
        "https://arxiv.org/abs/2307.09288"^^xsd:string .

<http://mlentory.zbmed.de/mlentory_graph/f57740f97820ddb55f90898c07a60a736e9a9030d5eac125af5c595ad0638c8f> a schema:DefinedTerm ;
    schema:name "text-to-image"^^xsd:string .

<http://mlentory.zbmed.de/mlentory_graph/f5a6a15b057055acaed46aabd835cf3eb56fa2343723cec43da3298c6a298537> a schema:Person ;
    schema:name "lachiewyoung"^^xsd:string ;
    schema:url "https://huggingface.co/lachiewyoung"^^xsd:anyURI .

<http://mlentory.zbmed.de/mlentory_graph/f68885f104a68685936c980fdc14f386a9ccf26d5fa89b57ee217dbaf592e58a> a schema:Person ;
    schema:name "Xinging"^^xsd:string ;
    schema:url "https://huggingface.co/Xinging"^^xsd:anyURI .

<http://mlentory.zbmed.de/mlentory_graph/main/answer> a ns2:Field ;
    ns2:dataType schema:Text ;
    schema:description "Column 'answer' from the Hugging Face parquet file."@en ;
    schema:name "main/answer"@en .

<http://mlentory.zbmed.de/mlentory_graph/main/question> a ns2:Field ;
    ns2:dataType schema:Text ;
    schema:description "Column 'question' from the Hugging Face parquet file."@en ;
    schema:name "main/question"@en .

<http://mlentory.zbmed.de/mlentory_graph/main/split> a ns2:Field ;
    ns2:dataType schema:Text ;
    schema:description "Split to which the example belongs to."@en ;
    schema:name "main/split"@en .

<http://mlentory.zbmed.de/mlentory_graph/plain_text/domain> a ns2:Field ;
    ns2:dataType schema:Text ;
    schema:description "Column 'domain' from the Hugging Face parquet file."@en ;
    schema:name "plain_text/domain"@en .

<http://mlentory.zbmed.de/mlentory_graph/plain_text/split> a ns2:Field ;
    ns2:dataType schema:Text ;
    schema:description "Split to which the example belongs to."@en ;
    schema:name "plain_text/split"@en .

<http://mlentory.zbmed.de/mlentory_graph/plain_text/text> a ns2:Field ;
    ns2:dataType schema:Text ;
    schema:description "Column 'text' from the Hugging Face parquet file."@en ;
    schema:name "plain_text/text"@en .

<http://mlentory.zbmed.de/mlentory_graph/raw/correct> a ns2:Field ;
    ns2:dataType schema:Text ;
    schema:description "Column 'correct' from the Hugging Face parquet file."@en ;
    schema:name "raw/correct"@en .

<http://mlentory.zbmed.de/mlentory_graph/raw/options> a ns2:Field ;
    ns2:dataType schema:Text ;
    ns2:repeated true ;
    schema:description "Column 'options' from the Hugging Face parquet file."@en ;
    schema:name "raw/options"@en .

<http://mlentory.zbmed.de/mlentory_graph/raw/question> a ns2:Field ;
    ns2:dataType schema:Text ;
    schema:description "Column 'question' from the Hugging Face parquet file."@en ;
    schema:name "raw/question"@en .

<http://mlentory.zbmed.de/mlentory_graph/raw/rationale> a ns2:Field ;
    ns2:dataType schema:Text ;
    schema:description "Column 'rationale' from the Hugging Face parquet file."@en ;
    schema:name "raw/rationale"@en .

<http://mlentory.zbmed.de/mlentory_graph/raw/split> a ns2:Field ;
    ns2:dataType schema:Text ;
    schema:description "Split to which the example belongs to."@en ;
    schema:name "raw/split"@en .

<http://mlentory.zbmed.de/mlentory_graph/socratic/answer> a ns2:Field ;
    ns2:dataType schema:Text ;
    schema:description "Column 'answer' from the Hugging Face parquet file."@en ;
    schema:name "socratic/answer"@en .

<http://mlentory.zbmed.de/mlentory_graph/socratic/question> a ns2:Field ;
    ns2:dataType schema:Text ;
    schema:description "Column 'question' from the Hugging Face parquet file."@en ;
    schema:name "socratic/question"@en .

<http://mlentory.zbmed.de/mlentory_graph/socratic/split> a ns2:Field ;
    ns2:dataType schema:Text ;
    schema:description "Split to which the example belongs to."@en ;
    schema:name "socratic/split"@en .

<http://mlentory.zbmed.de/mlentory_graph/tokenized/correct> a ns2:Field ;
    ns2:dataType schema:Text ;
    schema:description "Column 'correct' from the Hugging Face parquet file."@en ;
    schema:name "tokenized/correct"@en .

<http://mlentory.zbmed.de/mlentory_graph/tokenized/options> a ns2:Field ;
    ns2:dataType schema:Text ;
    ns2:repeated true ;
    schema:description "Column 'options' from the Hugging Face parquet file."@en ;
    schema:name "tokenized/options"@en .

<http://mlentory.zbmed.de/mlentory_graph/tokenized/question> a ns2:Field ;
    ns2:dataType schema:Text ;
    schema:description "Column 'question' from the Hugging Face parquet file."@en ;
    schema:name "tokenized/question"@en .

<http://mlentory.zbmed.de/mlentory_graph/tokenized/rationale> a ns2:Field ;
    ns2:dataType schema:Text ;
    schema:description "Column 'rationale' from the Hugging Face parquet file."@en ;
    schema:name "tokenized/rationale"@en .

<http://mlentory.zbmed.de/mlentory_graph/tokenized/split> a ns2:Field ;
    ns2:dataType schema:Text ;
    schema:description "Split to which the example belongs to."@en ;
    schema:name "tokenized/split"@en .

<http://mlentory.zbmed.de/mlentory_graph/04151ef09fe56a2be18a7d842066720d6e7cee10ed5bf1a3363193444decd94d> a schema:DefinedTerm ;
    schema:name "generated_from_trainer"^^xsd:string .

<http://mlentory.zbmed.de/mlentory_graph/13e6e4095523310627190177e08c0206ca97e76f4c4565c15c2b35270daa2588> a schema:DefinedTerm ;
    schema:name "model-index"^^xsd:string .

<http://mlentory.zbmed.de/mlentory_graph/1f1b91c653f20f0cf893aeb65fa83459983d2cb51e18030488be0e30b0e6db67> a schema:DefinedTerm ;
    schema:description "Models based on LLaMA (Large Language Model Meta AI), a family of large language models that use a transformer architecture."^^xsd:string ;
    schema:name "llama"^^xsd:string .

<http://mlentory.zbmed.de/mlentory_graph/29d9051dd7490ee997ef15f45bf916274706268eab63f2c7bff767388d51cf25> a schema:DefinedTerm ;
    schema:name "audio"^^xsd:string .

<http://mlentory.zbmed.de/mlentory_graph/61cce84de930f0da8c78ddef3203a2afac70cf5e46684f0407180738cd821965> a schema:DefinedTerm ;
    schema:name "conversational"^^xsd:string .

<http://mlentory.zbmed.de/mlentory_graph/79549f00e6767e7c56b491b734b5ec351d3faaae4afc546b64c29d0146128a68> a schema:ScholarlyArticle ;
    schema:abstract """We study the capabilities of speech processing systems trained simply to
predict large amounts of transcripts of audio on the internet. When scaled to
680,000 hours of multilingual and multitask supervision, the resulting models
generalize well to standard benchmarks and are often competitive with prior
fully supervised results but in a zero-shot transfer setting without the need
for any fine-tuning. When compared to humans, the models approach their
accuracy and robustness. We are releasing models and inference code to serve as
a foundation for further work on robust speech processing."""^^xsd:string ;
    schema:author "{'name': 'Alec Radford', 'affiliation': None}"^^xsd:string,
        "{'name': 'Christine McLeavey', 'affiliation': None}"^^xsd:string,
        "{'name': 'Greg Brockman', 'affiliation': None}"^^xsd:string,
        "{'name': 'Ilya Sutskever', 'affiliation': None}"^^xsd:string,
        "{'name': 'Jong Wook Kim', 'affiliation': None}"^^xsd:string,
        "{'name': 'Tao Xu', 'affiliation': None}"^^xsd:string ;
    schema:datePublished "2022-12-06"^^xsd:date ;
    schema:keywords "cs.CL"^^xsd:string,
        "cs.LG"^^xsd:string,
        "cs.SD"^^xsd:string,
        "eess.AS"^^xsd:string ;
    schema:name "Robust Speech Recognition via Large-Scale Weak Supervision"^^xsd:string ;
    schema:url "https://arxiv.org/abs/2212.04356"^^xsd:anyURI,
        "https://arxiv.org/abs/2212.04356"^^xsd:string .

<http://mlentory.zbmed.de/mlentory_graph/863d9e15edc2c98657749abae884b48544051490f76ea0e913adf85a3f2727a5> a schema:Person ;
    schema:name "openai"^^xsd:string ;
    schema:url "https://huggingface.co/openai"^^xsd:anyURI .

<http://mlentory.zbmed.de/mlentory_graph/974df5e3234c3601080dac4fa96eebf5d19d40df41e9e30cb61084d9fbefea1e> a schema:DefinedTerm ;
    schema:description "Visualization toolkit for machine learning experiments that helps track metrics, visualize graphs, and explore embeddings."^^xsd:string ;
    schema:name "TensorBoard"^^xsd:string,
        "tensorboard"^^xsd:string .

<http://mlentory.zbmed.de/mlentory_graph/default_splits/split_name> a ns2:Field ;
    ns2:dataType schema:Text ;
    schema:description "The name of the split."@en ;
    schema:name "split_name"@en .

<http://mlentory.zbmed.de/mlentory_graph/main_splits/split_name> a ns2:Field ;
    ns2:dataType schema:Text ;
    schema:description "The name of the split."@en ;
    schema:name "split_name"@en .

<http://mlentory.zbmed.de/mlentory_graph/plain_text_splits/split_name> a ns2:Field ;
    ns2:dataType schema:Text ;
    schema:description "The name of the split."@en ;
    schema:name "split_name"@en .

<http://mlentory.zbmed.de/mlentory_graph/raw_splits/split_name> a ns2:Field ;
    ns2:dataType schema:Text ;
    schema:description "The name of the split."@en ;
    schema:name "split_name"@en .

<http://mlentory.zbmed.de/mlentory_graph/socratic_splits/split_name> a ns2:Field ;
    ns2:dataType schema:Text ;
    schema:description "The name of the split."@en ;
    schema:name "split_name"@en .

<http://mlentory.zbmed.de/mlentory_graph/tokenized_splits/split_name> a ns2:Field ;
    ns2:dataType schema:Text ;
    schema:description "The name of the split."@en ;
    schema:name "split_name"@en .

<http://mlentory.zbmed.de/mlentory_graph/07456871ec04ff7e102a14a63ee4f77775baadaf5e404b74e2ab827a14335259> a schema:DefinedTerm ;
    schema:name "automatic-speech-recognition"^^xsd:string .

<http://mlentory.zbmed.de/mlentory_graph/1fe551ba3faf898fda38c533bbd65bcba38644c47f7415289a6bee9579f2b365> a ns1:Dataset,
        schema:Dataset ;
    schema:name "deepmind/code_contests"^^xsd:string ;
    schema:url "https://huggingface.co/datasets/deepmind/code_contests"^^xsd:anyURI .

<http://mlentory.zbmed.de/mlentory_graph/43bc0319b35edce6a819b7513d5d158c1ea9bd4b7e1f558fabd51fb09b4f7755> a ns1:Dataset ;
    schema:name "qed"^^xsd:string ;
    schema:url "https://huggingface.co/datasets/qed"^^xsd:anyURI .

<http://mlentory.zbmed.de/mlentory_graph/4a958b2cddc6f3096d3a4e912c3bf694e8c132edcdb79366c6a34dff81cbbc7b> a ns1:Dataset ;
    schema:name "taskmaster2"^^xsd:string ;
    schema:url "https://huggingface.co/datasets/taskmaster2"^^xsd:anyURI .

<http://mlentory.zbmed.de/mlentory_graph/5ad4ea0a1adc915075db5ddcb934b366ce7b5457e888eac0c229b5478d60a36b> a ns1:Dataset,
        schema:Dataset ;
    schema:name "aqua_rat"^^xsd:string ;
    schema:url "https://huggingface.co/datasets/aqua_rat"^^xsd:anyURI .

<http://mlentory.zbmed.de/mlentory_graph/5dc0f178a97885f8a2e4615a52b4e2b4f27d25a59fce78191c80557258b63498> a ns1:Dataset,
        schema:Dataset ;
    schema:name "lambada"^^xsd:string ;
    schema:url "https://huggingface.co/datasets/lambada"^^xsd:anyURI .

<http://mlentory.zbmed.de/mlentory_graph/63c4690edf3557f17b07f48296b33ccc383956a845d01233d59d9e359bf38c99> a ns1:Dataset ;
    schema:name "DianaJin/sample"^^xsd:string ;
    schema:url "https://huggingface.co/datasets/DianaJin/sample"^^xsd:anyURI .

<http://mlentory.zbmed.de/mlentory_graph/65d71074238354144f600279f94efa203ecd00ca7b0c6df7d4041b8a3daa0c02> a ns1:Dataset,
        schema:Dataset ;
    schema:name "svakulenk0/qrecc"^^xsd:string ;
    schema:url "https://huggingface.co/datasets/svakulenk0/qrecc"^^xsd:anyURI .

<http://mlentory.zbmed.de/mlentory_graph/6925cb204ab4d5280c948ac7e23dd8f7b48d1de433cf9edc5c30a8d87ce3b317> a schema:DefinedTerm ;
    schema:description "Creates natural language text based on initial prompts."^^xsd:string ;
    schema:name "Text Generation"^^xsd:string,
        "text generation"^^xsd:string .

<http://mlentory.zbmed.de/mlentory_graph/79cf083846a8329d2912fcd7f375233c37a54917af291bb945f0b58bc735b8ad> a schema:DefinedTerm ;
    schema:name "text-generation"^^xsd:string .

<http://mlentory.zbmed.de/mlentory_graph/83f6b13508bdbd7f513cbd6de7ef5170638d3e63612800f251838bd8e03c995e> a ns1:Dataset ;
    schema:name "quasc"^^xsd:string ;
    schema:url "https://huggingface.co/datasets/quasc"^^xsd:anyURI .

<http://mlentory.zbmed.de/mlentory_graph/8e9892e571845c79509180a69a268f19c0592a4e975a5fd3e16f2059af61ea75> a schema:DefinedTerm ;
    schema:name "hf-asr-leaderboard"^^xsd:string .

<http://mlentory.zbmed.de/mlentory_graph/9773f8d647166503d14c7a05030b47d6b1610f17bdd55e8c98cb4fc2b13a3379> a ns1:Dataset ;
    schema:name "djaym7/wiki_dialog"^^xsd:string ;
    schema:url "https://huggingface.co/datasets/djaym7/wiki_dialog"^^xsd:anyURI .

<http://mlentory.zbmed.de/mlentory_graph/9c51ba772888465129d6bda3b0b520a3a16960b8c108a8cd2276eb4fb85ee5f2> a schema:DefinedTerm ;
    schema:description "High-performance numerical computing library that combines NumPy, automatic differentiation, and GPU/TPU support for ML research."^^xsd:string ;
    schema:name "JAX"^^xsd:string,
        "jax"^^xsd:string .

<http://mlentory.zbmed.de/mlentory_graph/a7eca72cd0a3a0ce30e3b37b299034e8cf2e3b921a7deaf54545b7d00e88c5e4> a schema:DefinedTerm ;
    schema:name "whisper"^^xsd:string .

<http://mlentory.zbmed.de/mlentory_graph/ba52d56993d4b3a19ff2ae9a283e7057fc5503a3a3eecc69e091547b776282b4> a ns1:Dataset,
        schema:Dataset ;
    schema:name "gsm8k"^^xsd:string ;
    schema:url "https://huggingface.co/datasets/gsm8k"^^xsd:anyURI .

<http://mlentory.zbmed.de/mlentory_graph/cafa6cfd9a4170cbf6a99f2d8b42715517f11068dc92b807e31dad9ab0535893> a ns1:Dataset ;
    schema:name "esnli"^^xsd:string ;
    schema:url "https://huggingface.co/datasets/esnli"^^xsd:anyURI .

<http://mlentory.zbmed.de/mlentory_graph/db86f2c8ce693db878b689231690fab2fe37b7ae1abc1e54dca9fae35bc0df0d> a schema:DefinedTerm ;
    schema:description "Transcribes spoken language into written text."^^xsd:string ;
    schema:name "Automatic Speech Recognition"^^xsd:string,
        "automatic speech recognition"^^xsd:string .

<http://mlentory.zbmed.de/mlentory_graph/fadbdd40ae3e4d21fb8044995368c36935104a0e589c0bb691d566a182b91295> a ns1:Dataset ;
    schema:name "CyberHarem/chokai_azurlane"^^xsd:string ;
    schema:url "https://huggingface.co/datasets/CyberHarem/chokai_azurlane"^^xsd:anyURI .

<http://mlentory.zbmed.de/mlentory_graph/81c4f52fcccf6ef0d25453aedb7cebe30c7034e3b2fa752246d0e43da889a0e1> a schema:DefinedTerm ;
    schema:name "autotrain_compatible"^^xsd:string .

<http://mlentory.zbmed.de/mlentory_graph/f59cf55f3a86acf0bcfc020eac552a72c13f1212154211a7bf30504548661f8d> a schema:DefinedTerm ;
    schema:description "Optimized backend for deploying and serving Large Language Models (LLMs) with high performance."^^xsd:string ;
    schema:name "text-generation-inference"^^xsd:string .

<http://mlentory.zbmed.de/mlentory_graph/3e9a4e1232f617b33fa8460d6c142ee49e69eb5c55acfd1e618d58e7495955e8> a schema:DefinedTerm ;
    schema:description "Deep learning framework that provides tensor computation with GPU acceleration and automatic differentiation. Popular for research and production ML models."^^xsd:string ;
    schema:name "PyTorch"^^xsd:string,
        "pytorch"^^xsd:string .

<http://mlentory.zbmed.de/mlentory_graph/0dce0f5e7319b6178cd79d5f2163f0e134d0064f4ea4f93e8afeec1e7d78fa8d> a schema:DefinedTerm ;
    schema:name "endpoints_compatible"^^xsd:string .

<http://mlentory.zbmed.de/mlentory_graph/87b927fef88a46248b3b208472aec7bfeb38667386b309f46772e26b40f6affb> a schema:DefinedTerm ;
    schema:description "Fast and safe serialization format for storing and distributing machine learning model weights."^^xsd:string ;
    schema:name "Safetensors"^^xsd:string,
        "safetensors"^^xsd:string .

<http://mlentory.zbmed.de/mlentory_graph/df4982af808ead1a57663cc7a83e60059f6a6ae1baf83a270fdf8bdfef11a3de> a schema:DefinedTerm ;
    schema:description "Library providing pretrained models for NLP and CV tasks, with implementations in PyTorch and TensorFlow."^^xsd:string ;
    schema:name "Transformers"^^xsd:string,
        "transformers"^^xsd:string .

