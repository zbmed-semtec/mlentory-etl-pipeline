@prefix ns1: <https://w3id.org/fair4ml/> .
@prefix ns2: <https://w3id.org/codemeta/> .
@prefix schema: <https://schema.org/> .
@prefix xsd: <http://www.w3.org/2001/XMLSchema#> .

<https://w3id.org/mlentory/mlentory_graph/017f19456e7a37fe3c1ad51165020b62cc12497d5d20651e073e3520a5099eb9> a schema:DefinedTerm ;
    schema:description "Answers questions based on tabular data."^^xsd:string ;
    schema:name "Table Question Answering"^^xsd:string .

<https://w3id.org/mlentory/mlentory_graph/0c3d01ed44dc2940ae38707146a02c16bc80cc8637ce48ac5f3125b7c6fb2982> a schema:DefinedTerm ;
    schema:description "Models based on BERT (Bidirectional Encoder Representations from Transformers), a transformer architecture that learns contextual word embeddings."^^xsd:string ;
    schema:name "bert"^^xsd:string .

<https://w3id.org/mlentory/mlentory_graph/119bd2aa6d51fb076ddf89b0c5c2536f1550ff5bf549b11a6c834340b0979a14> a schema:DefinedTerm ;
    schema:description "Library for span-based named entity recognition using transformer models."^^xsd:string ;
    schema:name "SpanMarker"^^xsd:string .

<https://w3id.org/mlentory/mlentory_graph/12855f71ca9ab0f85c6609885b9e912174c81e608da47e6448d968f757f5ab44> a schema:DefinedTerm ;
    schema:description "Library for efficient text classification and word representation learning."^^xsd:string ;
    schema:name "fastText"^^xsd:string .

<https://w3id.org/mlentory/mlentory_graph/145a1db14402ffd2d346a7bf50e3e9e8c75169383a079480e9ba655e5e2fab8a> a schema:DefinedTerm ;
    schema:description "Unity package for running neural networks in real-time applications and games."^^xsd:string ;
    schema:name "unity-sentis"^^xsd:string .

<https://w3id.org/mlentory/mlentory_graph/15ceeb8703c6ba669411911c62acbbac38f4d1235e8ac6118537ac1e6d75ae84> a schema:DefinedTerm ;
    schema:description "High-throughput asynchronous reinforcement learning framework for training RL agents."^^xsd:string ;
    schema:name "sample-factory"^^xsd:string .

<https://w3id.org/mlentory/mlentory_graph/1759562ba5af131b8ba1cdb4e06a2cee5c1ebff35971610e6ef2eb585b413ef7> a schema:DefinedTerm ;
    schema:description "Identifies when someone is speaking in an audio stream."^^xsd:string ;
    schema:name "Voice Activity Detection"^^xsd:string .

<https://w3id.org/mlentory/mlentory_graph/18cdeb8540660e6ff688421d2a21f14d043b33f931a4cde8d50e489c56efce84> a ns1:ML_Model ;
    schema:archivedAt <https://huggingface.co/p2g4ads5/Qwen2.5-0.5B-Instruct-Gensyn-Swarm-docile_playful_octopus> ;
    schema:conditionsOfAccess "Information not found"^^xsd:string ;
    schema:dateCreated "2025-05-17T18:34:55+00:00"^^xsd:dateTime ;
    schema:dateModified "2025-06-20T00:40:11+00:00"^^xsd:dateTime ;
    schema:datePublished "2025-05-17T18:34:55+00:00"^^xsd:dateTime ;
    schema:description """

# Model Card for Qwen2.5-0.5B-Instruct-Gensyn-Swarm-docile_playful_octopus

This model is a fine-tuned version of [unsloth/Qwen2.5-0.5B-Instruct](https://huggingface.co/unsloth/Qwen2.5-0.5B-Instruct).
It has been trained using [TRL](https://github.com/huggingface/trl).

## Quick start

```python
from transformers import pipeline

question = "If you had a time machine, but could only go to the past or the future once and never return, which would you choose and why?"
generator = pipeline("text-generation", model="p2g4ads5/Qwen2.5-0.5B-Instruct-Gensyn-Swarm-docile_playful_octopus", device="cuda")
output = generator([{"role": "user", "content": question}], max_new_tokens=128, return_full_text=False)[0]
print(output["generated_text"])
```

## Training procedure

 


This model was trained with GRPO, a method introduced in [DeepSeekMath: Pushing the Limits of Mathematical Reasoning in Open Language Models](https://huggingface.co/papers/2402.03300).

### Framework versions

- TRL: 0.17.0
- Transformers: 4.51.3
- Pytorch: 2.7.0
- Datasets: 3.6.0
- Tokenizers: 0.21.1

## Citations

Cite GRPO as:

```bibtex
@article{zhihong2024deepseekmath,
    title        = {{DeepSeekMath: Pushing the Limits of Mathematical Reasoning in Open Language Models}},
    author       = {Zhihong Shao and Peiyi Wang and Qihao Zhu and Runxin Xu and Junxiao Song and Mingchuan Zhang and Y. K. Li and Y. Wu and Daya Guo},
    year         = 2024,
    eprint       = {arXiv:2402.03300},
}

```

Cite TRL as:
    
```bibtex
@misc{vonwerra2022trl,
	title        = {{TRL: Transformer Reinforcement Learning}},
	author       = {Leandro von Werra and Younes Belkada and Lewis Tunstall and Edward Beeching and Tristan Thrush and Nathan Lambert and Shengyi Huang and Kashif Rasul and Quentin Gallou{\\'e}dec},
	year         = 2020,
	journal      = {GitHub repository},
	publisher    = {GitHub},
	howpublished = {\\url{https://github.com/huggingface/trl}}
}
```"""^^xsd:string ;
    schema:discussionUrl <https://huggingface.co/p2g4ads5/Qwen2.5-0.5B-Instruct-Gensyn-Swarm-docile_playful_octopus/discussions> ;
    schema:identifier "https://huggingface.co/p2g4ads5/Qwen2.5-0.5B-Instruct-Gensyn-Swarm-docile_playful_octopus"^^xsd:string ;
    schema:inLanguage "Information not found"^^xsd:string ;
    schema:keywords <https://w3id.org/mlentory/mlentory_graph/04151ef09fe56a2be18a7d842066720d6e7cee10ed5bf1a3363193444decd94d>,
        <https://w3id.org/mlentory/mlentory_graph/0dce0f5e7319b6178cd79d5f2163f0e134d0064f4ea4f93e8afeec1e7d78fa8d>,
        <https://w3id.org/mlentory/mlentory_graph/28f6fc79227e13d54a24f63fe2a8971b6f281ac3ca778d4303f84baacbc18a18>,
        <https://w3id.org/mlentory/mlentory_graph/29901b0ecce864a67f7734a040b22f9867d7435fdb731b76633a212ffab331f4>,
        <https://w3id.org/mlentory/mlentory_graph/5f6067eceeefdacabbbeea2a780dfa7345e1272c829c82298b760358c1bb07a8>,
        <https://w3id.org/mlentory/mlentory_graph/61cce84de930f0da8c78ddef3203a2afac70cf5e46684f0407180738cd821965>,
        <https://w3id.org/mlentory/mlentory_graph/789df8584c437cfcddc5b2fff51cdef26423ea8d53635a0100a83cd8490b5cb6>,
        <https://w3id.org/mlentory/mlentory_graph/79cf083846a8329d2912fcd7f375233c37a54917af291bb945f0b58bc735b8ad>,
        <https://w3id.org/mlentory/mlentory_graph/81c4f52fcccf6ef0d25453aedb7cebe30c7034e3b2fa752246d0e43da889a0e1>,
        <https://w3id.org/mlentory/mlentory_graph/87b927fef88a46248b3b208472aec7bfeb38667386b309f46772e26b40f6affb>,
        <https://w3id.org/mlentory/mlentory_graph/a4cf9836ab3780436e61a37fe48729edb682b8e0e1c3f9363cb10061770a7197>,
        <https://w3id.org/mlentory/mlentory_graph/c21ccd276af5ae1828bea64af6da9742c6ef229f7b0571987909160419d90560>,
        <https://w3id.org/mlentory/mlentory_graph/df4982af808ead1a57663cc7a83e60059f6a6ae1baf83a270fdf8bdfef11a3de>,
        <https://w3id.org/mlentory/mlentory_graph/f59cf55f3a86acf0bcfc020eac552a72c13f1212154211a7bf30504548661f8d> ;
    schema:license "Information not found"^^xsd:string ;
    schema:memoryRequirements "Not available"^^xsd:string ;
    schema:name "Qwen2.5-0.5B-Instruct-Gensyn-Swarm-docile_playful_octopus"^^xsd:string ;
    schema:url <https://huggingface.co/p2g4ads5/Qwen2.5-0.5B-Instruct-Gensyn-Swarm-docile_playful_octopus> ;
    ns2:issueTracker <https://huggingface.co/p2g4ads5/Qwen2.5-0.5B-Instruct-Gensyn-Swarm-docile_playful_octopus/discussions> ;
    ns2:readme <https://huggingface.co/p2g4ads5/Qwen2.5-0.5B-Instruct-Gensyn-Swarm-docile_playful_octopus/blob/main/README.md> ;
    ns2:referencePublication <https://w3id.org/mlentory/mlentory_graph/57ac8dd147b53050bf4aa8cb4dbc16ad91197f7662c02666466eb8e9888d87a7> ;
    ns1:evaluatedOn "Information not found"^^xsd:string ;
    ns1:fineTunedFrom <https://w3id.org/mlentory/mlentory_graph/4d2ce24e500528b55a21cac8de96cce215994b6ca25877254bca1857cd8b9e55> ;
    ns1:mlTask <https://w3id.org/mlentory/mlentory_graph/6925cb204ab4d5280c948ac7e23dd8f7b48d1de433cf9edc5c30a8d87ce3b317> ;
    ns1:sharedBy <https://w3id.org/mlentory/mlentory_graph/cc9b9fbf64bf4588733ee17a2c0af8d22af99f9375d502c4dc33e83e14cb7c9f> ;
    ns1:testedOn "Information not found"^^xsd:string ;
    ns1:trainedOn "Information not found"^^xsd:string .

<https://w3id.org/mlentory/mlentory_graph/192e3c37cdad044da28b01edd768819d9dc9ebf5642a4dd3e0cf9564058b6d2a> a schema:DefinedTerm ;
    schema:description "Models quantized to 8-bit precision, balancing performance and memory efficiency."^^xsd:string ;
    schema:name "8-bit precision"^^xsd:string .

<https://w3id.org/mlentory/mlentory_graph/1f1b91c653f20f0cf893aeb65fa83459983d2cb51e18030488be0e30b0e6db67> a schema:DefinedTerm ;
    schema:description "Models based on LLaMA (Large Language Model Meta AI), a family of large language models that use a transformer architecture."^^xsd:string ;
    schema:name "llama"^^xsd:string .

<https://w3id.org/mlentory/mlentory_graph/21a4b3b0fe861021548d89e241eb815b3c147c6d12ec9eade6925be45bc78650> a schema:DefinedTerm ;
    schema:description "Transforms audio signals from one form to another."^^xsd:string ;
    schema:name "Audio to Audio"^^xsd:string .

<https://w3id.org/mlentory/mlentory_graph/251690051accbb99d763e77f3aed9b94caecf82b9e2db7c17f8adfca42a4ca39> a schema:DefinedTerm ;
    schema:description "Creates concise summaries of longer texts."^^xsd:string ;
    schema:name "Summarization"^^xsd:string .

<https://w3id.org/mlentory/mlentory_graph/25a48b7b32ec31051c00ea96f30d1637f216eb0ed7620da77d06c4637ab5da7f> a schema:DefinedTerm ;
    schema:description "Categorizes images into predefined classes or labels."^^xsd:string ;
    schema:name "Image Classification"^^xsd:string .

<https://w3id.org/mlentory/mlentory_graph/266c130bc128debb0db48b7a2e58c6423c7bafb2445fcccd68e2da192f3487d1> a schema:DefinedTerm ;
    schema:description "Converts visual content from images into textual representations."^^xsd:string ;
    schema:name "Image toText"^^xsd:string .

<https://w3id.org/mlentory/mlentory_graph/293ad034f899dc681b5be10c715f25c59fa7f5261f229b66d796246e10927354> a schema:DefinedTerm ;
    schema:description "Unity plugin that enables games and simulations to serve as environments for training intelligent agents."^^xsd:string ;
    schema:name "ml-agents"^^xsd:string .

<https://w3id.org/mlentory/mlentory_graph/2ae536499f90e7e5edcd87dddf0d258801cae8e7a2f82d8ce02361ef54e77c05> a schema:DefinedTerm ;
    schema:description "Apple's framework for integrating machine learning models into iOS, macOS, watchOS, and tvOS apps."^^xsd:string ;
    schema:name "Core ML"^^xsd:string .

<https://w3id.org/mlentory/mlentory_graph/2f28cc27d9dac219caa56a5425741f7391153065f1558fe7418d6ccc1c598fb4> a schema:DefinedTerm ;
    schema:description "Applies AI for robot control, perception, and decision-making."^^xsd:string ;
    schema:name "Robotics"^^xsd:string .

<https://w3id.org/mlentory/mlentory_graph/2f45196854d69c3bcc21304aceb64e2a3db2d17613399d7d3c7a21611573a4d5> a schema:DefinedTerm ;
    schema:description "Models with documented carbon footprint information related to their training process."^^xsd:string ;
    schema:name "Carbon Emissions"^^xsd:string .

<https://w3id.org/mlentory/mlentory_graph/3135ad7c615e157f80ecab1b96d4167d2e6c147b2e563721a652a5b56845418c> a schema:DefinedTerm ;
    schema:description "Collection of SOTA computer vision models, layers, utilities, and optimizers for training and inferencing."^^xsd:string ;
    schema:name "timm"^^xsd:string .

<https://w3id.org/mlentory/mlentory_graph/316fd1b6c56f67729f7e0880d91953804a9af869ce76b2906f26f3d534937931> a schema:DefinedTerm ;
    schema:description "Topic modeling technique that leverages BERT embeddings and clustering for document topic extraction."^^xsd:string ;
    schema:name "BERTopic"^^xsd:string .

<https://w3id.org/mlentory/mlentory_graph/320fd2f312d852d4c331c6d264303da78750d5a84acdf45bd9299f67ce480324> a ns1:ML_Model ;
    schema:archivedAt <https://huggingface.co/silverbenehi/Qwen2.5-0.5B-Instruct-Gensyn-Swarm-bold_running_kangaroo> ;
    schema:conditionsOfAccess "Information not found"^^xsd:string ;
    schema:dateCreated "2025-05-09T21:11:49+00:00"^^xsd:dateTime ;
    schema:dateModified "2025-07-16T17:29:13+00:00"^^xsd:dateTime ;
    schema:datePublished "2025-05-09T21:11:49+00:00"^^xsd:dateTime ;
    schema:description """

# Model Card for Qwen2.5-0.5B-Instruct-Gensyn-Swarm-bold_running_kangaroo

This model is a fine-tuned version of [unsloth/Qwen2.5-0.5B-Instruct](https://huggingface.co/unsloth/Qwen2.5-0.5B-Instruct).
It has been trained using [TRL](https://github.com/huggingface/trl).

## Quick start

```python
from transformers import pipeline

question = "If you had a time machine, but could only go to the past or the future once and never return, which would you choose and why?"
generator = pipeline("text-generation", model="silverbenehi/Qwen2.5-0.5B-Instruct-Gensyn-Swarm-bold_running_kangaroo", device="cuda")
output = generator([{"role": "user", "content": question}], max_new_tokens=128, return_full_text=False)[0]
print(output["generated_text"])
```

## Training procedure

 


This model was trained with GRPO, a method introduced in [DeepSeekMath: Pushing the Limits of Mathematical Reasoning in Open Language Models](https://huggingface.co/papers/2402.03300).

### Framework versions

- TRL: 0.17.0
- Transformers: 4.51.3
- Pytorch: 2.7.0
- Datasets: 3.6.0
- Tokenizers: 0.21.1

## Citations

Cite GRPO as:

```bibtex
@article{zhihong2024deepseekmath,
    title        = {{DeepSeekMath: Pushing the Limits of Mathematical Reasoning in Open Language Models}},
    author       = {Zhihong Shao and Peiyi Wang and Qihao Zhu and Runxin Xu and Junxiao Song and Mingchuan Zhang and Y. K. Li and Y. Wu and Daya Guo},
    year         = 2024,
    eprint       = {arXiv:2402.03300},
}

```

Cite TRL as:
    
```bibtex
@misc{vonwerra2022trl,
	title        = {{TRL: Transformer Reinforcement Learning}},
	author       = {Leandro von Werra and Younes Belkada and Lewis Tunstall and Edward Beeching and Tristan Thrush and Nathan Lambert and Shengyi Huang and Kashif Rasul and Quentin Gallou{\\'e}dec},
	year         = 2020,
	journal      = {GitHub repository},
	publisher    = {GitHub},
	howpublished = {\\url{https://github.com/huggingface/trl}}
}
```"""^^xsd:string ;
    schema:discussionUrl <https://huggingface.co/silverbenehi/Qwen2.5-0.5B-Instruct-Gensyn-Swarm-bold_running_kangaroo/discussions> ;
    schema:identifier "https://huggingface.co/silverbenehi/Qwen2.5-0.5B-Instruct-Gensyn-Swarm-bold_running_kangaroo"^^xsd:string ;
    schema:inLanguage "Information not found"^^xsd:string ;
    schema:keywords <https://w3id.org/mlentory/mlentory_graph/04151ef09fe56a2be18a7d842066720d6e7cee10ed5bf1a3363193444decd94d>,
        <https://w3id.org/mlentory/mlentory_graph/0dce0f5e7319b6178cd79d5f2163f0e134d0064f4ea4f93e8afeec1e7d78fa8d>,
        <https://w3id.org/mlentory/mlentory_graph/0f8852dfc8f82da503ed1ff94e72d2b21473b92b491c655b6de0ca10148428d3>,
        <https://w3id.org/mlentory/mlentory_graph/28f6fc79227e13d54a24f63fe2a8971b6f281ac3ca778d4303f84baacbc18a18>,
        <https://w3id.org/mlentory/mlentory_graph/29901b0ecce864a67f7734a040b22f9867d7435fdb731b76633a212ffab331f4>,
        <https://w3id.org/mlentory/mlentory_graph/3545f8928b123a1d57629499049e0f991171b9588a9886215e37fbab73d84c01>,
        <https://w3id.org/mlentory/mlentory_graph/61cce84de930f0da8c78ddef3203a2afac70cf5e46684f0407180738cd821965>,
        <https://w3id.org/mlentory/mlentory_graph/789df8584c437cfcddc5b2fff51cdef26423ea8d53635a0100a83cd8490b5cb6>,
        <https://w3id.org/mlentory/mlentory_graph/79cf083846a8329d2912fcd7f375233c37a54917af291bb945f0b58bc735b8ad>,
        <https://w3id.org/mlentory/mlentory_graph/81c4f52fcccf6ef0d25453aedb7cebe30c7034e3b2fa752246d0e43da889a0e1>,
        <https://w3id.org/mlentory/mlentory_graph/87b927fef88a46248b3b208472aec7bfeb38667386b309f46772e26b40f6affb>,
        <https://w3id.org/mlentory/mlentory_graph/9692fc27ed075852059afc5a54867bb875719345a6d2d9d29336d5e99e875a32>,
        <https://w3id.org/mlentory/mlentory_graph/a4cf9836ab3780436e61a37fe48729edb682b8e0e1c3f9363cb10061770a7197>,
        <https://w3id.org/mlentory/mlentory_graph/c21ccd276af5ae1828bea64af6da9742c6ef229f7b0571987909160419d90560>,
        <https://w3id.org/mlentory/mlentory_graph/df4982af808ead1a57663cc7a83e60059f6a6ae1baf83a270fdf8bdfef11a3de>,
        <https://w3id.org/mlentory/mlentory_graph/f59cf55f3a86acf0bcfc020eac552a72c13f1212154211a7bf30504548661f8d> ;
    schema:license "Information not found"^^xsd:string ;
    schema:memoryRequirements "Not available"^^xsd:string ;
    schema:name "Qwen2.5-0.5B-Instruct-Gensyn-Swarm-bold_running_kangaroo"^^xsd:string ;
    schema:url <https://huggingface.co/silverbenehi/Qwen2.5-0.5B-Instruct-Gensyn-Swarm-bold_running_kangaroo> ;
    ns2:issueTracker <https://huggingface.co/silverbenehi/Qwen2.5-0.5B-Instruct-Gensyn-Swarm-bold_running_kangaroo/discussions> ;
    ns2:readme <https://huggingface.co/silverbenehi/Qwen2.5-0.5B-Instruct-Gensyn-Swarm-bold_running_kangaroo/blob/main/README.md> ;
    ns2:referencePublication <https://w3id.org/mlentory/mlentory_graph/57ac8dd147b53050bf4aa8cb4dbc16ad91197f7662c02666466eb8e9888d87a7> ;
    ns1:evaluatedOn "Information not found"^^xsd:string ;
    ns1:fineTunedFrom <https://w3id.org/mlentory/mlentory_graph/4d2ce24e500528b55a21cac8de96cce215994b6ca25877254bca1857cd8b9e55> ;
    ns1:mlTask <https://w3id.org/mlentory/mlentory_graph/6925cb204ab4d5280c948ac7e23dd8f7b48d1de433cf9edc5c30a8d87ce3b317> ;
    ns1:sharedBy <https://w3id.org/mlentory/mlentory_graph/dc53475d9f31201c0e3ed7ccc3986594179e18c27fb01dc5aca0dcfda21516e9> ;
    ns1:testedOn "Information not found"^^xsd:string ;
    ns1:trainedOn "Information not found"^^xsd:string .

<https://w3id.org/mlentory/mlentory_graph/35d7d276230081bdfd86d06ca958126011d6a7e381452a488c2bfa8fcc512fdb> a schema:DefinedTerm ;
    schema:description "Architecture where multiple specialized sub-models (experts) are conditionally activated based on input."^^xsd:string ;
    schema:name "Mixture of Experts"^^xsd:string .

<https://w3id.org/mlentory/mlentory_graph/3b4b981961ee604488ce9db2b6cea45a4fb777fb6ee8ef76bb274e14ff6cbdf4> a schema:DefinedTerm ;
    schema:description "Trains agents through interaction with environments using rewards."^^xsd:string ;
    schema:name "Reinforcement Learning"^^xsd:string .

<https://w3id.org/mlentory/mlentory_graph/3db362f2d160db0ec9efef6e48b6ba6fc466784d4fdf38393a2818c9c974f93e> a schema:DefinedTerm ;
    schema:description "Deep learning library that simplifies training neural networks using modern best practices."^^xsd:string ;
    schema:name "fastai"^^xsd:string .

<https://w3id.org/mlentory/mlentory_graph/3e9a4e1232f617b33fa8460d6c142ee49e69eb5c55acfd1e618d58e7495955e8> a schema:DefinedTerm ;
    schema:description "Deep learning framework that provides tensor computation with GPU acceleration and automatic differentiation. Popular for research and production ML models."^^xsd:string ;
    schema:name "PyTorch"^^xsd:string .

<https://w3id.org/mlentory/mlentory_graph/40e5b840897abb6f44300acdb8df19e9ba787840ae3899b5cff54ee848bd4df6> a schema:DefinedTerm ;
    schema:description "Predicts the depth of objects in images for 3D scene understanding."^^xsd:string ;
    schema:name "Depth Estimation"^^xsd:string .

<https://w3id.org/mlentory/mlentory_graph/427579e1091b3a9a3bf55b54c4167319ee1e7fd37d7a1389722fcb73d6a8901c> a schema:DefinedTerm ;
    schema:description "Classifies images into categories not seen during training."^^xsd:string ;
    schema:name "Zero Shot Image Classification"^^xsd:string .

<https://w3id.org/mlentory/mlentory_graph/435f6e89d90ad4bd6be870aa7e1a66a9ce6bb4c201cdc1adf4aec7db47ff1148> a schema:DefinedTerm ;
    schema:description "Generates audio content from textual descriptions."^^xsd:string ;
    schema:name "Text to Audio"^^xsd:string .

<https://w3id.org/mlentory/mlentory_graph/43625c04f736f13b1f357a0d9357ed3dbc8e216e352796b03fb0fa69aea1f93b> a schema:DefinedTerm ;
    schema:description "Models based on XLM-RoBERTa, a cross-lingual version of RoBERTa pretrained on text from 100 languages for multilingual understanding."^^xsd:string ;
    schema:name "xlm-roberta"^^xsd:string .

<https://w3id.org/mlentory/mlentory_graph/45ef55138ac28324915f59dee5c5614894be22d29e2a8283b76835bcb91e3e87> a schema:DefinedTerm ;
    schema:description "Answers natural language questions about images."^^xsd:string ;
    schema:name "Visual Question Answering"^^xsd:string .

<https://w3id.org/mlentory/mlentory_graph/46fd5133284e3f6058330c31c628a6854b5eeb608d471e58c7052d9365f5acf4> a schema:DefinedTerm ;
    schema:description "Extracts meaningful features from images for downstream tasks."^^xsd:string ;
    schema:name "Image Feature Extraction"^^xsd:string .

<https://w3id.org/mlentory/mlentory_graph/483896b5e350be531b5efa19e0153e0827f930f532cf99d78a53cde6863ec9c5> a ns1:ML_Model ;
    schema:archivedAt <https://huggingface.co/goodcasper/see_ai_rt-detr_r18> ;
    schema:conditionsOfAccess "Information not found"^^xsd:string ;
    schema:dateCreated "2025-06-18T08:17:00+00:00"^^xsd:dateTime ;
    schema:dateModified "2025-06-20T00:40:00+00:00"^^xsd:dateTime ;
    schema:datePublished "2025-06-18T08:17:00+00:00"^^xsd:dateTime ;
    schema:description """

<!-- This model card has been generated automatically according to the information the Trainer had access to. You
should probably proofread and complete it, then remove this comment. -->

# see_ai_rt-detr_r18

This model is a fine-tuned version of [PekingU/rtdetr_r18vd_coco_o365](https://huggingface.co/PekingU/rtdetr_r18vd_coco_o365) on an unknown dataset.
It achieves the following results on the evaluation set:
- Loss: 14.0181
- Map: 0.0
- Map 50: 0.0
- Map 75: 0.0
- Map Small: 0.0
- Map Medium: 0.0
- Map Large: 0.0
- Mar 1: 0.0
- Mar 10: 0.0001
- Mar 100: 0.0012
- Mar Small: 0.0
- Mar Medium: 0.002
- Mar Large: 0.0
- Map Angiodysplasia: 0.0
- Mar 100 Angiodysplasia: 0.0
- Map Erosion: 0.0
- Mar 100 Erosion: 0.0
- Map Stenosis: 0.0
- Mar 100 Stenosis: 0.0
- Map Lymphangiectasia: 0.0
- Mar 100 Lymphangiectasia: 0.0
- Map Lymph follicle: 0.0
- Mar 100 Lymph follicle: 0.0138
- Map Smt: 0.0
- Mar 100 Smt: 0.0
- Map Polyp-like: 0.0
- Mar 100 Polyp-like: 0.0
- Map Bleeding: 0.0
- Mar 100 Bleeding: 0.0
- Map Diverticulum: 0.0
- Mar 100 Diverticulum: 0.0
- Map Erythema: 0.0
- Mar 100 Erythema: 0.0
- Map Foreign body: 0.0
- Mar 100 Foreign body: 0.0
- Map Vein: 0.0
- Mar 100 Vein: 0.0

## Model description

More information needed

## Intended uses & limitations

More information needed

## Training and evaluation data

More information needed

## Training procedure

### Training hyperparameters

The following hyperparameters were used during training:
- learning_rate: 0.01
- train_batch_size: 16
- eval_batch_size: 1
- seed: 42
- optimizer: Use adamw_torch with betas=(0.9,0.999) and epsilon=1e-08 and optimizer_args=No additional optimizer arguments
- lr_scheduler_type: linear
- lr_scheduler_warmup_steps: 300
- num_epochs: 1

### Training results

| Training Loss | Epoch | Step | Validation Loss | Map | Map 50 | Map 75 | Map Small | Map Medium | Map Large | Mar 1 | Mar 10 | Mar 100 | Mar Small | Mar Medium | Mar Large | Map Angiodysplasia | Mar 100 Angiodysplasia | Map Erosion | Mar 100 Erosion | Map Stenosis | Mar 100 Stenosis | Map Lymphangiectasia | Mar 100 Lymphangiectasia | Map Lymph follicle | Mar 100 Lymph follicle | Map Smt | Mar 100 Smt | Map Polyp-like | Mar 100 Polyp-like | Map Bleeding | Mar 100 Bleeding | Map Diverticulum | Mar 100 Diverticulum | Map Erythema | Mar 100 Erythema | Map Foreign body | Mar 100 Foreign body | Map Vein | Mar 100 Vein |
|:-------------:|:-----:|:----:|:---------------:|:---:|:------:|:------:|:---------:|:----------:|:---------:|:-----:|:------:|:-------:|:---------:|:----------:|:---------:|:------------------:|:----------------------:|:-----------:|:---------------:|:------------:|:----------------:|:--------------------:|:------------------------:|:------------------:|:----------------------:|:-------:|:-----------:|:--------------:|:------------------:|:------------:|:----------------:|:----------------:|:--------------------:|:------------:|:----------------:|:----------------:|:--------------------:|:--------:|:------------:|
| 25.2342       | 1.0   | 924  | 14.4355         | 0.0 | 0.0    | 0.0    | 0.0       | 0.0        | 0.0       | 0.0   | 0.0001 | 0.001   | 0.0       | 0.002      | 0.0       | 0.0                | 0.0                    | 0.0         | 0.0             | 0.0          | 0.0              | 0.0                  | 0.0                      | 0.0                | 0.0121                 | 0.0     | 0.0         | 0.0            | 0.0                | 0.0          | 0.0              | 0.0              | 0.0                  | 0.0          | 0.0              | 0.0              | 0.0                  | 0.0      | 0.0          |


### Framework versions

- Transformers 4.53.0.dev0
- Pytorch 2.7.1+cu126
- Datasets 3.6.0
- Tokenizers 0.21.1
"""^^xsd:string ;
    schema:discussionUrl <https://huggingface.co/goodcasper/see_ai_rt-detr_r18/discussions> ;
    schema:identifier "https://huggingface.co/goodcasper/see_ai_rt-detr_r18"^^xsd:string ;
    schema:inLanguage "Information not found"^^xsd:string ;
    schema:keywords <https://w3id.org/mlentory/mlentory_graph/04151ef09fe56a2be18a7d842066720d6e7cee10ed5bf1a3363193444decd94d>,
        <https://w3id.org/mlentory/mlentory_graph/0dce0f5e7319b6178cd79d5f2163f0e134d0064f4ea4f93e8afeec1e7d78fa8d>,
        <https://w3id.org/mlentory/mlentory_graph/87b927fef88a46248b3b208472aec7bfeb38667386b309f46772e26b40f6affb>,
        <https://w3id.org/mlentory/mlentory_graph/8b17850df3f6918f97a864deac6761f4da511fdf01824bc548e41b5f19be8be9>,
        <https://w3id.org/mlentory/mlentory_graph/974df5e3234c3601080dac4fa96eebf5d19d40df41e9e30cb61084d9fbefea1e>,
        <https://w3id.org/mlentory/mlentory_graph/cd80afb56f05e9ebd40fbd9cf6e6ae1f1295504c991157b8c26b00d097cef292>,
        <https://w3id.org/mlentory/mlentory_graph/df4982af808ead1a57663cc7a83e60059f6a6ae1baf83a270fdf8bdfef11a3de> ;
    schema:license <https://w3id.org/mlentory/mlentory_graph/c76582abee5256ca6e0f130b7b4bb38d54684358fa6802ca36e620ee6c5f00f1> ;
    schema:memoryRequirements "Not available"^^xsd:string ;
    schema:name "see_ai_rt-detr_r18"^^xsd:string ;
    schema:url <https://huggingface.co/goodcasper/see_ai_rt-detr_r18> ;
    ns2:issueTracker <https://huggingface.co/goodcasper/see_ai_rt-detr_r18/discussions> ;
    ns2:readme <https://huggingface.co/goodcasper/see_ai_rt-detr_r18/blob/main/README.md> ;
    ns2:referencePublication "Information not found"^^xsd:string ;
    ns1:evaluatedOn "Information not found"^^xsd:string ;
    ns1:fineTunedFrom <https://w3id.org/mlentory/mlentory_graph/a6b4bd257f7c074d7ae1233e862a380ec00b15c9d14abcc9f96831670d55e4fe> ;
    ns1:mlTask <https://w3id.org/mlentory/mlentory_graph/c6a31d1f7013eb41349bc590b0cc16d51b0a1706fa3f70c1337a8eecf06d2173> ;
    ns1:sharedBy <https://w3id.org/mlentory/mlentory_graph/0fe4886c1d6af8940799e0f31a8afc2d6d5e01a47df25d73d5928461e904426c> ;
    ns1:testedOn "Information not found"^^xsd:string ;
    ns1:trainedOn "Information not found"^^xsd:string .

<https://w3id.org/mlentory/mlentory_graph/49bf7b39c8a2a4cb84ab43bc3c320de6e0c1da1253ebf022a5d0a84737581119> a schema:DefinedTerm ;
    schema:description "Converts image content into textual descriptions or captions."^^xsd:string ;
    schema:name "Image Text to Text"^^xsd:string .

<https://w3id.org/mlentory/mlentory_graph/4acb0244517b271c7719eadb638a9049f7dfa43a14bf6eb119d83c2dbc6d856f> a schema:DefinedTerm ;
    schema:description "Sequence modeling toolkit for training custom models for translation, summarization, and other text generation tasks."^^xsd:string ;
    schema:name "Fairseq"^^xsd:string .

<https://w3id.org/mlentory/mlentory_graph/4e5443728f51b2323bf3a1c4a6a6d8612484cbca0a8b0beeb5fb0258d1df5196> a schema:DefinedTerm ;
    schema:description "Open Neural Network Exchange format that enables interoperability between different ML frameworks."^^xsd:string ;
    schema:name "ONNX"^^xsd:string .

<https://w3id.org/mlentory/mlentory_graph/4eaeba2a8985fdb21e18ca1e967f067a345c0498ed10fc3e5e9ba95e39876cab> a schema:DefinedTerm ;
    schema:description "Categorizes rows in tabular data into predefined classes."^^xsd:string ;
    schema:name "Tabular Classification"^^xsd:string .

<https://w3id.org/mlentory/mlentory_graph/5294100683a6737ae3cdcdb512f4b8459993c27fd8f86917ce5e595178c28f6d> a schema:DefinedTerm ;
    schema:description "Extracts answers from documents based on questions."^^xsd:string ;
    schema:name "Document Question Answering"^^xsd:string .

<https://w3id.org/mlentory/mlentory_graph/55c2ef29f4fc34014e7c41f2439cd686ebcc0bd4d1a02299b7491148b03bd06b> a schema:DefinedTerm ;
    schema:description "Models with custom implementation code beyond standard library functionality."^^xsd:string ;
    schema:name "custom_code"^^xsd:string .

<https://w3id.org/mlentory/mlentory_graph/55f0c4818716a5c86a051b41b27450e6f00f7e81d8a89b0f3bd6928719ce08e4> a schema:DefinedTerm ;
    schema:description "Library for lightweight pipelining in Python, used for saving/loading Python objects and parallelizing loops."^^xsd:string ;
    schema:name "Joblib"^^xsd:string .

<https://w3id.org/mlentory/mlentory_graph/5670ef7e87a4fbee3fa95024561f672fca6cc6a159a62e20ed73b98d267a72bd> a schema:DefinedTerm ;
    schema:description "JavaScript library for running transformer models in browsers and Node.js environments."^^xsd:string ;
    schema:name "Transformers.js"^^xsd:string .

<https://w3id.org/mlentory/mlentory_graph/5931df18dd0fa4a7991df9c03e52fe5074eee570f6c3e7b480947ec85d10c3a1> a schema:DefinedTerm ;
    schema:description "Toolkit for optimizing and deploying deep learning models across Intel hardware."^^xsd:string ;
    schema:name "OpenVINO"^^xsd:string .

<https://w3id.org/mlentory/mlentory_graph/59b663660275b892172a573e140e5eeec1a75e54c1838aea8d6f78d0f6286eba> a schema:DefinedTerm ;
    schema:description "Models that can be fine-tuned using HuggingFace's AutoTrain service without requiring manual code."^^xsd:string ;
    schema:name "AutoTrain Compatible"^^xsd:string .

<https://w3id.org/mlentory/mlentory_graph/5c6c7a9e81be05e126c2ff79f262747bcaa13dce4de3db78679e947f541d5911> a schema:DefinedTerm ;
    schema:description "Industrial-strength NLP library with pre-trained models and support for 65+ languages."^^xsd:string ;
    schema:name "spaCy"^^xsd:string .

<https://w3id.org/mlentory/mlentory_graph/5e9f8dc5efdf686d003f27fc61cf3a0b9e5dbed094499e8e3332f5c535d686f3> a schema:DefinedTerm ;
    schema:description "End-to-end speech processing toolkit covering ASR, TTS, speech translation, and speech enhancement."^^xsd:string ;
    schema:name "ESPnet"^^xsd:string .

<https://w3id.org/mlentory/mlentory_graph/5f8c97c4aaca5a8c6afac1954a68be2dcb40698e64871f37e5fe5dc5849a3aab> a schema:DefinedTerm ;
    schema:description "Measures how similar two sentences are semantically."^^xsd:string ;
    schema:name "Sentence Similarity"^^xsd:string .

<https://w3id.org/mlentory/mlentory_graph/660591e88f00e321049a76543ded76af3005cf92f0a834054184e0177278716c> a schema:DefinedTerm ;
    schema:description "Generates images from textual descriptions or prompts."^^xsd:string ;
    schema:name "Text to Image"^^xsd:string .

<https://w3id.org/mlentory/mlentory_graph/677141c7838f0e2d4464609611f11eaefdce4dfcd623ff6812b98851a78c9c60> a ns1:ML_Model ;
    schema:archivedAt <https://huggingface.co/Biondovi/Qwen2.5-0.5B-Instruct-Gensyn-Swarm-huge_fluffy_barracuda> ;
    schema:conditionsOfAccess "Information not found"^^xsd:string ;
    schema:dateCreated "2025-04-08T21:04:05+00:00"^^xsd:dateTime ;
    schema:dateModified "2025-06-20T00:40:03+00:00"^^xsd:dateTime ;
    schema:datePublished "2025-04-08T21:04:05+00:00"^^xsd:dateTime ;
    schema:description """

# Model Card for Qwen2.5-0.5B-Instruct-Gensyn-Swarm-huge_fluffy_barracuda

This model is a fine-tuned version of [unsloth/Qwen2.5-0.5B-Instruct](https://huggingface.co/unsloth/Qwen2.5-0.5B-Instruct).
It has been trained using [TRL](https://github.com/huggingface/trl).

## Quick start

```python
from transformers import pipeline

question = "If you had a time machine, but could only go to the past or the future once and never return, which would you choose and why?"
generator = pipeline("text-generation", model="Biondovi/Qwen2.5-0.5B-Instruct-Gensyn-Swarm-huge_fluffy_barracuda", device="cuda")
output = generator([{"role": "user", "content": question}], max_new_tokens=128, return_full_text=False)[0]
print(output["generated_text"])
```

## Training procedure

 


This model was trained with GRPO, a method introduced in [DeepSeekMath: Pushing the Limits of Mathematical Reasoning in Open Language Models](https://huggingface.co/papers/2402.03300).

### Framework versions

- TRL: 0.18.2
- Transformers: 4.52.4
- Pytorch: 2.7.1
- Datasets: 3.6.0
- Tokenizers: 0.21.1

## Citations

Cite GRPO as:

```bibtex
@article{zhihong2024deepseekmath,
    title        = {{DeepSeekMath: Pushing the Limits of Mathematical Reasoning in Open Language Models}},
    author       = {Zhihong Shao and Peiyi Wang and Qihao Zhu and Runxin Xu and Junxiao Song and Mingchuan Zhang and Y. K. Li and Y. Wu and Daya Guo},
    year         = 2024,
    eprint       = {arXiv:2402.03300},
}

```

Cite TRL as:
    
```bibtex
@misc{vonwerra2022trl,
	title        = {{TRL: Transformer Reinforcement Learning}},
	author       = {Leandro von Werra and Younes Belkada and Lewis Tunstall and Edward Beeching and Tristan Thrush and Nathan Lambert and Shengyi Huang and Kashif Rasul and Quentin Gallou{\\'e}dec},
	year         = 2020,
	journal      = {GitHub repository},
	publisher    = {GitHub},
	howpublished = {\\url{https://github.com/huggingface/trl}}
}
```"""^^xsd:string ;
    schema:discussionUrl <https://huggingface.co/Biondovi/Qwen2.5-0.5B-Instruct-Gensyn-Swarm-huge_fluffy_barracuda/discussions> ;
    schema:identifier "https://huggingface.co/Biondovi/Qwen2.5-0.5B-Instruct-Gensyn-Swarm-huge_fluffy_barracuda"^^xsd:string ;
    schema:inLanguage "Information not found"^^xsd:string ;
    schema:keywords <https://w3id.org/mlentory/mlentory_graph/04151ef09fe56a2be18a7d842066720d6e7cee10ed5bf1a3363193444decd94d>,
        <https://w3id.org/mlentory/mlentory_graph/0a51816a4973430cbbb79302d54b3c75493751bc40079439c5c7a4e592e74514>,
        <https://w3id.org/mlentory/mlentory_graph/0dce0f5e7319b6178cd79d5f2163f0e134d0064f4ea4f93e8afeec1e7d78fa8d>,
        <https://w3id.org/mlentory/mlentory_graph/28f6fc79227e13d54a24f63fe2a8971b6f281ac3ca778d4303f84baacbc18a18>,
        <https://w3id.org/mlentory/mlentory_graph/29901b0ecce864a67f7734a040b22f9867d7435fdb731b76633a212ffab331f4>,
        <https://w3id.org/mlentory/mlentory_graph/61cce84de930f0da8c78ddef3203a2afac70cf5e46684f0407180738cd821965>,
        <https://w3id.org/mlentory/mlentory_graph/789df8584c437cfcddc5b2fff51cdef26423ea8d53635a0100a83cd8490b5cb6>,
        <https://w3id.org/mlentory/mlentory_graph/79cf083846a8329d2912fcd7f375233c37a54917af291bb945f0b58bc735b8ad>,
        <https://w3id.org/mlentory/mlentory_graph/81c4f52fcccf6ef0d25453aedb7cebe30c7034e3b2fa752246d0e43da889a0e1>,
        <https://w3id.org/mlentory/mlentory_graph/87b927fef88a46248b3b208472aec7bfeb38667386b309f46772e26b40f6affb>,
        <https://w3id.org/mlentory/mlentory_graph/a4cf9836ab3780436e61a37fe48729edb682b8e0e1c3f9363cb10061770a7197>,
        <https://w3id.org/mlentory/mlentory_graph/c21ccd276af5ae1828bea64af6da9742c6ef229f7b0571987909160419d90560>,
        <https://w3id.org/mlentory/mlentory_graph/df4982af808ead1a57663cc7a83e60059f6a6ae1baf83a270fdf8bdfef11a3de>,
        <https://w3id.org/mlentory/mlentory_graph/f59cf55f3a86acf0bcfc020eac552a72c13f1212154211a7bf30504548661f8d> ;
    schema:license "Information not found"^^xsd:string ;
    schema:memoryRequirements "Not available"^^xsd:string ;
    schema:name "Qwen2.5-0.5B-Instruct-Gensyn-Swarm-huge_fluffy_barracuda"^^xsd:string ;
    schema:url <https://huggingface.co/Biondovi/Qwen2.5-0.5B-Instruct-Gensyn-Swarm-huge_fluffy_barracuda> ;
    ns2:issueTracker <https://huggingface.co/Biondovi/Qwen2.5-0.5B-Instruct-Gensyn-Swarm-huge_fluffy_barracuda/discussions> ;
    ns2:readme <https://huggingface.co/Biondovi/Qwen2.5-0.5B-Instruct-Gensyn-Swarm-huge_fluffy_barracuda/blob/main/README.md> ;
    ns2:referencePublication <https://w3id.org/mlentory/mlentory_graph/57ac8dd147b53050bf4aa8cb4dbc16ad91197f7662c02666466eb8e9888d87a7> ;
    ns1:evaluatedOn "Information not found"^^xsd:string ;
    ns1:fineTunedFrom <https://w3id.org/mlentory/mlentory_graph/4d2ce24e500528b55a21cac8de96cce215994b6ca25877254bca1857cd8b9e55> ;
    ns1:mlTask <https://w3id.org/mlentory/mlentory_graph/6925cb204ab4d5280c948ac7e23dd8f7b48d1de433cf9edc5c30a8d87ce3b317> ;
    ns1:sharedBy <https://w3id.org/mlentory/mlentory_graph/8ef75d117a8dc210ae12e742be36678d97d2ebfb8e582cad2ac1cf6f7d8e9c1d> ;
    ns1:testedOn "Information not found"^^xsd:string ;
    ns1:trainedOn "Information not found"^^xsd:string .

<https://w3id.org/mlentory/mlentory_graph/6803a9142550ca466078b0794746397f37034f277ce6f45bb7f252be171ab407> a schema:DefinedTerm ;
    schema:description "Creates images without specific text prompts or conditions."^^xsd:string ;
    schema:name "Unconditional Image Generation"^^xsd:string .

<https://w3id.org/mlentory/mlentory_graph/6839f153ace4a5cfe1e9a1cdb43c1bfc2260f4c85be0608af5ec84a75a205d2c> a schema:DefinedTerm ;
    schema:description "Converts written text into spoken audio."^^xsd:string ;
    schema:name "Text to Speech"^^xsd:string .

<https://w3id.org/mlentory/mlentory_graph/6b72a43d7396497fe9733cb91a9e688db073b7c1c583e2c5fca339bd414a4dac> a schema:DefinedTerm ;
    schema:description "General label indicating the model or dataset has been categorized with specific keywords for discoverability."^^xsd:string ;
    schema:name "tags"^^xsd:string .

<https://w3id.org/mlentory/mlentory_graph/6b75cb265aea0eff37651595203eec38a2a621d81df99e4cfcd5f30cef590384> a schema:DefinedTerm ;
    schema:description "Toolkit for building, training, and fine-tuning GPU-accelerated conversational AI models."^^xsd:string ;
    schema:name "NeMo"^^xsd:string .

<https://w3id.org/mlentory/mlentory_graph/6bdae8c542a61819acfd0767eb5e55cafba29955aaefd1261c204618a4d3a487> a schema:DefinedTerm ;
    schema:description "Models with published evaluation metrics, benchmarks, or test results available for review."^^xsd:string ;
    schema:name "Eval Results"^^xsd:string .

<https://w3id.org/mlentory/mlentory_graph/6fa5b295a0420d9a3cc819e672ebdd61720c48761f8c2960d28ff7f7655875be> a schema:DefinedTerm ;
    schema:description "Provides answers to questions based on given context."^^xsd:string ;
    schema:name "Question Answering"^^xsd:string .

<https://w3id.org/mlentory/mlentory_graph/6fd4d85e3416654bf33d9c5f3803b3e9900ce78a6309e4e6a84b2499ad4b7981> a schema:DefinedTerm ;
    schema:description "Simple framework for state-of-the-art NLP supporting tasks like named entity recognition and part-of-speech tagging."^^xsd:string ;
    schema:name "Flair"^^xsd:string .

<https://w3id.org/mlentory/mlentory_graph/746e796ec31ad9ad2b517555a4e91b2e3dfff187021fd0255aae50476624430d> a schema:DefinedTerm ;
    schema:description "Extracts meaningful features from input data for downstream tasks."^^xsd:string ;
    schema:name "Feature Extraction"^^xsd:string .

<https://w3id.org/mlentory/mlentory_graph/771e059c7890ae196a3227d36771c27f019638d33a819ca19bef2ae302b92b44> a schema:DefinedTerm ;
    schema:description "PyTorch-based audio source separation toolkit for researchers."^^xsd:string ;
    schema:name "Asteroid"^^xsd:string .

<https://w3id.org/mlentory/mlentory_graph/79765e8db24271bde7a56b897b0b6c389d5be642563652aae56b6253290a801e> a schema:DefinedTerm ;
    schema:description "Classifies content into categories not seen during training."^^xsd:string ;
    schema:name "Zero Shot Classification"^^xsd:string .

<https://w3id.org/mlentory/mlentory_graph/7daea98679eae3b5819f476833cada39b566629edb49ee1f55db0016e8ecf118> a schema:DefinedTerm ;
    schema:description "Python NLP library for accurate multilingual text analysis, including tokenization, POS tagging, and dependency parsing."^^xsd:string ;
    schema:name "Stanza"^^xsd:string .

<https://w3id.org/mlentory/mlentory_graph/7e10a0f7380ddd069e6fbbf352beba979447b463fdca98bf36882dc2a3161628> a ns1:ML_Model ;
    schema:archivedAt <https://huggingface.co/Wiliambill/Qwen2.5-0.5B-Instruct-Gensyn-Swarm-scavenging_sniffing_lizard> ;
    schema:conditionsOfAccess "Information not found"^^xsd:string ;
    schema:dateCreated "2025-04-09T08:28:41+00:00"^^xsd:dateTime ;
    schema:dateModified "2025-06-20T00:40:16+00:00"^^xsd:dateTime ;
    schema:datePublished "2025-04-09T08:28:41+00:00"^^xsd:dateTime ;
    schema:description """

# Model Card for Qwen2.5-0.5B-Instruct-Gensyn-Swarm-scavenging_sniffing_lizard

This model is a fine-tuned version of [unsloth/Qwen2.5-0.5B-Instruct](https://huggingface.co/unsloth/Qwen2.5-0.5B-Instruct).
It has been trained using [TRL](https://github.com/huggingface/trl).

## Quick start

```python
from transformers import pipeline

question = "If you had a time machine, but could only go to the past or the future once and never return, which would you choose and why?"
generator = pipeline("text-generation", model="Wiliambill/Qwen2.5-0.5B-Instruct-Gensyn-Swarm-scavenging_sniffing_lizard", device="cuda")
output = generator([{"role": "user", "content": question}], max_new_tokens=128, return_full_text=False)[0]
print(output["generated_text"])
```

## Training procedure

 


This model was trained with GRPO, a method introduced in [DeepSeekMath: Pushing the Limits of Mathematical Reasoning in Open Language Models](https://huggingface.co/papers/2402.03300).

### Framework versions

- TRL: 0.18.2
- Transformers: 4.52.4
- Pytorch: 2.7.1
- Datasets: 3.6.0
- Tokenizers: 0.21.1

## Citations

Cite GRPO as:

```bibtex
@article{zhihong2024deepseekmath,
    title        = {{DeepSeekMath: Pushing the Limits of Mathematical Reasoning in Open Language Models}},
    author       = {Zhihong Shao and Peiyi Wang and Qihao Zhu and Runxin Xu and Junxiao Song and Mingchuan Zhang and Y. K. Li and Y. Wu and Daya Guo},
    year         = 2024,
    eprint       = {arXiv:2402.03300},
}

```

Cite TRL as:
    
```bibtex
@misc{vonwerra2022trl,
	title        = {{TRL: Transformer Reinforcement Learning}},
	author       = {Leandro von Werra and Younes Belkada and Lewis Tunstall and Edward Beeching and Tristan Thrush and Nathan Lambert and Shengyi Huang and Kashif Rasul and Quentin Gallou{\\'e}dec},
	year         = 2020,
	journal      = {GitHub repository},
	publisher    = {GitHub},
	howpublished = {\\url{https://github.com/huggingface/trl}}
}
```"""^^xsd:string ;
    schema:discussionUrl <https://huggingface.co/Wiliambill/Qwen2.5-0.5B-Instruct-Gensyn-Swarm-scavenging_sniffing_lizard/discussions> ;
    schema:identifier "https://huggingface.co/Wiliambill/Qwen2.5-0.5B-Instruct-Gensyn-Swarm-scavenging_sniffing_lizard"^^xsd:string ;
    schema:inLanguage "Information not found"^^xsd:string ;
    schema:keywords <https://w3id.org/mlentory/mlentory_graph/04151ef09fe56a2be18a7d842066720d6e7cee10ed5bf1a3363193444decd94d>,
        <https://w3id.org/mlentory/mlentory_graph/0dce0f5e7319b6178cd79d5f2163f0e134d0064f4ea4f93e8afeec1e7d78fa8d>,
        <https://w3id.org/mlentory/mlentory_graph/28f6fc79227e13d54a24f63fe2a8971b6f281ac3ca778d4303f84baacbc18a18>,
        <https://w3id.org/mlentory/mlentory_graph/29901b0ecce864a67f7734a040b22f9867d7435fdb731b76633a212ffab331f4>,
        <https://w3id.org/mlentory/mlentory_graph/34c1379d8dda014b2a509839fe7e8a7c6469730b7f9684dd37b425e4401f273c>,
        <https://w3id.org/mlentory/mlentory_graph/61cce84de930f0da8c78ddef3203a2afac70cf5e46684f0407180738cd821965>,
        <https://w3id.org/mlentory/mlentory_graph/789df8584c437cfcddc5b2fff51cdef26423ea8d53635a0100a83cd8490b5cb6>,
        <https://w3id.org/mlentory/mlentory_graph/79cf083846a8329d2912fcd7f375233c37a54917af291bb945f0b58bc735b8ad>,
        <https://w3id.org/mlentory/mlentory_graph/81c4f52fcccf6ef0d25453aedb7cebe30c7034e3b2fa752246d0e43da889a0e1>,
        <https://w3id.org/mlentory/mlentory_graph/87b927fef88a46248b3b208472aec7bfeb38667386b309f46772e26b40f6affb>,
        <https://w3id.org/mlentory/mlentory_graph/a4cf9836ab3780436e61a37fe48729edb682b8e0e1c3f9363cb10061770a7197>,
        <https://w3id.org/mlentory/mlentory_graph/c21ccd276af5ae1828bea64af6da9742c6ef229f7b0571987909160419d90560>,
        <https://w3id.org/mlentory/mlentory_graph/df4982af808ead1a57663cc7a83e60059f6a6ae1baf83a270fdf8bdfef11a3de>,
        <https://w3id.org/mlentory/mlentory_graph/f59cf55f3a86acf0bcfc020eac552a72c13f1212154211a7bf30504548661f8d> ;
    schema:license "Information not found"^^xsd:string ;
    schema:memoryRequirements "Not available"^^xsd:string ;
    schema:name "Qwen2.5-0.5B-Instruct-Gensyn-Swarm-scavenging_sniffing_lizard"^^xsd:string ;
    schema:url <https://huggingface.co/Wiliambill/Qwen2.5-0.5B-Instruct-Gensyn-Swarm-scavenging_sniffing_lizard> ;
    ns2:issueTracker <https://huggingface.co/Wiliambill/Qwen2.5-0.5B-Instruct-Gensyn-Swarm-scavenging_sniffing_lizard/discussions> ;
    ns2:readme <https://huggingface.co/Wiliambill/Qwen2.5-0.5B-Instruct-Gensyn-Swarm-scavenging_sniffing_lizard/blob/main/README.md> ;
    ns2:referencePublication <https://w3id.org/mlentory/mlentory_graph/57ac8dd147b53050bf4aa8cb4dbc16ad91197f7662c02666466eb8e9888d87a7> ;
    ns1:evaluatedOn "Information not found"^^xsd:string ;
    ns1:fineTunedFrom <https://w3id.org/mlentory/mlentory_graph/4d2ce24e500528b55a21cac8de96cce215994b6ca25877254bca1857cd8b9e55> ;
    ns1:mlTask <https://w3id.org/mlentory/mlentory_graph/6925cb204ab4d5280c948ac7e23dd8f7b48d1de433cf9edc5c30a8d87ce3b317> ;
    ns1:sharedBy <https://w3id.org/mlentory/mlentory_graph/3e864e5a8c8c21cc38e295a520d9d7e521b90b5852131c5c2504da726f75ece6> ;
    ns1:testedOn "Information not found"^^xsd:string ;
    ns1:trainedOn "Information not found"^^xsd:string .

<https://w3id.org/mlentory/mlentory_graph/7f54d24f6105f34a30d4a46010cdee62b6681914e55b54dfb140210acdb18759> a ns1:ML_Model ;
    schema:archivedAt <https://huggingface.co/Armijo/Qwen2.5-0.5B-Instruct-Gensyn-Swarm-small_lithe_ocelot> ;
    schema:conditionsOfAccess "Information not found"^^xsd:string ;
    schema:dateCreated "2025-04-08T23:48:53+00:00"^^xsd:dateTime ;
    schema:dateModified "2025-06-20T00:39:27+00:00"^^xsd:dateTime ;
    schema:datePublished "2025-04-08T23:48:53+00:00"^^xsd:dateTime ;
    schema:description """

# Model Card for Qwen2.5-0.5B-Instruct-Gensyn-Swarm-small_lithe_ocelot

This model is a fine-tuned version of [unsloth/Qwen2.5-0.5B-Instruct](https://huggingface.co/unsloth/Qwen2.5-0.5B-Instruct).
It has been trained using [TRL](https://github.com/huggingface/trl).

## Quick start

```python
from transformers import pipeline

question = "If you had a time machine, but could only go to the past or the future once and never return, which would you choose and why?"
generator = pipeline("text-generation", model="Armijo/Qwen2.5-0.5B-Instruct-Gensyn-Swarm-small_lithe_ocelot", device="cuda")
output = generator([{"role": "user", "content": question}], max_new_tokens=128, return_full_text=False)[0]
print(output["generated_text"])
```

## Training procedure

 


This model was trained with GRPO, a method introduced in [DeepSeekMath: Pushing the Limits of Mathematical Reasoning in Open Language Models](https://huggingface.co/papers/2402.03300).

### Framework versions

- TRL: 0.18.2
- Transformers: 4.52.4
- Pytorch: 2.7.1
- Datasets: 3.6.0
- Tokenizers: 0.21.1

## Citations

Cite GRPO as:

```bibtex
@article{zhihong2024deepseekmath,
    title        = {{DeepSeekMath: Pushing the Limits of Mathematical Reasoning in Open Language Models}},
    author       = {Zhihong Shao and Peiyi Wang and Qihao Zhu and Runxin Xu and Junxiao Song and Mingchuan Zhang and Y. K. Li and Y. Wu and Daya Guo},
    year         = 2024,
    eprint       = {arXiv:2402.03300},
}

```

Cite TRL as:
    
```bibtex
@misc{vonwerra2022trl,
	title        = {{TRL: Transformer Reinforcement Learning}},
	author       = {Leandro von Werra and Younes Belkada and Lewis Tunstall and Edward Beeching and Tristan Thrush and Nathan Lambert and Shengyi Huang and Kashif Rasul and Quentin Gallou{\\'e}dec},
	year         = 2020,
	journal      = {GitHub repository},
	publisher    = {GitHub},
	howpublished = {\\url{https://github.com/huggingface/trl}}
}
```"""^^xsd:string ;
    schema:discussionUrl <https://huggingface.co/Armijo/Qwen2.5-0.5B-Instruct-Gensyn-Swarm-small_lithe_ocelot/discussions> ;
    schema:identifier "https://huggingface.co/Armijo/Qwen2.5-0.5B-Instruct-Gensyn-Swarm-small_lithe_ocelot"^^xsd:string ;
    schema:inLanguage "Information not found"^^xsd:string ;
    schema:keywords <https://w3id.org/mlentory/mlentory_graph/04151ef09fe56a2be18a7d842066720d6e7cee10ed5bf1a3363193444decd94d>,
        <https://w3id.org/mlentory/mlentory_graph/0dce0f5e7319b6178cd79d5f2163f0e134d0064f4ea4f93e8afeec1e7d78fa8d>,
        <https://w3id.org/mlentory/mlentory_graph/28f6fc79227e13d54a24f63fe2a8971b6f281ac3ca778d4303f84baacbc18a18>,
        <https://w3id.org/mlentory/mlentory_graph/29901b0ecce864a67f7734a040b22f9867d7435fdb731b76633a212ffab331f4>,
        <https://w3id.org/mlentory/mlentory_graph/31ecbf7f13864b695a4c988570ba98cbd834f15dab3fdbc890692e395b618f05>,
        <https://w3id.org/mlentory/mlentory_graph/61cce84de930f0da8c78ddef3203a2afac70cf5e46684f0407180738cd821965>,
        <https://w3id.org/mlentory/mlentory_graph/789df8584c437cfcddc5b2fff51cdef26423ea8d53635a0100a83cd8490b5cb6>,
        <https://w3id.org/mlentory/mlentory_graph/79cf083846a8329d2912fcd7f375233c37a54917af291bb945f0b58bc735b8ad>,
        <https://w3id.org/mlentory/mlentory_graph/81c4f52fcccf6ef0d25453aedb7cebe30c7034e3b2fa752246d0e43da889a0e1>,
        <https://w3id.org/mlentory/mlentory_graph/87b927fef88a46248b3b208472aec7bfeb38667386b309f46772e26b40f6affb>,
        <https://w3id.org/mlentory/mlentory_graph/a4cf9836ab3780436e61a37fe48729edb682b8e0e1c3f9363cb10061770a7197>,
        <https://w3id.org/mlentory/mlentory_graph/c21ccd276af5ae1828bea64af6da9742c6ef229f7b0571987909160419d90560>,
        <https://w3id.org/mlentory/mlentory_graph/df4982af808ead1a57663cc7a83e60059f6a6ae1baf83a270fdf8bdfef11a3de>,
        <https://w3id.org/mlentory/mlentory_graph/f59cf55f3a86acf0bcfc020eac552a72c13f1212154211a7bf30504548661f8d> ;
    schema:license "Information not found"^^xsd:string ;
    schema:memoryRequirements "Not available"^^xsd:string ;
    schema:name "Qwen2.5-0.5B-Instruct-Gensyn-Swarm-small_lithe_ocelot"^^xsd:string ;
    schema:url <https://huggingface.co/Armijo/Qwen2.5-0.5B-Instruct-Gensyn-Swarm-small_lithe_ocelot> ;
    ns2:issueTracker <https://huggingface.co/Armijo/Qwen2.5-0.5B-Instruct-Gensyn-Swarm-small_lithe_ocelot/discussions> ;
    ns2:readme <https://huggingface.co/Armijo/Qwen2.5-0.5B-Instruct-Gensyn-Swarm-small_lithe_ocelot/blob/main/README.md> ;
    ns2:referencePublication <https://w3id.org/mlentory/mlentory_graph/57ac8dd147b53050bf4aa8cb4dbc16ad91197f7662c02666466eb8e9888d87a7> ;
    ns1:evaluatedOn "Information not found"^^xsd:string ;
    ns1:fineTunedFrom <https://w3id.org/mlentory/mlentory_graph/4d2ce24e500528b55a21cac8de96cce215994b6ca25877254bca1857cd8b9e55> ;
    ns1:mlTask <https://w3id.org/mlentory/mlentory_graph/6925cb204ab4d5280c948ac7e23dd8f7b48d1de433cf9edc5c30a8d87ce3b317> ;
    ns1:sharedBy <https://w3id.org/mlentory/mlentory_graph/2534beaf4101b2fd3b1d3f00d3dd5637829b105e8535323bf257e5dfd4aec3a6> ;
    ns1:testedOn "Information not found"^^xsd:string ;
    ns1:trainedOn "Information not found"^^xsd:string .

<https://w3id.org/mlentory/mlentory_graph/8022b9df0c401fa9475fbcf4411dcd4deb4cb9ee388b3cf615f765aa60684202> a ns1:ML_Model ;
    schema:archivedAt <https://huggingface.co/nymphe/Qwen2.5-0.5B-Instruct-Gensyn-Swarm-agile_pawing_lobster> ;
    schema:conditionsOfAccess "Information not found"^^xsd:string ;
    schema:dateCreated "2025-04-09T07:13:25+00:00"^^xsd:dateTime ;
    schema:dateModified "2025-06-20T00:41:05+00:00"^^xsd:dateTime ;
    schema:datePublished "2025-04-09T07:13:25+00:00"^^xsd:dateTime ;
    schema:description """

# Model Card for Qwen2.5-0.5B-Instruct-Gensyn-Swarm-agile_pawing_lobster

This model is a fine-tuned version of [unsloth/Qwen2.5-0.5B-Instruct](https://huggingface.co/unsloth/Qwen2.5-0.5B-Instruct).
It has been trained using [TRL](https://github.com/huggingface/trl).

## Quick start

```python
from transformers import pipeline

question = "If you had a time machine, but could only go to the past or the future once and never return, which would you choose and why?"
generator = pipeline("text-generation", model="nymphe/Qwen2.5-0.5B-Instruct-Gensyn-Swarm-agile_pawing_lobster", device="cuda")
output = generator([{"role": "user", "content": question}], max_new_tokens=128, return_full_text=False)[0]
print(output["generated_text"])
```

## Training procedure

 


This model was trained with GRPO, a method introduced in [DeepSeekMath: Pushing the Limits of Mathematical Reasoning in Open Language Models](https://huggingface.co/papers/2402.03300).

### Framework versions

- TRL: 0.18.2
- Transformers: 4.52.4
- Pytorch: 2.7.1
- Datasets: 3.6.0
- Tokenizers: 0.21.1

## Citations

Cite GRPO as:

```bibtex
@article{zhihong2024deepseekmath,
    title        = {{DeepSeekMath: Pushing the Limits of Mathematical Reasoning in Open Language Models}},
    author       = {Zhihong Shao and Peiyi Wang and Qihao Zhu and Runxin Xu and Junxiao Song and Mingchuan Zhang and Y. K. Li and Y. Wu and Daya Guo},
    year         = 2024,
    eprint       = {arXiv:2402.03300},
}

```

Cite TRL as:
    
```bibtex
@misc{vonwerra2022trl,
	title        = {{TRL: Transformer Reinforcement Learning}},
	author       = {Leandro von Werra and Younes Belkada and Lewis Tunstall and Edward Beeching and Tristan Thrush and Nathan Lambert and Shengyi Huang and Kashif Rasul and Quentin Gallou{\\'e}dec},
	year         = 2020,
	journal      = {GitHub repository},
	publisher    = {GitHub},
	howpublished = {\\url{https://github.com/huggingface/trl}}
}
```"""^^xsd:string ;
    schema:discussionUrl <https://huggingface.co/nymphe/Qwen2.5-0.5B-Instruct-Gensyn-Swarm-agile_pawing_lobster/discussions> ;
    schema:identifier "https://huggingface.co/nymphe/Qwen2.5-0.5B-Instruct-Gensyn-Swarm-agile_pawing_lobster"^^xsd:string ;
    schema:inLanguage "Information not found"^^xsd:string ;
    schema:keywords <https://w3id.org/mlentory/mlentory_graph/04151ef09fe56a2be18a7d842066720d6e7cee10ed5bf1a3363193444decd94d>,
        <https://w3id.org/mlentory/mlentory_graph/0dce0f5e7319b6178cd79d5f2163f0e134d0064f4ea4f93e8afeec1e7d78fa8d>,
        <https://w3id.org/mlentory/mlentory_graph/28f6fc79227e13d54a24f63fe2a8971b6f281ac3ca778d4303f84baacbc18a18>,
        <https://w3id.org/mlentory/mlentory_graph/29901b0ecce864a67f7734a040b22f9867d7435fdb731b76633a212ffab331f4>,
        <https://w3id.org/mlentory/mlentory_graph/61cce84de930f0da8c78ddef3203a2afac70cf5e46684f0407180738cd821965>,
        <https://w3id.org/mlentory/mlentory_graph/789df8584c437cfcddc5b2fff51cdef26423ea8d53635a0100a83cd8490b5cb6>,
        <https://w3id.org/mlentory/mlentory_graph/79cf083846a8329d2912fcd7f375233c37a54917af291bb945f0b58bc735b8ad>,
        <https://w3id.org/mlentory/mlentory_graph/81c4f52fcccf6ef0d25453aedb7cebe30c7034e3b2fa752246d0e43da889a0e1>,
        <https://w3id.org/mlentory/mlentory_graph/87b927fef88a46248b3b208472aec7bfeb38667386b309f46772e26b40f6affb>,
        <https://w3id.org/mlentory/mlentory_graph/a026994daef9aeefcbd15022017302a1255a44ff8dd0c3d7d4fa63ab770ca0d1>,
        <https://w3id.org/mlentory/mlentory_graph/a4cf9836ab3780436e61a37fe48729edb682b8e0e1c3f9363cb10061770a7197>,
        <https://w3id.org/mlentory/mlentory_graph/c21ccd276af5ae1828bea64af6da9742c6ef229f7b0571987909160419d90560>,
        <https://w3id.org/mlentory/mlentory_graph/df4982af808ead1a57663cc7a83e60059f6a6ae1baf83a270fdf8bdfef11a3de>,
        <https://w3id.org/mlentory/mlentory_graph/f59cf55f3a86acf0bcfc020eac552a72c13f1212154211a7bf30504548661f8d> ;
    schema:license "Information not found"^^xsd:string ;
    schema:memoryRequirements "Not available"^^xsd:string ;
    schema:name "Qwen2.5-0.5B-Instruct-Gensyn-Swarm-agile_pawing_lobster"^^xsd:string ;
    schema:url <https://huggingface.co/nymphe/Qwen2.5-0.5B-Instruct-Gensyn-Swarm-agile_pawing_lobster> ;
    ns2:issueTracker <https://huggingface.co/nymphe/Qwen2.5-0.5B-Instruct-Gensyn-Swarm-agile_pawing_lobster/discussions> ;
    ns2:readme <https://huggingface.co/nymphe/Qwen2.5-0.5B-Instruct-Gensyn-Swarm-agile_pawing_lobster/blob/main/README.md> ;
    ns2:referencePublication <https://w3id.org/mlentory/mlentory_graph/57ac8dd147b53050bf4aa8cb4dbc16ad91197f7662c02666466eb8e9888d87a7> ;
    ns1:evaluatedOn "Information not found"^^xsd:string ;
    ns1:fineTunedFrom <https://w3id.org/mlentory/mlentory_graph/4d2ce24e500528b55a21cac8de96cce215994b6ca25877254bca1857cd8b9e55> ;
    ns1:mlTask <https://w3id.org/mlentory/mlentory_graph/6925cb204ab4d5280c948ac7e23dd8f7b48d1de433cf9edc5c30a8d87ce3b317> ;
    ns1:sharedBy <https://w3id.org/mlentory/mlentory_graph/d55bcd6c258df6a392d65ed4980d9d8db579b01fd74d5014ac5577b1b1eac883> ;
    ns1:testedOn "Information not found"^^xsd:string ;
    ns1:trainedOn "Information not found"^^xsd:string .

<https://w3id.org/mlentory/mlentory_graph/85b6833a0e3a566c8de87c0f42b57ec97f67e03180245edb416823e240ee11d1> a schema:DefinedTerm ;
    schema:description "Array framework for machine learning on Apple silicon, designed for efficiency and ease of use."^^xsd:string ;
    schema:name "MLX"^^xsd:string .

<https://w3id.org/mlentory/mlentory_graph/85f0e69a70ce025a206d6ddbf78d989a3cabbdae215f2045df9b67b21a9d6780> a schema:DefinedTerm ;
    schema:description "Categorizes text documents into predefined classes."^^xsd:string ;
    schema:name "Text Classification"^^xsd:string .

<https://w3id.org/mlentory/mlentory_graph/86f52aa6369c70ec009cd27198c0d2e52782b473507c01a7426d4c1bf4185e05> a schema:DefinedTerm ;
    schema:description "Optimized backend for deploying and serving text embedding models with high performance."^^xsd:string ;
    schema:name "text-embedding-inference"^^xsd:string .

<https://w3id.org/mlentory/mlentory_graph/8e3ef3eca594ad7c00e178d3b96e2c833479b0583e72fe3cd86be8c59389bd97> a ns1:ML_Model ;
    schema:archivedAt <https://huggingface.co/Oberhaus/Qwen2.5-0.5B-Instruct-Gensyn-Swarm-rabid_prowling_jay> ;
    schema:conditionsOfAccess "Information not found"^^xsd:string ;
    schema:dateCreated "2025-04-08T23:19:11+00:00"^^xsd:dateTime ;
    schema:dateModified "2025-06-20T00:40:28+00:00"^^xsd:dateTime ;
    schema:datePublished "2025-04-08T23:19:11+00:00"^^xsd:dateTime ;
    schema:description """

# Model Card for Qwen2.5-0.5B-Instruct-Gensyn-Swarm-rabid_prowling_jay

This model is a fine-tuned version of [unsloth/Qwen2.5-0.5B-Instruct](https://huggingface.co/unsloth/Qwen2.5-0.5B-Instruct).
It has been trained using [TRL](https://github.com/huggingface/trl).

## Quick start

```python
from transformers import pipeline

question = "If you had a time machine, but could only go to the past or the future once and never return, which would you choose and why?"
generator = pipeline("text-generation", model="Oberhaus/Qwen2.5-0.5B-Instruct-Gensyn-Swarm-rabid_prowling_jay", device="cuda")
output = generator([{"role": "user", "content": question}], max_new_tokens=128, return_full_text=False)[0]
print(output["generated_text"])
```

## Training procedure

 


This model was trained with GRPO, a method introduced in [DeepSeekMath: Pushing the Limits of Mathematical Reasoning in Open Language Models](https://huggingface.co/papers/2402.03300).

### Framework versions

- TRL: 0.18.2
- Transformers: 4.52.4
- Pytorch: 2.7.1
- Datasets: 3.6.0
- Tokenizers: 0.21.1

## Citations

Cite GRPO as:

```bibtex
@article{zhihong2024deepseekmath,
    title        = {{DeepSeekMath: Pushing the Limits of Mathematical Reasoning in Open Language Models}},
    author       = {Zhihong Shao and Peiyi Wang and Qihao Zhu and Runxin Xu and Junxiao Song and Mingchuan Zhang and Y. K. Li and Y. Wu and Daya Guo},
    year         = 2024,
    eprint       = {arXiv:2402.03300},
}

```

Cite TRL as:
    
```bibtex
@misc{vonwerra2022trl,
	title        = {{TRL: Transformer Reinforcement Learning}},
	author       = {Leandro von Werra and Younes Belkada and Lewis Tunstall and Edward Beeching and Tristan Thrush and Nathan Lambert and Shengyi Huang and Kashif Rasul and Quentin Gallou{\\'e}dec},
	year         = 2020,
	journal      = {GitHub repository},
	publisher    = {GitHub},
	howpublished = {\\url{https://github.com/huggingface/trl}}
}
```"""^^xsd:string ;
    schema:discussionUrl <https://huggingface.co/Oberhaus/Qwen2.5-0.5B-Instruct-Gensyn-Swarm-rabid_prowling_jay/discussions> ;
    schema:identifier "https://huggingface.co/Oberhaus/Qwen2.5-0.5B-Instruct-Gensyn-Swarm-rabid_prowling_jay"^^xsd:string ;
    schema:inLanguage "Information not found"^^xsd:string ;
    schema:keywords <https://w3id.org/mlentory/mlentory_graph/04151ef09fe56a2be18a7d842066720d6e7cee10ed5bf1a3363193444decd94d>,
        <https://w3id.org/mlentory/mlentory_graph/0dce0f5e7319b6178cd79d5f2163f0e134d0064f4ea4f93e8afeec1e7d78fa8d>,
        <https://w3id.org/mlentory/mlentory_graph/28f6fc79227e13d54a24f63fe2a8971b6f281ac3ca778d4303f84baacbc18a18>,
        <https://w3id.org/mlentory/mlentory_graph/29901b0ecce864a67f7734a040b22f9867d7435fdb731b76633a212ffab331f4>,
        <https://w3id.org/mlentory/mlentory_graph/61cce84de930f0da8c78ddef3203a2afac70cf5e46684f0407180738cd821965>,
        <https://w3id.org/mlentory/mlentory_graph/789df8584c437cfcddc5b2fff51cdef26423ea8d53635a0100a83cd8490b5cb6>,
        <https://w3id.org/mlentory/mlentory_graph/79cf083846a8329d2912fcd7f375233c37a54917af291bb945f0b58bc735b8ad>,
        <https://w3id.org/mlentory/mlentory_graph/81c4f52fcccf6ef0d25453aedb7cebe30c7034e3b2fa752246d0e43da889a0e1>,
        <https://w3id.org/mlentory/mlentory_graph/87b927fef88a46248b3b208472aec7bfeb38667386b309f46772e26b40f6affb>,
        <https://w3id.org/mlentory/mlentory_graph/a245f998950c99a9208b9f67dc4acdedb6db4ee02c9ff48ca6bec03c788b7e11>,
        <https://w3id.org/mlentory/mlentory_graph/a4cf9836ab3780436e61a37fe48729edb682b8e0e1c3f9363cb10061770a7197>,
        <https://w3id.org/mlentory/mlentory_graph/c21ccd276af5ae1828bea64af6da9742c6ef229f7b0571987909160419d90560>,
        <https://w3id.org/mlentory/mlentory_graph/df4982af808ead1a57663cc7a83e60059f6a6ae1baf83a270fdf8bdfef11a3de>,
        <https://w3id.org/mlentory/mlentory_graph/f59cf55f3a86acf0bcfc020eac552a72c13f1212154211a7bf30504548661f8d> ;
    schema:license "Information not found"^^xsd:string ;
    schema:memoryRequirements "Not available"^^xsd:string ;
    schema:name "Qwen2.5-0.5B-Instruct-Gensyn-Swarm-rabid_prowling_jay"^^xsd:string ;
    schema:url <https://huggingface.co/Oberhaus/Qwen2.5-0.5B-Instruct-Gensyn-Swarm-rabid_prowling_jay> ;
    ns2:issueTracker <https://huggingface.co/Oberhaus/Qwen2.5-0.5B-Instruct-Gensyn-Swarm-rabid_prowling_jay/discussions> ;
    ns2:readme <https://huggingface.co/Oberhaus/Qwen2.5-0.5B-Instruct-Gensyn-Swarm-rabid_prowling_jay/blob/main/README.md> ;
    ns2:referencePublication <https://w3id.org/mlentory/mlentory_graph/57ac8dd147b53050bf4aa8cb4dbc16ad91197f7662c02666466eb8e9888d87a7> ;
    ns1:evaluatedOn "Information not found"^^xsd:string ;
    ns1:fineTunedFrom <https://w3id.org/mlentory/mlentory_graph/4d2ce24e500528b55a21cac8de96cce215994b6ca25877254bca1857cd8b9e55> ;
    ns1:mlTask <https://w3id.org/mlentory/mlentory_graph/6925cb204ab4d5280c948ac7e23dd8f7b48d1de433cf9edc5c30a8d87ce3b317> ;
    ns1:sharedBy <https://w3id.org/mlentory/mlentory_graph/a0ab69316adb7c09d875e25f934210e1c8f7ec32062ecc56eadc9299d760e44e> ;
    ns1:testedOn "Information not found"^^xsd:string ;
    ns1:trainedOn "Information not found"^^xsd:string .

<https://w3id.org/mlentory/mlentory_graph/8fd2e8ec655b6111cc83724fbc62c13d0c8b3442b1768b9bc35e0eceae0ebe85> a schema:DefinedTerm ;
    schema:description "Creates masks for objects or regions in images."^^xsd:string ;
    schema:name "Mask Generation"^^xsd:string .

<https://w3id.org/mlentory/mlentory_graph/9132b663f2893be0a7b034405164be91c4fe250d2b1ecd3390fb9b9bd689997b> a schema:DefinedTerm ;
    schema:description "Categorizes video content into predefined classes."^^xsd:string ;
    schema:name "Video Classification"^^xsd:string .

<https://w3id.org/mlentory/mlentory_graph/934dea1e0796f0376db45e4b74e093aeb422ffdf79cf5c4aaea1e5e84969c76e> a schema:DefinedTerm ;
    schema:description "A file format for efficiently storing and loading large language models with quantization options."^^xsd:string ;
    schema:name "GGUF"^^xsd:string .

<https://w3id.org/mlentory/mlentory_graph/956922acae22f21b82ce000e45d4739baf3f94e8b6eb2825a93166a8ccfc2fbf> a schema:DefinedTerm ;
    schema:description "NLP library developed by Baidu based on PaddlePaddle, offering Chinese and multilingual support."^^xsd:string ;
    schema:name "paddlenlp"^^xsd:string .

<https://w3id.org/mlentory/mlentory_graph/9abc397b7489422e962aeae20a5ed774806c8bd8f47e9008eef451699b8a61c1> a schema:DefinedTerm ;
    schema:description "Transforms input text into a different textual form."^^xsd:string ;
    schema:name "Text2Text Generation"^^xsd:string .

<https://w3id.org/mlentory/mlentory_graph/9c51ba772888465129d6bda3b0b520a3a16960b8c108a8cd2276eb4fb85ee5f2> a schema:DefinedTerm ;
    schema:description "High-performance numerical computing library that combines NumPy, automatic differentiation, and GPU/TPU support for ML research."^^xsd:string ;
    schema:name "JAX"^^xsd:string .

<https://w3id.org/mlentory/mlentory_graph/9db08d1a554609ae7c645781f30f4c335c5142d3c63fde5964e29f8a404c9566> a schema:DefinedTerm ;
    schema:description "Efficient framework for few-shot text classification using Sentence Transformers."^^xsd:string ;
    schema:name "setfit"^^xsd:string .

<https://w3id.org/mlentory/mlentory_graph/a0e0c1ddbfc3fa3aaab6bbd4ee4022410d9adc63e05996f59a545a7929aaf019> a schema:DefinedTerm ;
    schema:description "Open-source implementation of CLIP (Contrastive Language-Image Pre-Training) models."^^xsd:string ;
    schema:name "OpenCLIP"^^xsd:string .

<https://w3id.org/mlentory/mlentory_graph/a225e69a17f4be8c51cc1f1852c40371a478cfa95661008284bc676564a876e9> a schema:DefinedTerm ;
    schema:description "High-level neural networks API, designed for human beings, not machines, focusing on enabling fast experimentation."^^xsd:string ;
    schema:name "Keras"^^xsd:string .

<https://w3id.org/mlentory/mlentory_graph/a2f3a1fe1480acaf0753eb2d5ef88519c7b81e26e6505fed6d5c93c3a5119a65> a schema:DefinedTerm ;
    schema:description "Framework for efficiently deploying models on Intelligence Processing Unit (IPU) hardware."^^xsd:string ;
    schema:name "Graphcore"^^xsd:string .

<https://w3id.org/mlentory/mlentory_graph/a3c9ca93ab7ec29d067dd25733037f174c1326ef487292e5e1c9eea5cb35feb1> a schema:DefinedTerm ;
    schema:description "Set of reliable implementations of reinforcement learning algorithms in PyTorch."^^xsd:string ;
    schema:name "stable-baselines3"^^xsd:string .

<https://w3id.org/mlentory/mlentory_graph/a464d85abf29c8b2f8dc299e9fe390a547c8450e42b7ab0ccaac88fdcaeaaa84> a schema:DefinedTerm ;
    schema:description "Predicts missing words or tokens in masked text."^^xsd:string ;
    schema:name "Fill Mask"^^xsd:string .

<https://w3id.org/mlentory/mlentory_graph/ab2624f913f0d530408cbfa25c29a33523a1a481ba19c3d46f91a6fac4e63844> a schema:DefinedTerm ;
    schema:description "Detects objects in categories not seen during training."^^xsd:string ;
    schema:name "Zero Shot Object Detection"^^xsd:string .

<https://w3id.org/mlentory/mlentory_graph/b07372cae2aaf834044064c3f58684a47c8f4685d11fccf85dbb95dac4dc7141> a schema:DefinedTerm ;
    schema:description "Neural building blocks for speaker diarization in Python, supporting voice activity detection and speaker embedding."^^xsd:string ;
    schema:name "pyannote.audio"^^xsd:string .

<https://w3id.org/mlentory/mlentory_graph/b47d8ed02d0fc1a7d72d5d61255296300a82f2caa55dd809c63448bfdd9b4284> a schema:DefinedTerm ;
    schema:description "Analyzes and learns from graph-structured data."^^xsd:string ;
    schema:name "Graph Machine Learning"^^xsd:string .

<https://w3id.org/mlentory/mlentory_graph/b6151564ea69b1c14a6fc8e9915b0364e186996ab3b8c8aa14dcdd71756c51fb> a ns1:ML_Model ;
    schema:archivedAt <https://huggingface.co/PekingU/rtdetr_r101vd_coco_o365> ;
    schema:conditionsOfAccess "Information not found"^^xsd:string ;
    schema:dateCreated "2024-06-05T00:42:49+00:00"^^xsd:dateTime ;
    schema:dateModified "2024-07-01T14:17:49+00:00"^^xsd:dateTime ;
    schema:datePublished "2024-06-05T00:42:49+00:00"^^xsd:dateTime ;
    schema:description """


# Model Card for RT-DETR


## Table of Contents

1. [Model Details](#model-details)
2. [Model Sources](#model-sources)
3. [How to Get Started with the Model](#how-to-get-started-with-the-model)
4. [Training Details](#training-details)
5. [Evaluation](#evaluation)
6. [Model Architecture and Objective](#model-architecture-and-objective)
7. [Citation](#citation)


## Model Details

![image/png](https://cdn-uploads.huggingface.co/production/uploads/6579e0eaa9e58aec614e9d97/WULSDLsCVs7RNEs9KB0Lr.png)

> The YOLO series has become the most popular framework for real-time object detection due to its reasonable trade-off between speed and accuracy. 
However, we observe that the speed and accuracy of YOLOs are negatively affected by the NMS. 
Recently, end-to-end Transformer-based detectors (DETRs) have provided an alternative to eliminating NMS. 
Nevertheless, the high computational cost limits their practicality and hinders them from fully exploiting the advantage of excluding NMS. 
In this paper, we propose the Real-Time DEtection TRansformer (RT-DETR), the first real-time end-to-end object detector to our best knowledge that addresses the above dilemma. 
We build RT-DETR in two steps, drawing on the advanced DETR: 
first we focus on maintaining accuracy while improving speed, followed by maintaining speed while improving accuracy. 
Specifically, we design an efficient hybrid encoder to expeditiously process multi-scale features by decoupling intra-scale interaction and cross-scale fusion to improve speed. 
Then, we propose the uncertainty-minimal query selection to provide high-quality initial queries to the decoder, thereby improving accuracy. 
In addition, RT-DETR supports flexible speed tuning by adjusting the number of decoder layers to adapt to various scenarios without retraining. 
Our RT-DETR-R50 / R101 achieves 53.1% / 54.3% AP on COCO and 108 / 74 FPS on T4 GPU, outperforming previously advanced YOLOs in both speed and accuracy. 
We also develop scaled RT-DETRs that outperform the lighter YOLO detectors (S and M models). 
Furthermore, RT-DETR-R50 outperforms DINO-R50 by 2.2% AP in accuracy and about 21 times in FPS. 
After pre-training with Objects365, RT-DETR-R50 / R101 achieves 55.3% / 56.2% AP. The project page: this [https URL](https://zhao-yian.github.io/RTDETR/).



This is the model card of a  [transformers](https://huggingface.co/docs/transformers/index) model that has been pushed on the Hub.

- **Developed by:** Yian Zhao and Sangbum Choi
- **Funded by:**  National Key R&D Program of China (No.2022ZD0118201), Natural Science Foundation of China (No.61972217, 32071459, 62176249, 62006133, 62271465),
and the Shenzhen Medical Research Funds in China (No.
B2302037). 
- **Shared by:** Sangbum Choi
- **Model type:** [RT-DETR](https://huggingface.co/docs/transformers/main/en/model_doc/rt_detr)
- **License:** Apache-2.0

### Model Sources

<!-- Provide the basic links for the model. -->

- **HF Docs:** [RT-DETR](https://huggingface.co/docs/transformers/main/en/model_doc/rt_detr)
- **Repository:** https://github.com/lyuwenyu/RT-DETR
- **Paper:** https://arxiv.org/abs/2304.08069
- **Demo:** [RT-DETR Tracking](https://huggingface.co/spaces/merve/RT-DETR-tracking-coco)

## How to Get Started with the Model

Use the code below to get started with the model.

```python
import torch
import requests

from PIL import Image
from transformers import RTDetrForObjectDetection, RTDetrImageProcessor

url = 'http://images.cocodataset.org/val2017/000000039769.jpg' 
image = Image.open(requests.get(url, stream=True).raw)

image_processor = RTDetrImageProcessor.from_pretrained("PekingU/rtdetr_r101vd_coco_o365")
model = RTDetrForObjectDetection.from_pretrained("PekingU/rtdetr_r101vd_coco_o365")

inputs = image_processor(images=image, return_tensors="pt")

with torch.no_grad():
    outputs = model(**inputs)

results = image_processor.post_process_object_detection(outputs, target_sizes=torch.tensor([image.size[::-1]]), threshold=0.3)

for result in results:
    for score, label_id, box in zip(result["scores"], result["labels"], result["boxes"]):
        score, label = score.item(), label_id.item()
        box = [round(i, 2) for i in box.tolist()]
        print(f"{model.config.id2label[label]}: {score:.2f} {box}")
```
This should output
```
sofa: 0.97 [0.14, 0.38, 640.13, 476.21]
cat: 0.96 [343.38, 24.28, 640.14, 371.5]
cat: 0.96 [13.23, 54.18, 318.98, 472.22]
remote: 0.95 [40.11, 73.44, 175.96, 118.48]
remote: 0.92 [333.73, 76.58, 369.97, 186.99]
```

## Training Details

### Training Data

<!-- This should link to a Dataset Card, perhaps with a short stub of information on what the training data is all about as well as documentation related to data pre-processing or additional filtering. -->

The RTDETR model was trained on [COCO 2017 object detection](https://cocodataset.org/#download), a dataset consisting of 118k/5k annotated images for training/validation respectively. 

### Training Procedure

<!-- This relates heavily to the Technical Specifications. Content here should link to that section when it is relevant to the training procedure. -->

We conduct experiments on COCO and Objects365 datasets, where RT-DETR is trained on COCO train2017 and validated on COCO val2017 dataset. 
We report the standard COCO metrics, including AP (averaged over uniformly sampled IoU thresholds ranging from 0.50-0.95 with a step size of 0.05), 
AP50, AP75, as well as AP at different scales: APS, APM, APL.

### Preprocessing

Images are resized to 640x640 pixels and rescaled with `image_mean=[0.485, 0.456, 0.406]` and `image_std=[0.229, 0.224, 0.225]`.

### Training Hyperparameters

- **Training regime:** <!--fp32, fp16 mixed precision, bf16 mixed precision, bf16 non-mixed precision, fp16 non-mixed precision, fp8 mixed precision -->

![image/png](https://cdn-uploads.huggingface.co/production/uploads/6579e0eaa9e58aec614e9d97/E15I9MwZCtwNIms-W8Ra9.png)


## Evaluation


| Model                      | #Epochs | #Params (M) | GFLOPs | FPS_bs=1 | AP (val) | AP50 (val) | AP75 (val) | AP-s (val) | AP-m (val) | AP-l (val) |
|----------------------------|---------|-------------|--------|----------|--------|-----------|-----------|----------|----------|----------|
| RT-DETR-R18   | 72      | 20          | 60.7   | 217      | 46.5   | 63.8      | 50.4      | 28.4     | 49.8     | 63.0     |
| RT-DETR-R34   | 72      | 31         | 91.0   | 172      | 48.5   | 66.2      | 52.3      | 30.2     | 51.9     | 66.2     |
| RT-DETR R50 | 72      | 42          | 136    | 108      | 53.1   | 71.3      | 57.7      | 34.8     | 58.0     | 70.0     |
| RT-DETR R101| 72      | 76          | 259    | 74       | 54.3   | 72.7      | 58.6      | 36.0     | 58.8     | 72.1     |
| RT-DETR-R18 (Objects 365 pretrained)   | 60      | 20          | 61     | 217      | 49.2  | 66.6      | 53.5      | 33.2     | 52.3     | 64.8     |
| RT-DETR-R50 (Objects 365 pretrained)   | 24      | 42          | 136    | 108      | 55.3  | 73.4      | 60.1      | 37.9     | 59.9     | 71.8     |
| RT-DETR-R101 (Objects 365 pretrained)  | 24      | 76          | 259    | 74       | 56.2  | 74.6      | 61.3      | 38.3     | 60.5     | 73.5     |



### Model Architecture and Objective

![image/png](https://cdn-uploads.huggingface.co/production/uploads/6579e0eaa9e58aec614e9d97/sdIwTRlHNwPzyBNwHja60.png)

Overview of RT-DETR. We feed the features from the last three stages of the backbone into the encoder. The efficient hybrid
encoder transforms multi-scale features into a sequence of image features through the Attention-based Intra-scale Feature Interaction (AIFI)
and the CNN-based Cross-scale Feature Fusion (CCFF). Then, the uncertainty-minimal query selection selects a fixed number of encoder
features to serve as initial object queries for the decoder. Finally, the decoder with auxiliary prediction heads iteratively optimizes object
queries to generate categories and boxes.


## Citation

<!-- If there is a paper or blog post introducing the model, the APA and Bibtex information for that should go in this section. -->

**BibTeX:**

```bibtex
@misc{lv2023detrs,
      title={DETRs Beat YOLOs on Real-time Object Detection},
      author={Yian Zhao and Wenyu Lv and Shangliang Xu and Jinman Wei and Guanzhong Wang and Qingqing Dang and Yi Liu and Jie Chen},
      year={2023},
      eprint={2304.08069},
      archivePrefix={arXiv},
      primaryClass={cs.CV}
}
```

## Model Card Authors

[Sangbum Choi](https://huggingface.co/danelcsb)  
[Pavel Iakubovskii](https://huggingface.co/qubvel-hf)

"""^^xsd:string ;
    schema:discussionUrl <https://huggingface.co/PekingU/rtdetr_r101vd_coco_o365/discussions> ;
    schema:identifier "https://huggingface.co/PekingU/rtdetr_r101vd_coco_o365"^^xsd:string ;
    schema:inLanguage "en"^^xsd:string ;
    schema:keywords <https://w3id.org/mlentory/mlentory_graph/0dce0f5e7319b6178cd79d5f2163f0e134d0064f4ea4f93e8afeec1e7d78fa8d>,
        <https://w3id.org/mlentory/mlentory_graph/26d073be85a3ff0cdc5e730b4f76ae6826240fafeec865a5c98fe9a94cb9be8b>,
        <https://w3id.org/mlentory/mlentory_graph/87b927fef88a46248b3b208472aec7bfeb38667386b309f46772e26b40f6affb>,
        <https://w3id.org/mlentory/mlentory_graph/8b17850df3f6918f97a864deac6761f4da511fdf01824bc548e41b5f19be8be9>,
        <https://w3id.org/mlentory/mlentory_graph/cd80afb56f05e9ebd40fbd9cf6e6ae1f1295504c991157b8c26b00d097cef292>,
        <https://w3id.org/mlentory/mlentory_graph/df4982af808ead1a57663cc7a83e60059f6a6ae1baf83a270fdf8bdfef11a3de> ;
    schema:license <https://w3id.org/mlentory/mlentory_graph/c76582abee5256ca6e0f130b7b4bb38d54684358fa6802ca36e620ee6c5f00f1> ;
    schema:memoryRequirements "Not available"^^xsd:string ;
    schema:name "rtdetr_r101vd_coco_o365"^^xsd:string ;
    schema:url <https://huggingface.co/PekingU/rtdetr_r101vd_coco_o365> ;
    ns2:issueTracker <https://huggingface.co/PekingU/rtdetr_r101vd_coco_o365/discussions> ;
    ns2:readme <https://huggingface.co/PekingU/rtdetr_r101vd_coco_o365/blob/main/README.md> ;
    ns2:referencePublication <https://w3id.org/mlentory/mlentory_graph/f09f16395d224d8d8c2cf0df84c7f2a269bcd29b24f0f2d728c6fea7e009b1ce> ;
    ns1:evaluatedOn <https://w3id.org/mlentory/mlentory_graph/bc6b0c92e28e79bca517979432945aec4c2f9fbd1676acf8574200fe061a6485> ;
    ns1:fineTunedFrom "Information not found"^^xsd:string ;
    ns1:mlTask <https://w3id.org/mlentory/mlentory_graph/c6a31d1f7013eb41349bc590b0cc16d51b0a1706fa3f70c1337a8eecf06d2173> ;
    ns1:sharedBy <https://w3id.org/mlentory/mlentory_graph/5905daa0c1bcf7f259cc6f8e1fc4824b50e974518900d25f01cbf3cae9a7eff9> ;
    ns1:testedOn <https://w3id.org/mlentory/mlentory_graph/bc6b0c92e28e79bca517979432945aec4c2f9fbd1676acf8574200fe061a6485> ;
    ns1:trainedOn <https://w3id.org/mlentory/mlentory_graph/bc6b0c92e28e79bca517979432945aec4c2f9fbd1676acf8574200fe061a6485> .

<https://w3id.org/mlentory/mlentory_graph/b6726f6435b32ab359d8c48bd5f24d3180c4c1772a769d50d3b4c8cf8f0ecd46> a schema:DefinedTerm ;
    schema:description "Models created by merging multiple other models, often to combine their strengths or capabilities."^^xsd:string ;
    schema:name "Merge"^^xsd:string .

<https://w3id.org/mlentory/mlentory_graph/b6bffbd25ee4f19a8e55b6c7f32040744865e1e7d74080964d19fac6f207948c> a schema:DefinedTerm ;
    schema:description "Lightweight solution for mobile and embedded devices to run optimized TensorFlow models with low latency."^^xsd:string ;
    schema:name "TF Lite"^^xsd:string .

<https://w3id.org/mlentory/mlentory_graph/b9cbedab515a4ba3d4c78d2aaebae3eaaa730c9bfc49212dad2910d0f2c63595> a schema:DefinedTerm ;
    schema:description "Categorizes audio clips into predefined classes."^^xsd:string ;
    schema:name "Audio Classification"^^xsd:string .

<https://w3id.org/mlentory/mlentory_graph/bbf4caca758174ac9ca1258e1174d6c6d75a330218b88807385547a31f8229ab> a schema:DefinedTerm ;
    schema:description "Comprehensive machine learning library for Python featuring various classification, regression, and clustering algorithms."^^xsd:string ;
    schema:name "Scikit-learn"^^xsd:string .

<https://w3id.org/mlentory/mlentory_graph/bc53f85f6e664d1c6ece992a9d80b2e0705d1b3c75028563adb2ed9f36aedec9> a schema:DefinedTerm ;
    schema:description "Memory-safe, high-performance language used for building efficient ML systems and infrastructure."^^xsd:string ;
    schema:name "Rust"^^xsd:string .

<https://w3id.org/mlentory/mlentory_graph/bc69543009040d6e8dba73b201af25ed291f7933acca2056091eb5f643c4f919> a schema:DefinedTerm ;
    schema:description "Models based on RoBERTa (Robustly Optimized BERT Approach), an optimized BERT variant with improved pretraining and performance."^^xsd:string ;
    schema:name "roberta"^^xsd:string .

<https://w3id.org/mlentory/mlentory_graph/c0097ccf601f8114782f9c0c86386c6c995d5b2e12eddde21fdd7251761ee1fd> a schema:DefinedTerm ;
    schema:description "Framework for running ML workloads on Habana Gaudi accelerators with performance optimization."^^xsd:string ;
    schema:name "Habana"^^xsd:string .

<https://w3id.org/mlentory/mlentory_graph/c27ded3c38387a56bdeaa5c4cb3819535ecb0508621796ee78b329fdb73f682a> a ns1:ML_Model ;
    schema:archivedAt <https://huggingface.co/gitas/Qwen2.5-0.5B-Instruct-Gensyn-Swarm-skilled_gilded_bee> ;
    schema:conditionsOfAccess "Information not found"^^xsd:string ;
    schema:dateCreated "2025-06-11T15:04:43+00:00"^^xsd:dateTime ;
    schema:dateModified "2025-06-20T00:39:00+00:00"^^xsd:dateTime ;
    schema:datePublished "2025-06-11T15:04:43+00:00"^^xsd:dateTime ;
    schema:description """

# Model Card for Qwen2.5-0.5B-Instruct-Gensyn-Swarm-skilled_gilded_bee

This model is a fine-tuned version of [unsloth/Qwen2.5-0.5B-Instruct](https://huggingface.co/unsloth/Qwen2.5-0.5B-Instruct).
It has been trained using [TRL](https://github.com/huggingface/trl).

## Quick start

```python
from transformers import pipeline

question = "If you had a time machine, but could only go to the past or the future once and never return, which would you choose and why?"
generator = pipeline("text-generation", model="gitas/Qwen2.5-0.5B-Instruct-Gensyn-Swarm-skilled_gilded_bee", device="cuda")
output = generator([{"role": "user", "content": question}], max_new_tokens=128, return_full_text=False)[0]
print(output["generated_text"])
```

## Training procedure

 


This model was trained with GRPO, a method introduced in [DeepSeekMath: Pushing the Limits of Mathematical Reasoning in Open Language Models](https://huggingface.co/papers/2402.03300).

### Framework versions

- TRL: 0.18.1
- Transformers: 4.52.4
- Pytorch: 2.7.1
- Datasets: 3.6.0
- Tokenizers: 0.21.1

## Citations

Cite GRPO as:

```bibtex
@article{zhihong2024deepseekmath,
    title        = {{DeepSeekMath: Pushing the Limits of Mathematical Reasoning in Open Language Models}},
    author       = {Zhihong Shao and Peiyi Wang and Qihao Zhu and Runxin Xu and Junxiao Song and Mingchuan Zhang and Y. K. Li and Y. Wu and Daya Guo},
    year         = 2024,
    eprint       = {arXiv:2402.03300},
}

```

Cite TRL as:
    
```bibtex
@misc{vonwerra2022trl,
	title        = {{TRL: Transformer Reinforcement Learning}},
	author       = {Leandro von Werra and Younes Belkada and Lewis Tunstall and Edward Beeching and Tristan Thrush and Nathan Lambert and Shengyi Huang and Kashif Rasul and Quentin Gallou{\\'e}dec},
	year         = 2020,
	journal      = {GitHub repository},
	publisher    = {GitHub},
	howpublished = {\\url{https://github.com/huggingface/trl}}
}
```"""^^xsd:string ;
    schema:discussionUrl <https://huggingface.co/gitas/Qwen2.5-0.5B-Instruct-Gensyn-Swarm-skilled_gilded_bee/discussions> ;
    schema:identifier "https://huggingface.co/gitas/Qwen2.5-0.5B-Instruct-Gensyn-Swarm-skilled_gilded_bee"^^xsd:string ;
    schema:inLanguage "Information not found"^^xsd:string ;
    schema:keywords <https://w3id.org/mlentory/mlentory_graph/04151ef09fe56a2be18a7d842066720d6e7cee10ed5bf1a3363193444decd94d>,
        <https://w3id.org/mlentory/mlentory_graph/0dce0f5e7319b6178cd79d5f2163f0e134d0064f4ea4f93e8afeec1e7d78fa8d>,
        <https://w3id.org/mlentory/mlentory_graph/28f6fc79227e13d54a24f63fe2a8971b6f281ac3ca778d4303f84baacbc18a18>,
        <https://w3id.org/mlentory/mlentory_graph/29901b0ecce864a67f7734a040b22f9867d7435fdb731b76633a212ffab331f4>,
        <https://w3id.org/mlentory/mlentory_graph/61cce84de930f0da8c78ddef3203a2afac70cf5e46684f0407180738cd821965>,
        <https://w3id.org/mlentory/mlentory_graph/789df8584c437cfcddc5b2fff51cdef26423ea8d53635a0100a83cd8490b5cb6>,
        <https://w3id.org/mlentory/mlentory_graph/79cf083846a8329d2912fcd7f375233c37a54917af291bb945f0b58bc735b8ad>,
        <https://w3id.org/mlentory/mlentory_graph/81c4f52fcccf6ef0d25453aedb7cebe30c7034e3b2fa752246d0e43da889a0e1>,
        <https://w3id.org/mlentory/mlentory_graph/87b927fef88a46248b3b208472aec7bfeb38667386b309f46772e26b40f6affb>,
        <https://w3id.org/mlentory/mlentory_graph/8960ef15233adcffe0ffb89374d9955f251580395819df1a9693362ac19a04d7>,
        <https://w3id.org/mlentory/mlentory_graph/a4cf9836ab3780436e61a37fe48729edb682b8e0e1c3f9363cb10061770a7197>,
        <https://w3id.org/mlentory/mlentory_graph/c21ccd276af5ae1828bea64af6da9742c6ef229f7b0571987909160419d90560>,
        <https://w3id.org/mlentory/mlentory_graph/df4982af808ead1a57663cc7a83e60059f6a6ae1baf83a270fdf8bdfef11a3de>,
        <https://w3id.org/mlentory/mlentory_graph/f59cf55f3a86acf0bcfc020eac552a72c13f1212154211a7bf30504548661f8d> ;
    schema:license "Information not found"^^xsd:string ;
    schema:memoryRequirements "Not available"^^xsd:string ;
    schema:name "Qwen2.5-0.5B-Instruct-Gensyn-Swarm-skilled_gilded_bee"^^xsd:string ;
    schema:url <https://huggingface.co/gitas/Qwen2.5-0.5B-Instruct-Gensyn-Swarm-skilled_gilded_bee> ;
    ns2:issueTracker <https://huggingface.co/gitas/Qwen2.5-0.5B-Instruct-Gensyn-Swarm-skilled_gilded_bee/discussions> ;
    ns2:readme <https://huggingface.co/gitas/Qwen2.5-0.5B-Instruct-Gensyn-Swarm-skilled_gilded_bee/blob/main/README.md> ;
    ns2:referencePublication <https://w3id.org/mlentory/mlentory_graph/57ac8dd147b53050bf4aa8cb4dbc16ad91197f7662c02666466eb8e9888d87a7> ;
    ns1:evaluatedOn "Information not found"^^xsd:string ;
    ns1:fineTunedFrom <https://w3id.org/mlentory/mlentory_graph/4d2ce24e500528b55a21cac8de96cce215994b6ca25877254bca1857cd8b9e55> ;
    ns1:mlTask <https://w3id.org/mlentory/mlentory_graph/6925cb204ab4d5280c948ac7e23dd8f7b48d1de433cf9edc5c30a8d87ce3b317> ;
    ns1:sharedBy <https://w3id.org/mlentory/mlentory_graph/eef0031ff6e5dac5843259d345350aaa1f938abb2683bf0974713c4785c2af9c> ;
    ns1:testedOn "Information not found"^^xsd:string ;
    ns1:trainedOn "Information not found"^^xsd:string .

<https://w3id.org/mlentory/mlentory_graph/c7062dc4cfa463be9c92783a4d2c8abb9a4b37f71f4caef7c07cd6787e1843ed> a schema:DefinedTerm ;
    schema:description "Transforms static images into video sequences."^^xsd:string ;
    schema:name "Imageto Video"^^xsd:string .

<https://w3id.org/mlentory/mlentory_graph/cb9bd15fb27d24d93383343fa6ee37e644b0a41da399de954b0a5cf93c7b3501> a schema:DefinedTerm ;
    schema:description "Labels individual tokens (words) in text with specific categories."^^xsd:string ;
    schema:name "Token Classification"^^xsd:string .

<https://w3id.org/mlentory/mlentory_graph/cba5458c023bd0e333fefb47511914b963716a71b0356b435370871727585038> a schema:DefinedTerm ;
    schema:description "Generates video content based on textual descriptions."^^xsd:string ;
    schema:name "Text to Video"^^xsd:string .

<https://w3id.org/mlentory/mlentory_graph/d1054f9c274823fbeb3d1ab19d0f2344791cee18915cdb21fb1437bba03ba8fb> a schema:DefinedTerm ;
    schema:description "Predicts continuous values from tabular data."^^xsd:string ;
    schema:name "Tabular Regression"^^xsd:string .

<https://w3id.org/mlentory/mlentory_graph/d36cbf1999007e337f8cfc0a8b2c40dd8a4bf2d6c4c2cd990849a1f06f820fcd> a ns1:ML_Model ;
    schema:archivedAt <https://huggingface.co/Qwen/Qwen2.5-0.5B-Instruct>,
        <https://huggingface.co/unsloth/Qwen2.5-0.5B-Instruct> ;
    schema:conditionsOfAccess "Information not found"^^xsd:string ;
    schema:dateCreated "2024-09-16T11:52:46+00:00"^^xsd:dateTime,
        "2024-09-18T21:06:02+00:00"^^xsd:dateTime ;
    schema:dateModified "2024-09-25T12:32:56+00:00"^^xsd:dateTime,
        "2025-02-06T02:04:10+00:00"^^xsd:dateTime ;
    schema:datePublished "2024-09-16T11:52:46+00:00"^^xsd:dateTime,
        "2024-09-18T21:06:02+00:00"^^xsd:dateTime ;
    schema:description """

# Finetune Llama 3.1, Gemma 2, Mistral 2-5x faster with 70% less memory via Unsloth!

We have a Qwen 2.5 (all model sizes) [free Google Colab Tesla T4 notebook](https://colab.research.google.com/drive/1Kose-ucXO1IBaZq5BvbwWieuubP7hxvQ?usp=sharing).
Also a [Qwen 2.5 conversational style notebook](https://colab.research.google.com/drive/1qN1CEalC70EO1wGKhNxs1go1W9So61R5?usp=sharing).

[<img src="https://raw.githubusercontent.com/unslothai/unsloth/main/images/Discord%20button.png" width="200"/>](https://discord.gg/unsloth)
[<img src="https://raw.githubusercontent.com/unslothai/unsloth/main/images/unsloth%20made%20with%20love.png" width="200"/>](https://github.com/unslothai/unsloth)

##  Finetune for Free

All notebooks are **beginner friendly**! Add your dataset, click "Run All", and you'll get a 2x faster finetuned model which can be exported to GGUF, vLLM or uploaded to Hugging Face.

| Unsloth supports          |    Free Notebooks                                                                                           | Performance | Memory use |
|-----------------|--------------------------------------------------------------------------------------------------------------------------|-------------|----------|
| **Llama-3.1 8b**      | [ Start on Colab](https://colab.research.google.com/drive/1Ys44kVvmeZtnICzWz0xgpRnrIOjZAuxp?usp=sharing)               | 2.4x faster | 58% less |
| **Phi-3.5 (mini)** | [ Start on Colab](https://colab.research.google.com/drive/1lN6hPQveB_mHSnTOYifygFcrO8C1bxq4?usp=sharing)               | 2x faster | 50% less |
| **Gemma-2 9b**      | [ Start on Colab](https://colab.research.google.com/drive/1vIrqH5uYDQwsJ4-OO3DErvuv4pBgVwk4?usp=sharing)               | 2.4x faster | 58% less |
| **Mistral 7b**    | [ Start on Colab](https://colab.research.google.com/drive/1Dyauq4kTZoLewQ1cApceUQVNcnnNTzg_?usp=sharing)               | 2.2x faster | 62% less |
| **TinyLlama**  | [ Start on Colab](https://colab.research.google.com/drive/1AZghoNBQaMDgWJpi4RbffGM1h6raLUj9?usp=sharing)              | 3.9x faster | 74% less |
| **DPO - Zephyr**     | [ Start on Colab](https://colab.research.google.com/drive/15vttTpzzVXv_tJwEk-hIcQ0S9FcEWvwP?usp=sharing)               | 1.9x faster | 19% less |

- This [conversational notebook](https://colab.research.google.com/drive/1Aau3lgPzeZKQ-98h69CCu1UJcvIBLmy2?usp=sharing) is useful for ShareGPT ChatML / Vicuna templates.
- This [text completion notebook](https://colab.research.google.com/drive/1ef-tab5bhkvWmBOObepl1WgJvfvSzn5Q?usp=sharing) is for raw text. This [DPO notebook](https://colab.research.google.com/drive/15vttTpzzVXv_tJwEk-hIcQ0S9FcEWvwP?usp=sharing) replicates Zephyr.
- \\* Kaggle has 2x T4s, but we use 1. Due to overhead, 1x T4 is 5x faster.

# Qwen2.5-0.5B-Instruct

## Introduction

Qwen2.5 is the latest series of Qwen large language models. For Qwen2.5, we release a number of base language models and instruction-tuned language models ranging from 0.5 to 72 billion parameters. Qwen2.5 brings the following improvements upon Qwen2:

- Significantly **more knowledge** and has greatly improved capabilities in **coding** and **mathematics**, thanks to our specialized expert models in these domains.
- Significant improvements in **instruction following**, **generating long texts** (over 8K tokens), **understanding structured data** (e.g, tables), and **generating structured outputs** especially JSON. **More resilient to the diversity of system prompts**, enhancing role-play implementation and condition-setting for chatbots.
- **Long-context Support** up to 128K tokens and can generate up to 8K tokens.
- **Multilingual support** for over 29 languages, including Chinese, English, French, Spanish, Portuguese, German, Italian, Russian, Japanese, Korean, Vietnamese, Thai, Arabic, and more. 

**This repo contains the instruction-tuned 0.5B Qwen2.5 model**, which has the following features:
- Type: Causal Language Models
- Training Stage: Pretraining & Post-training
- Architecture: transformers with RoPE, SwiGLU, RMSNorm, Attention QKV bias and tied word embeddings
- Number of Parameters: 0.49B
- Number of Paramaters (Non-Embedding): 0.36B
- Number of Layers: 24
- Number of Attention Heads (GQA): 14 for Q and 2 for KV
- Context Length: Full 32,768 tokens and generation 8192 tokens

For more details, please refer to our [blog](https://qwenlm.github.io/blog/qwen2.5/), [GitHub](https://github.com/QwenLM/Qwen2.5), and [Documentation](https://qwen.readthedocs.io/en/latest/).

## Requirements

The code of Qwen2.5 has been in the latest Hugging face `transformers` and we advise you to use the latest version of `transformers`.

With `transformers<4.37.0`, you will encounter the following error:
```
KeyError: 'qwen2'
```

## Quickstart

Here provides a code snippet with `apply_chat_template` to show you how to load the tokenizer and model and how to generate contents.

```python
from transformers import AutoModelForCausalLM, AutoTokenizer

model_name = "Qwen/Qwen2.5-0.5B-Instruct"

model = AutoModelForCausalLM.from_pretrained(
    model_name,
    torch_dtype="auto",
    device_map="auto"
)
tokenizer = AutoTokenizer.from_pretrained(model_name)

prompt = "Give me a short introduction to large language model."
messages = [
    {"role": "system", "content": "You are Qwen, created by Alibaba Cloud. You are a helpful assistant."},
    {"role": "user", "content": prompt}
]
text = tokenizer.apply_chat_template(
    messages,
    tokenize=False,
    add_generation_prompt=True
)
model_inputs = tokenizer([text], return_tensors="pt").to(model.device)

generated_ids = model.generate(
    **model_inputs,
    max_new_tokens=512
)
generated_ids = [
    output_ids[len(input_ids):] for input_ids, output_ids in zip(model_inputs.input_ids, generated_ids)
]

response = tokenizer.batch_decode(generated_ids, skip_special_tokens=True)[0]
```


## Evaluation & Performance

Detailed evaluation results are reported in this [ blog](https://qwenlm.github.io/blog/qwen2.5/).

For requirements on GPU memory and the respective throughput, see results [here](https://qwen.readthedocs.io/en/latest/benchmark/speed_benchmark.html).

## Citation

If you find our work helpful, feel free to give us a cite.

```
@misc{qwen2.5,
    title = {Qwen2.5: A Party of Foundation Models},
    url = {https://qwenlm.github.io/blog/qwen2.5/},
    author = {Qwen Team},
    month = {September},
    year = {2024}
}

@article{qwen2,
      title={Qwen2 Technical Report}, 
      author={An Yang and Baosong Yang and Binyuan Hui and Bo Zheng and Bowen Yu and Chang Zhou and Chengpeng Li and Chengyuan Li and Dayiheng Liu and Fei Huang and Guanting Dong and Haoran Wei and Huan Lin and Jialong Tang and Jialin Wang and Jian Yang and Jianhong Tu and Jianwei Zhang and Jianxin Ma and Jin Xu and Jingren Zhou and Jinze Bai and Jinzheng He and Junyang Lin and Kai Dang and Keming Lu and Keqin Chen and Kexin Yang and Mei Li and Mingfeng Xue and Na Ni and Pei Zhang and Peng Wang and Ru Peng and Rui Men and Ruize Gao and Runji Lin and Shijie Wang and Shuai Bai and Sinan Tan and Tianhang Zhu and Tianhao Li and Tianyu Liu and Wenbin Ge and Xiaodong Deng and Xiaohuan Zhou and Xingzhang Ren and Xinyu Zhang and Xipin Wei and Xuancheng Ren and Yang Fan and Yang Yao and Yichang Zhang and Yu Wan and Yunfei Chu and Yuqiong Liu and Zeyu Cui and Zhenru Zhang and Zhihao Fan},
      journal={arXiv preprint arXiv:2407.10671},
      year={2024}
}
```"""^^xsd:string,
        """

# Qwen2.5-0.5B-Instruct

## Introduction

Qwen2.5 is the latest series of Qwen large language models. For Qwen2.5, we release a number of base language models and instruction-tuned language models ranging from 0.5 to 72 billion parameters. Qwen2.5 brings the following improvements upon Qwen2:

- Significantly **more knowledge** and has greatly improved capabilities in **coding** and **mathematics**, thanks to our specialized expert models in these domains.
- Significant improvements in **instruction following**, **generating long texts** (over 8K tokens), **understanding structured data** (e.g, tables), and **generating structured outputs** especially JSON. **More resilient to the diversity of system prompts**, enhancing role-play implementation and condition-setting for chatbots.
- **Long-context Support** up to 128K tokens and can generate up to 8K tokens.
- **Multilingual support** for over 29 languages, including Chinese, English, French, Spanish, Portuguese, German, Italian, Russian, Japanese, Korean, Vietnamese, Thai, Arabic, and more. 

**This repo contains the instruction-tuned 0.5B Qwen2.5 model**, which has the following features:
- Type: Causal Language Models
- Training Stage: Pretraining & Post-training
- Architecture: transformers with RoPE, SwiGLU, RMSNorm, Attention QKV bias and tied word embeddings
- Number of Parameters: 0.49B
- Number of Paramaters (Non-Embedding): 0.36B
- Number of Layers: 24
- Number of Attention Heads (GQA): 14 for Q and 2 for KV
- Context Length: Full 32,768 tokens and generation 8192 tokens

For more details, please refer to our [blog](https://qwenlm.github.io/blog/qwen2.5/), [GitHub](https://github.com/QwenLM/Qwen2.5), and [Documentation](https://qwen.readthedocs.io/en/latest/).

## Requirements

The code of Qwen2.5 has been in the latest Hugging face `transformers` and we advise you to use the latest version of `transformers`.

With `transformers<4.37.0`, you will encounter the following error:
```
KeyError: 'qwen2'
```

## Quickstart

Here provides a code snippet with `apply_chat_template` to show you how to load the tokenizer and model and how to generate contents.

```python
from transformers import AutoModelForCausalLM, AutoTokenizer

model_name = "Qwen/Qwen2.5-0.5B-Instruct"

model = AutoModelForCausalLM.from_pretrained(
    model_name,
    torch_dtype="auto",
    device_map="auto"
)
tokenizer = AutoTokenizer.from_pretrained(model_name)

prompt = "Give me a short introduction to large language model."
messages = [
    {"role": "system", "content": "You are Qwen, created by Alibaba Cloud. You are a helpful assistant."},
    {"role": "user", "content": prompt}
]
text = tokenizer.apply_chat_template(
    messages,
    tokenize=False,
    add_generation_prompt=True
)
model_inputs = tokenizer([text], return_tensors="pt").to(model.device)

generated_ids = model.generate(
    **model_inputs,
    max_new_tokens=512
)
generated_ids = [
    output_ids[len(input_ids):] for input_ids, output_ids in zip(model_inputs.input_ids, generated_ids)
]

response = tokenizer.batch_decode(generated_ids, skip_special_tokens=True)[0]
```


## Evaluation & Performance

Detailed evaluation results are reported in this [ blog](https://qwenlm.github.io/blog/qwen2.5/).

For requirements on GPU memory and the respective throughput, see results [here](https://qwen.readthedocs.io/en/latest/benchmark/speed_benchmark.html).

## Citation

If you find our work helpful, feel free to give us a cite.

```
@misc{qwen2.5,
    title = {Qwen2.5: A Party of Foundation Models},
    url = {https://qwenlm.github.io/blog/qwen2.5/},
    author = {Qwen Team},
    month = {September},
    year = {2024}
}

@article{qwen2,
      title={Qwen2 Technical Report}, 
      author={An Yang and Baosong Yang and Binyuan Hui and Bo Zheng and Bowen Yu and Chang Zhou and Chengpeng Li and Chengyuan Li and Dayiheng Liu and Fei Huang and Guanting Dong and Haoran Wei and Huan Lin and Jialong Tang and Jialin Wang and Jian Yang and Jianhong Tu and Jianwei Zhang and Jianxin Ma and Jin Xu and Jingren Zhou and Jinze Bai and Jinzheng He and Junyang Lin and Kai Dang and Keming Lu and Keqin Chen and Kexin Yang and Mei Li and Mingfeng Xue and Na Ni and Pei Zhang and Peng Wang and Ru Peng and Rui Men and Ruize Gao and Runji Lin and Shijie Wang and Shuai Bai and Sinan Tan and Tianhang Zhu and Tianhao Li and Tianyu Liu and Wenbin Ge and Xiaodong Deng and Xiaohuan Zhou and Xingzhang Ren and Xinyu Zhang and Xipin Wei and Xuancheng Ren and Yang Fan and Yang Yao and Yichang Zhang and Yu Wan and Yunfei Chu and Yuqiong Liu and Zeyu Cui and Zhenru Zhang and Zhihao Fan},
      journal={arXiv preprint arXiv:2407.10671},
      year={2024}
}
```"""^^xsd:string ;
    schema:discussionUrl <https://huggingface.co/Qwen/Qwen2.5-0.5B-Instruct/discussions>,
        <https://huggingface.co/unsloth/Qwen2.5-0.5B-Instruct/discussions> ;
    schema:identifier "https://huggingface.co/Qwen/Qwen2.5-0.5B-Instruct"^^xsd:string,
        "https://huggingface.co/unsloth/Qwen2.5-0.5B-Instruct"^^xsd:string ;
    schema:inLanguage "en"^^xsd:string ;
    schema:keywords <https://w3id.org/mlentory/mlentory_graph/0aee914bbc884bff2ba1f0f20d69d212ea847639505c98357a8c490a96d303d0>,
        <https://w3id.org/mlentory/mlentory_graph/0dce0f5e7319b6178cd79d5f2163f0e134d0064f4ea4f93e8afeec1e7d78fa8d>,
        <https://w3id.org/mlentory/mlentory_graph/547c2a6f152d09c8e3dbd3a857c5481c4c4d77accf781e6fe237d9c49f47d9a7>,
        <https://w3id.org/mlentory/mlentory_graph/61cce84de930f0da8c78ddef3203a2afac70cf5e46684f0407180738cd821965>,
        <https://w3id.org/mlentory/mlentory_graph/789df8584c437cfcddc5b2fff51cdef26423ea8d53635a0100a83cd8490b5cb6>,
        <https://w3id.org/mlentory/mlentory_graph/79cf083846a8329d2912fcd7f375233c37a54917af291bb945f0b58bc735b8ad>,
        <https://w3id.org/mlentory/mlentory_graph/81c4f52fcccf6ef0d25453aedb7cebe30c7034e3b2fa752246d0e43da889a0e1>,
        <https://w3id.org/mlentory/mlentory_graph/87b927fef88a46248b3b208472aec7bfeb38667386b309f46772e26b40f6affb>,
        <https://w3id.org/mlentory/mlentory_graph/df4982af808ead1a57663cc7a83e60059f6a6ae1baf83a270fdf8bdfef11a3de>,
        <https://w3id.org/mlentory/mlentory_graph/f59cf55f3a86acf0bcfc020eac552a72c13f1212154211a7bf30504548661f8d> ;
    schema:license <https://w3id.org/mlentory/mlentory_graph/c76582abee5256ca6e0f130b7b4bb38d54684358fa6802ca36e620ee6c5f00f1> ;
    schema:memoryRequirements "Not available"^^xsd:string ;
    schema:name "Qwen2.5-0.5B-Instruct"^^xsd:string ;
    schema:url <https://huggingface.co/Qwen/Qwen2.5-0.5B-Instruct>,
        <https://huggingface.co/unsloth/Qwen2.5-0.5B-Instruct> ;
    ns2:issueTracker <https://huggingface.co/Qwen/Qwen2.5-0.5B-Instruct/discussions>,
        <https://huggingface.co/unsloth/Qwen2.5-0.5B-Instruct/discussions> ;
    ns2:readme <https://huggingface.co/Qwen/Qwen2.5-0.5B-Instruct/blob/main/README.md>,
        <https://huggingface.co/unsloth/Qwen2.5-0.5B-Instruct/blob/main/README.md> ;
    ns2:referencePublication <https://w3id.org/mlentory/mlentory_graph/e5e889a745f1d3f2a82efa664fb959d3d197a1e52340bab1e68dd99b052d5e9e> ;
    ns1:evaluatedOn "Information not found"^^xsd:string ;
    ns1:fineTunedFrom <https://w3id.org/mlentory/mlentory_graph/03796f961bc00b67e2b12acaa6748c5804221cd7dc225bdb8a6be0c1d057bad4>,
        <https://w3id.org/mlentory/mlentory_graph/3063efca2e942b6d98aad194d54ad582369c52ec8fc5991489a6f8e8e100fe93> ;
    ns1:mlTask <https://w3id.org/mlentory/mlentory_graph/6925cb204ab4d5280c948ac7e23dd8f7b48d1de433cf9edc5c30a8d87ce3b317> ;
    ns1:sharedBy <https://w3id.org/mlentory/mlentory_graph/20a607de6d3028bc24821288287faa1f8bf92a37433fb7df54105674128d8a68>,
        <https://w3id.org/mlentory/mlentory_graph/bf9cb754023f4cf332c0aade32b2500cf9a20677c98b90fe64b0897849999f8e> ;
    ns1:testedOn "Information not found"^^xsd:string ;
    ns1:trainedOn "Information not found"^^xsd:string .

<https://w3id.org/mlentory/mlentory_graph/d462b48c96b732d754a938aa86dbd16bfb7478ca5b0c1f1f006c611c112094e9> a schema:DefinedTerm ;
    schema:description "State-of-the-art library for diffusion models across multiple modalities like vision and audio."^^xsd:string ;
    schema:name "Diffusers"^^xsd:string .

<https://w3id.org/mlentory/mlentory_graph/d6f86ddd52b22c26a6970ea3473a2f8e657e9600a3cea6dd33e7307bf848d475> a schema:DefinedTerm ;
    schema:description "All-in-one toolkit for speech technology research, including ASR, speaker recognition, and speech enhancement."^^xsd:string ;
    schema:name "speechbrain"^^xsd:string .

<https://w3id.org/mlentory/mlentory_graph/d75a16357850d2896a768db42c912a9487fd97a50f3358217d5bbb602c39b195> a schema:DefinedTerm ;
    schema:description "Indicates a HuggingFace Space demo exists for this model allowing interactive testing without setup."^^xsd:string ;
    schema:name "Has a Space"^^xsd:string .

<https://w3id.org/mlentory/mlentory_graph/da7ceb435edd7abd79e326adff9ec9af9a7edae9dd877c3aa1c17160db9b6eae> a ns1:ML_Model ;
    schema:archivedAt <https://huggingface.co/Sonyabu/Qwen2.5-0.5B-Instruct-Gensyn-Swarm-carnivorous_scampering_macaque> ;
    schema:conditionsOfAccess "Information not found"^^xsd:string ;
    schema:dateCreated "2025-06-11T11:44:50+00:00"^^xsd:dateTime ;
    schema:dateModified "2025-06-20T00:40:55+00:00"^^xsd:dateTime ;
    schema:datePublished "2025-06-11T11:44:50+00:00"^^xsd:dateTime ;
    schema:description """

# Model Card for Qwen2.5-0.5B-Instruct-Gensyn-Swarm-carnivorous_scampering_macaque

This model is a fine-tuned version of [unsloth/Qwen2.5-0.5B-Instruct](https://huggingface.co/unsloth/Qwen2.5-0.5B-Instruct).
It has been trained using [TRL](https://github.com/huggingface/trl).

## Quick start

```python
from transformers import pipeline

question = "If you had a time machine, but could only go to the past or the future once and never return, which would you choose and why?"
generator = pipeline("text-generation", model="Sonyabu/Qwen2.5-0.5B-Instruct-Gensyn-Swarm-carnivorous_scampering_macaque", device="cuda")
output = generator([{"role": "user", "content": question}], max_new_tokens=128, return_full_text=False)[0]
print(output["generated_text"])
```

## Training procedure

 


This model was trained with GRPO, a method introduced in [DeepSeekMath: Pushing the Limits of Mathematical Reasoning in Open Language Models](https://huggingface.co/papers/2402.03300).

### Framework versions

- TRL: 0.18.1
- Transformers: 4.52.4
- Pytorch: 2.7.1
- Datasets: 3.6.0
- Tokenizers: 0.21.1

## Citations

Cite GRPO as:

```bibtex
@article{zhihong2024deepseekmath,
    title        = {{DeepSeekMath: Pushing the Limits of Mathematical Reasoning in Open Language Models}},
    author       = {Zhihong Shao and Peiyi Wang and Qihao Zhu and Runxin Xu and Junxiao Song and Mingchuan Zhang and Y. K. Li and Y. Wu and Daya Guo},
    year         = 2024,
    eprint       = {arXiv:2402.03300},
}

```

Cite TRL as:
    
```bibtex
@misc{vonwerra2022trl,
	title        = {{TRL: Transformer Reinforcement Learning}},
	author       = {Leandro von Werra and Younes Belkada and Lewis Tunstall and Edward Beeching and Tristan Thrush and Nathan Lambert and Shengyi Huang and Kashif Rasul and Quentin Gallou{\\'e}dec},
	year         = 2020,
	journal      = {GitHub repository},
	publisher    = {GitHub},
	howpublished = {\\url{https://github.com/huggingface/trl}}
}
```"""^^xsd:string ;
    schema:discussionUrl <https://huggingface.co/Sonyabu/Qwen2.5-0.5B-Instruct-Gensyn-Swarm-carnivorous_scampering_macaque/discussions> ;
    schema:identifier "https://huggingface.co/Sonyabu/Qwen2.5-0.5B-Instruct-Gensyn-Swarm-carnivorous_scampering_macaque"^^xsd:string ;
    schema:inLanguage "Information not found"^^xsd:string ;
    schema:keywords <https://w3id.org/mlentory/mlentory_graph/04151ef09fe56a2be18a7d842066720d6e7cee10ed5bf1a3363193444decd94d>,
        <https://w3id.org/mlentory/mlentory_graph/0dce0f5e7319b6178cd79d5f2163f0e134d0064f4ea4f93e8afeec1e7d78fa8d>,
        <https://w3id.org/mlentory/mlentory_graph/28f6fc79227e13d54a24f63fe2a8971b6f281ac3ca778d4303f84baacbc18a18>,
        <https://w3id.org/mlentory/mlentory_graph/29901b0ecce864a67f7734a040b22f9867d7435fdb731b76633a212ffab331f4>,
        <https://w3id.org/mlentory/mlentory_graph/61cce84de930f0da8c78ddef3203a2afac70cf5e46684f0407180738cd821965>,
        <https://w3id.org/mlentory/mlentory_graph/789df8584c437cfcddc5b2fff51cdef26423ea8d53635a0100a83cd8490b5cb6>,
        <https://w3id.org/mlentory/mlentory_graph/79cf083846a8329d2912fcd7f375233c37a54917af291bb945f0b58bc735b8ad>,
        <https://w3id.org/mlentory/mlentory_graph/81c4f52fcccf6ef0d25453aedb7cebe30c7034e3b2fa752246d0e43da889a0e1>,
        <https://w3id.org/mlentory/mlentory_graph/87b927fef88a46248b3b208472aec7bfeb38667386b309f46772e26b40f6affb>,
        <https://w3id.org/mlentory/mlentory_graph/a168e9b34d074761f8779451d3ce965501aaff2a0c86e967f06c2c999a8951f6>,
        <https://w3id.org/mlentory/mlentory_graph/a4cf9836ab3780436e61a37fe48729edb682b8e0e1c3f9363cb10061770a7197>,
        <https://w3id.org/mlentory/mlentory_graph/c21ccd276af5ae1828bea64af6da9742c6ef229f7b0571987909160419d90560>,
        <https://w3id.org/mlentory/mlentory_graph/df4982af808ead1a57663cc7a83e60059f6a6ae1baf83a270fdf8bdfef11a3de>,
        <https://w3id.org/mlentory/mlentory_graph/f59cf55f3a86acf0bcfc020eac552a72c13f1212154211a7bf30504548661f8d> ;
    schema:license "Information not found"^^xsd:string ;
    schema:memoryRequirements "Not available"^^xsd:string ;
    schema:name "Qwen2.5-0.5B-Instruct-Gensyn-Swarm-carnivorous_scampering_macaque"^^xsd:string ;
    schema:url <https://huggingface.co/Sonyabu/Qwen2.5-0.5B-Instruct-Gensyn-Swarm-carnivorous_scampering_macaque> ;
    ns2:issueTracker <https://huggingface.co/Sonyabu/Qwen2.5-0.5B-Instruct-Gensyn-Swarm-carnivorous_scampering_macaque/discussions> ;
    ns2:readme <https://huggingface.co/Sonyabu/Qwen2.5-0.5B-Instruct-Gensyn-Swarm-carnivorous_scampering_macaque/blob/main/README.md> ;
    ns2:referencePublication <https://w3id.org/mlentory/mlentory_graph/57ac8dd147b53050bf4aa8cb4dbc16ad91197f7662c02666466eb8e9888d87a7> ;
    ns1:evaluatedOn "Information not found"^^xsd:string ;
    ns1:fineTunedFrom <https://w3id.org/mlentory/mlentory_graph/4d2ce24e500528b55a21cac8de96cce215994b6ca25877254bca1857cd8b9e55> ;
    ns1:mlTask <https://w3id.org/mlentory/mlentory_graph/6925cb204ab4d5280c948ac7e23dd8f7b48d1de433cf9edc5c30a8d87ce3b317> ;
    ns1:sharedBy <https://w3id.org/mlentory/mlentory_graph/867fba26049e05cdeac357efdf65e1e500d7e599ea1baa5717727c900a775196> ;
    ns1:testedOn "Information not found"^^xsd:string ;
    ns1:trainedOn "Information not found"^^xsd:string .

<https://w3id.org/mlentory/mlentory_graph/db86f2c8ce693db878b689231690fab2fe37b7ae1abc1e54dca9fae35bc0df0d> a schema:DefinedTerm ;
    schema:description "Transcribes spoken language into written text."^^xsd:string ;
    schema:name "Automatic Speech Recognition"^^xsd:string .

<https://w3id.org/mlentory/mlentory_graph/dc96ea445d125873bc02183accca8dffafbc58c6100167ef5b113919f5afb57e> a schema:DefinedTerm ;
    schema:description "Generates 3D models or scenes from textual descriptions."^^xsd:string ;
    schema:name "Text to 3D"^^xsd:string .

<https://w3id.org/mlentory/mlentory_graph/dd477ce37bc2c08950a1d845aa243dff8c0e03de15cc42b9b35295d514538a84> a schema:DefinedTerm ;
    schema:description "Converts text from one language to another."^^xsd:string ;
    schema:name "Translation"^^xsd:string .

<https://w3id.org/mlentory/mlentory_graph/ddb15bfa0ef843723bc4c8a81ab1d826b1fc4ff36ed13faf8f8f3841261978b8> a schema:DefinedTerm ;
    schema:description "Models created by Mistral, a French artificial intelligence startup, headquartered in Paris. It specializes in open-weight large language models."^^xsd:string ;
    schema:name "mistral"^^xsd:string .

<https://w3id.org/mlentory/mlentory_graph/df2c9c7dc08f5514331c35b3bf3e4da58de6a14c0724dc40f90a3e588f9844dd> a schema:DefinedTerm ;
    schema:description "Models quantized to 4-bit precision, reducing memory footprint while maintaining reasonable performance."^^xsd:string ;
    schema:name "4-bit precision"^^xsd:string .

<https://w3id.org/mlentory/mlentory_graph/df3db739a5d22c6a5829694aeecdedee4e20b5804f1345689c8abd3350883e54> a schema:DefinedTerm ;
    schema:description "Indicates the model supports deployment through HuggingFace's managed inference API service for production environments."^^xsd:string ;
    schema:name "Inference Endpoints"^^xsd:string .

<https://w3id.org/mlentory/mlentory_graph/e2cb5f7dba65387f6ecd56e7a642d33df8fca1197b2ac918cd629a6cd9b294b2> a schema:DefinedTerm ;
    schema:description "Framework for computing dense vector representations of sentences and paragraphs using transformer models."^^xsd:string ;
    schema:name "sentence-transformers"^^xsd:string .

<https://w3id.org/mlentory/mlentory_graph/ebbad1761fb8870fe41c968d83d4055b2799265db268338f3fa38c3849f7932a> a schema:DefinedTerm ;
    schema:description "Comprehensive deep learning platform developed by Baidu, supporting industrial applications."^^xsd:string ;
    schema:name "PaddlePaddle"^^xsd:string .

<https://w3id.org/mlentory/mlentory_graph/ee41d767ffa75d0037ac340fa59164645b363ea8891e2a3f815c644b81ea9fbd> a schema:DefinedTerm ;
    schema:description "Python implementation of state-of-the-art variational autoencoders for generative modeling."^^xsd:string ;
    schema:name "pythae"^^xsd:string .

<https://w3id.org/mlentory/mlentory_graph/ef8c453c903ecc79a3f941fc76e3fb554c3c0e3459f4a7a1755e64539b934598> a schema:DefinedTerm ;
    schema:description "Library for parameter-efficient transfer learning through adapter modules in transformer models."^^xsd:string ;
    schema:name "Adapters"^^xsd:string .

<https://w3id.org/mlentory/mlentory_graph/f38a4d1014d3cc9f5709e2ecd78f5809ca2397dd49ed420aa2e4a0ab4210a289> a schema:DefinedTerm ;
    schema:description "End-to-end open source platform for ML with comprehensive tools and libraries for building and deploying models at scale."^^xsd:string ;
    schema:name "TensorFlow"^^xsd:string .

<https://w3id.org/mlentory/mlentory_graph/f398a6ed462d305d58506b378a7b488c448115a8aef746a62331a8435d54a72b> a schema:DefinedTerm ;
    schema:description "Open-source NLP research library built on PyTorch for developing state-of-the-art models."^^xsd:string ;
    schema:name "AllenNLP"^^xsd:string .

<https://w3id.org/mlentory/mlentory_graph/f4f5c02149ef4c63e1abfb237a7efd73b36b96243fa20ee9a3b83ab914689b18> a schema:DefinedTerm ;
    schema:description "Assigns each pixel in an image to a specific class or object."^^xsd:string ;
    schema:name "Image Segmentation"^^xsd:string .

<https://w3id.org/mlentory/mlentory_graph/f83566aa690a65900e25f19b29d427ae3a9b752766d6d3892299a866feca3edd> a schema:DefinedTerm ;
    schema:description "Parameter-Efficient Fine-Tuning methods that enable efficient adaptation of pre-trained language models."^^xsd:string ;
    schema:name "PEFT"^^xsd:string .

<https://w3id.org/mlentory/mlentory_graph/fd4e2f28de7e36539eda0f2e74a9e9b30f10d77fee3b927dc3aa5419c43369da> a schema:DefinedTerm ;
    schema:description "Converts 2D images into 3D representations or models."^^xsd:string ;
    schema:name "Image to 3D"^^xsd:string .

<https://w3id.org/mlentory/mlentory_graph/03796f961bc00b67e2b12acaa6748c5804221cd7dc225bdb8a6be0c1d057bad4> a ns1:MLModel ;
    schema:name "Qwen/Qwen2.5-0.5B-Instruct"^^xsd:string ;
    schema:url <https://huggingface.co/Qwen/Qwen2.5-0.5B-Instruct> .

<https://w3id.org/mlentory/mlentory_graph/0a51816a4973430cbbb79302d54b3c75493751bc40079439c5c7a4e592e74514> a schema:DefinedTerm ;
    schema:name "i am huge fluffy barracuda"^^xsd:string .

<https://w3id.org/mlentory/mlentory_graph/0aee914bbc884bff2ba1f0f20d69d212ea847639505c98357a8c490a96d303d0> a schema:DefinedTerm ;
    schema:name "chat"^^xsd:string .

<https://w3id.org/mlentory/mlentory_graph/0f8852dfc8f82da503ed1ff94e72d2b21473b92b491c655b6de0ca10148428d3> a schema:DefinedTerm ;
    schema:name "i am bold_running_kangaroo"^^xsd:string .

<https://w3id.org/mlentory/mlentory_graph/0fe4886c1d6af8940799e0f31a8afc2d6d5e01a47df25d73d5928461e904426c> a schema:Person ;
    schema:name "goodcasper"^^xsd:string ;
    schema:url "https://huggingface.co/goodcasper"^^xsd:anyURI .

<https://w3id.org/mlentory/mlentory_graph/20a607de6d3028bc24821288287faa1f8bf92a37433fb7df54105674128d8a68> a schema:Person ;
    schema:name "unsloth"^^xsd:string ;
    schema:url "https://huggingface.co/unsloth"^^xsd:anyURI .

<https://w3id.org/mlentory/mlentory_graph/2534beaf4101b2fd3b1d3f00d3dd5637829b105e8535323bf257e5dfd4aec3a6> a schema:Person ;
    schema:name "Armijo"^^xsd:string ;
    schema:url "https://huggingface.co/Armijo"^^xsd:anyURI .

<https://w3id.org/mlentory/mlentory_graph/26d073be85a3ff0cdc5e730b4f76ae6826240fafeec865a5c98fe9a94cb9be8b> a schema:DefinedTerm ;
    schema:name "vision"^^xsd:string .

<https://w3id.org/mlentory/mlentory_graph/3063efca2e942b6d98aad194d54ad582369c52ec8fc5991489a6f8e8e100fe93> a ns1:MLModel ;
    schema:name "Qwen/Qwen2.5-0.5B"^^xsd:string ;
    schema:url <https://huggingface.co/Qwen/Qwen2.5-0.5B> .

<https://w3id.org/mlentory/mlentory_graph/31ecbf7f13864b695a4c988570ba98cbd834f15dab3fdbc890692e395b618f05> a schema:DefinedTerm ;
    schema:name "i am small lithe ocelot"^^xsd:string .

<https://w3id.org/mlentory/mlentory_graph/34c1379d8dda014b2a509839fe7e8a7c6469730b7f9684dd37b425e4401f273c> a schema:DefinedTerm ;
    schema:name "i am scavenging sniffing lizard"^^xsd:string .

<https://w3id.org/mlentory/mlentory_graph/3545f8928b123a1d57629499049e0f991171b9588a9886215e37fbab73d84c01> a schema:DefinedTerm ;
    schema:name "i am bold running kangaroo"^^xsd:string .

<https://w3id.org/mlentory/mlentory_graph/3e864e5a8c8c21cc38e295a520d9d7e521b90b5852131c5c2504da726f75ece6> a schema:Person ;
    schema:name "Wiliambill"^^xsd:string ;
    schema:url "https://huggingface.co/Wiliambill"^^xsd:anyURI .

<https://w3id.org/mlentory/mlentory_graph/547c2a6f152d09c8e3dbd3a857c5481c4c4d77accf781e6fe237d9c49f47d9a7> a schema:DefinedTerm ;
    schema:name "unsloth"^^xsd:string .

<https://w3id.org/mlentory/mlentory_graph/5905daa0c1bcf7f259cc6f8e1fc4824b50e974518900d25f01cbf3cae9a7eff9> a schema:Person ;
    schema:name "PekingU"^^xsd:string ;
    schema:url "https://huggingface.co/PekingU"^^xsd:anyURI .

<https://w3id.org/mlentory/mlentory_graph/5f6067eceeefdacabbbeea2a780dfa7345e1272c829c82298b760358c1bb07a8> a schema:DefinedTerm ;
    schema:name "i am docile playful octopus"^^xsd:string .

<https://w3id.org/mlentory/mlentory_graph/867fba26049e05cdeac357efdf65e1e500d7e599ea1baa5717727c900a775196> a schema:Person ;
    schema:name "Sonyabu"^^xsd:string ;
    schema:url "https://huggingface.co/Sonyabu"^^xsd:anyURI .

<https://w3id.org/mlentory/mlentory_graph/8960ef15233adcffe0ffb89374d9955f251580395819df1a9693362ac19a04d7> a schema:DefinedTerm ;
    schema:name "i am skilled gilded bee"^^xsd:string .

<https://w3id.org/mlentory/mlentory_graph/8ef75d117a8dc210ae12e742be36678d97d2ebfb8e582cad2ac1cf6f7d8e9c1d> a schema:Person ;
    schema:name "Biondovi"^^xsd:string ;
    schema:url "https://huggingface.co/Biondovi"^^xsd:anyURI .

<https://w3id.org/mlentory/mlentory_graph/9692fc27ed075852059afc5a54867bb875719345a6d2d9d29336d5e99e875a32> a schema:DefinedTerm ;
    schema:name "genrl-swarm"^^xsd:string .

<https://w3id.org/mlentory/mlentory_graph/974df5e3234c3601080dac4fa96eebf5d19d40df41e9e30cb61084d9fbefea1e> a schema:DefinedTerm ;
    schema:description "Visualization toolkit for machine learning experiments that helps track metrics, visualize graphs, and explore embeddings."^^xsd:string ;
    schema:name "TensorBoard"^^xsd:string,
        "tensorboard"^^xsd:string .

<https://w3id.org/mlentory/mlentory_graph/a026994daef9aeefcbd15022017302a1255a44ff8dd0c3d7d4fa63ab770ca0d1> a schema:DefinedTerm ;
    schema:name "i am agile pawing lobster"^^xsd:string .

<https://w3id.org/mlentory/mlentory_graph/a0ab69316adb7c09d875e25f934210e1c8f7ec32062ecc56eadc9299d760e44e> a schema:Person ;
    schema:name "Oberhaus"^^xsd:string ;
    schema:url "https://huggingface.co/Oberhaus"^^xsd:anyURI .

<https://w3id.org/mlentory/mlentory_graph/a168e9b34d074761f8779451d3ce965501aaff2a0c86e967f06c2c999a8951f6> a schema:DefinedTerm ;
    schema:name "i am carnivorous scampering macaque"^^xsd:string .

<https://w3id.org/mlentory/mlentory_graph/a245f998950c99a9208b9f67dc4acdedb6db4ee02c9ff48ca6bec03c788b7e11> a schema:DefinedTerm ;
    schema:name "i am rabid prowling jay"^^xsd:string .

<https://w3id.org/mlentory/mlentory_graph/a6b4bd257f7c074d7ae1233e862a380ec00b15c9d14abcc9f96831670d55e4fe> a ns1:MLModel ;
    schema:name "PekingU/rtdetr_r18vd_coco_o365"^^xsd:string ;
    schema:url <https://huggingface.co/PekingU/rtdetr_r18vd_coco_o365> .

<https://w3id.org/mlentory/mlentory_graph/bf9cb754023f4cf332c0aade32b2500cf9a20677c98b90fe64b0897849999f8e> a schema:Person ;
    schema:name "Qwen"^^xsd:string ;
    schema:url "https://huggingface.co/Qwen"^^xsd:anyURI .

<https://w3id.org/mlentory/mlentory_graph/cc9b9fbf64bf4588733ee17a2c0af8d22af99f9375d502c4dc33e83e14cb7c9f> a schema:Person ;
    schema:name "p2g4ads5"^^xsd:string ;
    schema:url "https://huggingface.co/p2g4ads5"^^xsd:anyURI .

<https://w3id.org/mlentory/mlentory_graph/d55bcd6c258df6a392d65ed4980d9d8db579b01fd74d5014ac5577b1b1eac883> a schema:Person ;
    schema:name "nymphe"^^xsd:string ;
    schema:url "https://huggingface.co/nymphe"^^xsd:anyURI .

<https://w3id.org/mlentory/mlentory_graph/dc53475d9f31201c0e3ed7ccc3986594179e18c27fb01dc5aca0dcfda21516e9> a schema:Person ;
    schema:name "silverbenehi"^^xsd:string ;
    schema:url "https://huggingface.co/silverbenehi"^^xsd:anyURI .

<https://w3id.org/mlentory/mlentory_graph/e5e889a745f1d3f2a82efa664fb959d3d197a1e52340bab1e68dd99b052d5e9e> a schema:ScholarlyArticle ;
    schema:abstract """This report introduces the Qwen2 series, the latest addition to our large
language models and large multimodal models. We release a comprehensive suite
of foundational and instruction-tuned language models, encompassing a parameter
range from 0.5 to 72 billion, featuring dense models and a Mixture-of-Experts
model. Qwen2 surpasses most prior open-weight models, including its predecessor
Qwen1.5, and exhibits competitive performance relative to proprietary models
across diverse benchmarks on language understanding, generation, multilingual
proficiency, coding, mathematics, and reasoning.
  The flagship model, Qwen2-72B, showcases remarkable performance: 84.2 on
MMLU, 37.9 on GPQA, 64.6 on HumanEval, 89.5 on GSM8K, and 82.4 on BBH as a base
language model. The instruction-tuned variant, Qwen2-72B-Instruct, attains 9.1
on MT-Bench, 48.1 on Arena-Hard, and 35.7 on LiveCodeBench. Moreover, Qwen2
demonstrates robust multilingual capabilities, proficient in approximately 30
languages, spanning English, Chinese, Spanish, French, German, Arabic, Russian,
Korean, Japanese, Thai, Vietnamese, and more, underscoring its versatility and
global reach.
  To foster community innovation and accessibility, we have made the Qwen2
model weights openly available on Hugging Face and ModelScope, and the
supplementary materials including example code on GitHub. These platforms also
include resources for quantization, fine-tuning, and deployment, facilitating a
wide range of applications and research endeavors."""^^xsd:string ;
    schema:author "{'name': 'An Yang', 'affiliation': None}"^^xsd:string,
        "{'name': 'Baosong Yang', 'affiliation': None}"^^xsd:string,
        "{'name': 'Binyuan Hui', 'affiliation': None}"^^xsd:string,
        "{'name': 'Bo Zheng', 'affiliation': None}"^^xsd:string,
        "{'name': 'Bowen Yu', 'affiliation': None}"^^xsd:string,
        "{'name': 'Chang Zhou', 'affiliation': None}"^^xsd:string,
        "{'name': 'Chengpeng Li', 'affiliation': None}"^^xsd:string,
        "{'name': 'Chengyuan Li', 'affiliation': None}"^^xsd:string,
        "{'name': 'Dayiheng Liu', 'affiliation': None}"^^xsd:string,
        "{'name': 'Fei Huang', 'affiliation': None}"^^xsd:string,
        "{'name': 'Guanting Dong', 'affiliation': None}"^^xsd:string,
        "{'name': 'Haoran Wei', 'affiliation': None}"^^xsd:string,
        "{'name': 'Huan Lin', 'affiliation': None}"^^xsd:string,
        "{'name': 'Jialin Wang', 'affiliation': None}"^^xsd:string,
        "{'name': 'Jialong Tang', 'affiliation': None}"^^xsd:string,
        "{'name': 'Jian Yang', 'affiliation': None}"^^xsd:string,
        "{'name': 'Jianhong Tu', 'affiliation': None}"^^xsd:string,
        "{'name': 'Jianwei Zhang', 'affiliation': None}"^^xsd:string,
        "{'name': 'Jianxin Ma', 'affiliation': None}"^^xsd:string,
        "{'name': 'Jianxin Yang', 'affiliation': None}"^^xsd:string,
        "{'name': 'Jin Xu', 'affiliation': None}"^^xsd:string,
        "{'name': 'Jingren Zhou', 'affiliation': None}"^^xsd:string,
        "{'name': 'Jinze Bai', 'affiliation': None}"^^xsd:string,
        "{'name': 'Jinzheng He', 'affiliation': None}"^^xsd:string,
        "{'name': 'Junyang Lin', 'affiliation': None}"^^xsd:string,
        "{'name': 'Kai Dang', 'affiliation': None}"^^xsd:string,
        "{'name': 'Keming Lu', 'affiliation': None}"^^xsd:string,
        "{'name': 'Keqin Chen', 'affiliation': None}"^^xsd:string,
        "{'name': 'Kexin Yang', 'affiliation': None}"^^xsd:string,
        "{'name': 'Mei Li', 'affiliation': None}"^^xsd:string,
        "{'name': 'Mingfeng Xue', 'affiliation': None}"^^xsd:string,
        "{'name': 'Na Ni', 'affiliation': None}"^^xsd:string,
        "{'name': 'Pei Zhang', 'affiliation': None}"^^xsd:string,
        "{'name': 'Peng Wang', 'affiliation': None}"^^xsd:string,
        "{'name': 'Ru Peng', 'affiliation': None}"^^xsd:string,
        "{'name': 'Rui Men', 'affiliation': None}"^^xsd:string,
        "{'name': 'Ruize Gao', 'affiliation': None}"^^xsd:string,
        "{'name': 'Runji Lin', 'affiliation': None}"^^xsd:string,
        "{'name': 'Shijie Wang', 'affiliation': None}"^^xsd:string,
        "{'name': 'Shuai Bai', 'affiliation': None}"^^xsd:string,
        "{'name': 'Sinan Tan', 'affiliation': None}"^^xsd:string,
        "{'name': 'Tianhang Zhu', 'affiliation': None}"^^xsd:string,
        "{'name': 'Tianhao Li', 'affiliation': None}"^^xsd:string,
        "{'name': 'Tianyu Liu', 'affiliation': None}"^^xsd:string,
        "{'name': 'Wenbin Ge', 'affiliation': None}"^^xsd:string,
        "{'name': 'Xiaodong Deng', 'affiliation': None}"^^xsd:string,
        "{'name': 'Xiaohuan Zhou', 'affiliation': None}"^^xsd:string,
        "{'name': 'Xingzhang Ren', 'affiliation': None}"^^xsd:string,
        "{'name': 'Xinyu Zhang', 'affiliation': None}"^^xsd:string,
        "{'name': 'Xipin Wei', 'affiliation': None}"^^xsd:string,
        "{'name': 'Xuancheng Ren', 'affiliation': None}"^^xsd:string,
        "{'name': 'Xuejing Liu', 'affiliation': None}"^^xsd:string,
        "{'name': 'Yang Fan', 'affiliation': None}"^^xsd:string,
        "{'name': 'Yang Yao', 'affiliation': None}"^^xsd:string,
        "{'name': 'Yichang Zhang', 'affiliation': None}"^^xsd:string,
        "{'name': 'Yu Wan', 'affiliation': None}"^^xsd:string,
        "{'name': 'Yunfei Chu', 'affiliation': None}"^^xsd:string,
        "{'name': 'Yuqiong Liu', 'affiliation': None}"^^xsd:string,
        "{'name': 'Zeyu Cui', 'affiliation': None}"^^xsd:string,
        "{'name': 'Zhenru Zhang', 'affiliation': None}"^^xsd:string,
        "{'name': 'Zhifang Guo', 'affiliation': None}"^^xsd:string,
        "{'name': 'Zhihao Fan', 'affiliation': None}"^^xsd:string ;
    schema:datePublished "2024-07-15"^^xsd:date ;
    schema:keywords "cs.AI"^^xsd:string,
        "cs.CL"^^xsd:string ;
    schema:name "Qwen2 Technical Report"^^xsd:string ;
    schema:url "https://arxiv.org/abs/2407.10671"^^xsd:anyURI,
        "https://arxiv.org/abs/2407.10671"^^xsd:string .

<https://w3id.org/mlentory/mlentory_graph/eef0031ff6e5dac5843259d345350aaa1f938abb2683bf0974713c4785c2af9c> a schema:Person ;
    schema:name "gitas"^^xsd:string ;
    schema:url "https://huggingface.co/gitas"^^xsd:anyURI .

<https://w3id.org/mlentory/mlentory_graph/f09f16395d224d8d8c2cf0df84c7f2a269bcd29b24f0f2d728c6fea7e009b1ce> a schema:ScholarlyArticle ;
    schema:abstract """The YOLO series has become the most popular framework for real-time object
detection due to its reasonable trade-off between speed and accuracy. However,
we observe that the speed and accuracy of YOLOs are negatively affected by the
NMS. Recently, end-to-end Transformer-based detectors (DETRs) have provided an
alternative to eliminating NMS. Nevertheless, the high computational cost
limits their practicality and hinders them from fully exploiting the advantage
of excluding NMS. In this paper, we propose the Real-Time DEtection TRansformer
(RT-DETR), the first real-time end-to-end object detector to our best knowledge
that addresses the above dilemma. We build RT-DETR in two steps, drawing on the
advanced DETR: first we focus on maintaining accuracy while improving speed,
followed by maintaining speed while improving accuracy. Specifically, we design
an efficient hybrid encoder to expeditiously process multi-scale features by
decoupling intra-scale interaction and cross-scale fusion to improve speed.
Then, we propose the uncertainty-minimal query selection to provide
high-quality initial queries to the decoder, thereby improving accuracy. In
addition, RT-DETR supports flexible speed tuning by adjusting the number of
decoder layers to adapt to various scenarios without retraining. Our
RT-DETR-R50 / R101 achieves 53.1% / 54.3% AP on COCO and 108 / 74 FPS on T4
GPU, outperforming previously advanced YOLOs in both speed and accuracy. We
also develop scaled RT-DETRs that outperform the lighter YOLO detectors (S and
M models). Furthermore, RT-DETR-R50 outperforms DINO-R50 by 2.2% AP in accuracy
and about 21 times in FPS. After pre-training with Objects365, RT-DETR-R50 /
R101 achieves 55.3% / 56.2% AP. The project page:
https://zhao-yian.github.io/RTDETR."""^^xsd:string ;
    schema:author "{'name': 'Guanzhong Wang', 'affiliation': None}"^^xsd:string,
        "{'name': 'Jie Chen', 'affiliation': None}"^^xsd:string,
        "{'name': 'Jinman Wei', 'affiliation': None}"^^xsd:string,
        "{'name': 'Qingqing Dang', 'affiliation': None}"^^xsd:string,
        "{'name': 'Shangliang Xu', 'affiliation': None}"^^xsd:string,
        "{'name': 'Wenyu Lv', 'affiliation': None}"^^xsd:string,
        "{'name': 'Yi Liu', 'affiliation': None}"^^xsd:string,
        "{'name': 'Yian Zhao', 'affiliation': None}"^^xsd:string ;
    schema:datePublished "2023-04-17"^^xsd:date ;
    schema:keywords "cs.CV"^^xsd:string ;
    schema:name "DETRs Beat YOLOs on Real-time Object Detection"^^xsd:string ;
    schema:url "https://arxiv.org/abs/2304.08069"^^xsd:anyURI,
        "https://arxiv.org/abs/2304.08069"^^xsd:string .

<https://w3id.org/mlentory/mlentory_graph/8b17850df3f6918f97a864deac6761f4da511fdf01824bc548e41b5f19be8be9> a schema:DefinedTerm ;
    schema:name "rt_detr"^^xsd:string .

<https://w3id.org/mlentory/mlentory_graph/c6a31d1f7013eb41349bc590b0cc16d51b0a1706fa3f70c1337a8eecf06d2173> a schema:DefinedTerm ;
    schema:description "Identifies and locates objects within images using bounding boxes."^^xsd:string ;
    schema:name "Object Detection"^^xsd:string,
        "object detection"^^xsd:string .

<https://w3id.org/mlentory/mlentory_graph/cd80afb56f05e9ebd40fbd9cf6e6ae1f1295504c991157b8c26b00d097cef292> a schema:DefinedTerm ;
    schema:name "object-detection"^^xsd:string .

<https://w3id.org/mlentory/mlentory_graph/bc6b0c92e28e79bca517979432945aec4c2f9fbd1676acf8574200fe061a6485> a ns1:Dataset ;
    schema:name "coco"^^xsd:string ;
    schema:url "https://huggingface.co/datasets/coco"^^xsd:anyURI .

<https://w3id.org/mlentory/mlentory_graph/c76582abee5256ca6e0f130b7b4bb38d54684358fa6802ca36e620ee6c5f00f1> a schema:CreativeWork ;
    schema:identifier "Apache-2.0"^^xsd:string ;
    schema:name "Apache-2.0"^^xsd:string ;
    schema:url <https://spdx.org/licenses/Apache-2.0.html> .

<https://w3id.org/mlentory/mlentory_graph/28f6fc79227e13d54a24f63fe2a8971b6f281ac3ca778d4303f84baacbc18a18> a schema:DefinedTerm ;
    schema:name "trl"^^xsd:string .

<https://w3id.org/mlentory/mlentory_graph/29901b0ecce864a67f7734a040b22f9867d7435fdb731b76633a212ffab331f4> a schema:DefinedTerm ;
    schema:name "gensyn"^^xsd:string .

<https://w3id.org/mlentory/mlentory_graph/4d2ce24e500528b55a21cac8de96cce215994b6ca25877254bca1857cd8b9e55> a ns1:MLModel ;
    schema:name "unsloth/Qwen2.5-0.5B-Instruct"^^xsd:string ;
    schema:url <https://huggingface.co/unsloth/Qwen2.5-0.5B-Instruct> .

<https://w3id.org/mlentory/mlentory_graph/57ac8dd147b53050bf4aa8cb4dbc16ad91197f7662c02666466eb8e9888d87a7> a schema:ScholarlyArticle ;
    schema:abstract """Mathematical reasoning poses a significant challenge for language models due
to its complex and structured nature. In this paper, we introduce DeepSeekMath
7B, which continues pre-training DeepSeek-Coder-Base-v1.5 7B with 120B
math-related tokens sourced from Common Crawl, together with natural language
and code data. DeepSeekMath 7B has achieved an impressive score of 51.7% on the
competition-level MATH benchmark without relying on external toolkits and
voting techniques, approaching the performance level of Gemini-Ultra and GPT-4.
Self-consistency over 64 samples from DeepSeekMath 7B achieves 60.9% on MATH.
The mathematical reasoning capability of DeepSeekMath is attributed to two key
factors: First, we harness the significant potential of publicly available web
data through a meticulously engineered data selection pipeline. Second, we
introduce Group Relative Policy Optimization (GRPO), a variant of Proximal
Policy Optimization (PPO), that enhances mathematical reasoning abilities while
concurrently optimizing the memory usage of PPO."""^^xsd:string ;
    schema:author "{'name': 'Daya Guo', 'affiliation': None}"^^xsd:string,
        "{'name': 'Haowei Zhang', 'affiliation': None}"^^xsd:string,
        "{'name': 'Junxiao Song', 'affiliation': None}"^^xsd:string,
        "{'name': 'Mingchuan Zhang', 'affiliation': None}"^^xsd:string,
        "{'name': 'Peiyi Wang', 'affiliation': None}"^^xsd:string,
        "{'name': 'Qihao Zhu', 'affiliation': None}"^^xsd:string,
        "{'name': 'Runxin Xu', 'affiliation': None}"^^xsd:string,
        "{'name': 'Xiao Bi', 'affiliation': None}"^^xsd:string,
        "{'name': 'Y. K. Li', 'affiliation': None}"^^xsd:string,
        "{'name': 'Y. Wu', 'affiliation': None}"^^xsd:string,
        "{'name': 'Zhihong Shao', 'affiliation': None}"^^xsd:string ;
    schema:datePublished "2024-02-05"^^xsd:date ;
    schema:keywords "cs.AI"^^xsd:string,
        "cs.CL"^^xsd:string,
        "cs.LG"^^xsd:string ;
    schema:name "DeepSeekMath: Pushing the Limits of Mathematical Reasoning in Open Language Models"^^xsd:string ;
    schema:url "https://arxiv.org/abs/2402.03300"^^xsd:anyURI,
        "https://arxiv.org/abs/2402.03300"^^xsd:string .

<https://w3id.org/mlentory/mlentory_graph/a4cf9836ab3780436e61a37fe48729edb682b8e0e1c3f9363cb10061770a7197> a schema:DefinedTerm ;
    schema:name "grpo"^^xsd:string .

<https://w3id.org/mlentory/mlentory_graph/c21ccd276af5ae1828bea64af6da9742c6ef229f7b0571987909160419d90560> a schema:DefinedTerm ;
    schema:name "rl-swarm"^^xsd:string .

<https://w3id.org/mlentory/mlentory_graph/04151ef09fe56a2be18a7d842066720d6e7cee10ed5bf1a3363193444decd94d> a schema:DefinedTerm ;
    schema:name "generated_from_trainer"^^xsd:string .

<https://w3id.org/mlentory/mlentory_graph/61cce84de930f0da8c78ddef3203a2afac70cf5e46684f0407180738cd821965> a schema:DefinedTerm ;
    schema:name "conversational"^^xsd:string .

<https://w3id.org/mlentory/mlentory_graph/6925cb204ab4d5280c948ac7e23dd8f7b48d1de433cf9edc5c30a8d87ce3b317> a schema:DefinedTerm ;
    schema:description "Creates natural language text based on initial prompts."^^xsd:string ;
    schema:name "Text Generation"^^xsd:string,
        "text generation"^^xsd:string .

<https://w3id.org/mlentory/mlentory_graph/789df8584c437cfcddc5b2fff51cdef26423ea8d53635a0100a83cd8490b5cb6> a schema:DefinedTerm ;
    schema:name "qwen2"^^xsd:string .

<https://w3id.org/mlentory/mlentory_graph/79cf083846a8329d2912fcd7f375233c37a54917af291bb945f0b58bc735b8ad> a schema:DefinedTerm ;
    schema:name "text-generation"^^xsd:string .

<https://w3id.org/mlentory/mlentory_graph/81c4f52fcccf6ef0d25453aedb7cebe30c7034e3b2fa752246d0e43da889a0e1> a schema:DefinedTerm ;
    schema:name "autotrain_compatible"^^xsd:string .

<https://w3id.org/mlentory/mlentory_graph/f59cf55f3a86acf0bcfc020eac552a72c13f1212154211a7bf30504548661f8d> a schema:DefinedTerm ;
    schema:description "Optimized backend for deploying and serving Large Language Models (LLMs) with high performance."^^xsd:string ;
    schema:name "text-generation-inference"^^xsd:string .

<https://w3id.org/mlentory/mlentory_graph/0dce0f5e7319b6178cd79d5f2163f0e134d0064f4ea4f93e8afeec1e7d78fa8d> a schema:DefinedTerm ;
    schema:name "endpoints_compatible"^^xsd:string .

<https://w3id.org/mlentory/mlentory_graph/87b927fef88a46248b3b208472aec7bfeb38667386b309f46772e26b40f6affb> a schema:DefinedTerm ;
    schema:description "Fast and safe serialization format for storing and distributing machine learning model weights."^^xsd:string ;
    schema:name "Safetensors"^^xsd:string,
        "safetensors"^^xsd:string .

<https://w3id.org/mlentory/mlentory_graph/df4982af808ead1a57663cc7a83e60059f6a6ae1baf83a270fdf8bdfef11a3de> a schema:DefinedTerm ;
    schema:description "Library providing pretrained models for NLP and CV tasks, with implementations in PyTorch and TensorFlow."^^xsd:string ;
    schema:name "Transformers"^^xsd:string,
        "transformers"^^xsd:string .

